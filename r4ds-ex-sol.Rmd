--- 
title: "Решение упражнений из книги R Science"
author: "Stas Masuta"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
description: "Здесь будут публиковаться решения заданий из книги"
---

---
output: html_document
editor_options:
  chunk_output_type: console
---

# Введение

Это электронная версия решений упражнений, свёрстанная при помощи **bookdown**, который можно установить здесь:

```{r eval=FALSE}
install.packages("bookdown")
# or the development version
# devtools::install_github("rstudio/bookdown")
```

<!--chapter:end:index.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Предварительный анализ
## Визуализация данных с помощью `ggplot2`
### Введение
Электронная версия книги по адресу http://r4ds.had.co.nz.

Для начала работы подключаем библиотеки
```{r}
library("tidyverse")
library("viridis")
library("forcats")
library("nycflights13")
library("Lahman")
library("dplyr")
```

Дополнительно, используются пакеты `"nycflights13", "gapminder", "Lahman"`


А это шпаргалка [cheat_sheet](https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf)


Не было упражнений.

### Первые шаги
#### Упражнение 3.2.1 
<div class="question">
Run `ggplot(data = mpg)` what do you see?
</div>

```{r}
ggplot(data = mpg)
```

Пустое окно построения.  Функция `ggplot()` из пакета `ggplot2` только содаёт область построения, функциями мы производим наполнение области построения. Больше инфы смотри в подсказке https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf .

#### Упражнение 3.2.2 
<div class="question">
How many rows are in `mpg`? How many columns?
</div>

Чтобы проверить "строение" фрейма данных `mpg`,можно воспользоваться двумя способами.
Var1:

```{r}
ggplot2::mpg
```

где видно что `mpg` это матрица 234 строки на 11 столбцов.

Var2:

```{r}
glimpse(mpg)
```

Сразу тут покажу, что каждый параметр означает:

| Название     | Описание |
| ------------ |:-------------:|
| manufacturer | изготовитель|
| model        | модель|
| displ        | объём двигателя в литрах|
| year         | год изготовления|
| cyl          | количество цилиндров|
| trans        | тип трансмиссии|
| drv          | тип привода|
| cty          | кол-во миль по городу на галлон|
| hwy          | кол-во миль за городом на галлон|
| fl           | тип топлива|
| class        | класс автомобиля|


#### Упражнение 3.2.3 
<div class="question">
What does the `drv` variable describe? Read the help for `?mpg` to find out.
`drv` — это имя одного из параметров, оно обозначает тип привода автомобиля.
</div>

| Краткое название| Тип привода|
| --------------- |:----------:|
| f               | передний   |
| r               | задний     |
| 4               | полный     |

#### Упражнение 3.2.4 
<div class="question"> 
Make a scatter plot of `hwy` vs `cyl`.
</div>

можно прописывать на одной координатной плоскости разные геометрические функции с индивидуальными параметрами, тогда правильнее будет писать вот так


Var 1
```{r 41}
ggplot(data = mpg)+
  geom_point(mapping = aes(x = hwy, y = cyl))
```

Но если параметры одни и те же, а требуется построить разные геометрии, то лучше прописать общие параметры вынося их "за скобки"
Var 2
```{r}
ggplot(data = mpg, aes(x = hwy, y = cyl))+
 geom_point()
```

#### Упражнение 3.2.5 
<div class="question">
What happens if you make a scatterplot of `class` vs `drv`? Why is the plot not useful?
</div>

Оба параметра являются категориальными, или описательными. Можно построить `<chr>` от `<chr>`. 
```{r}
ggplot(data = mpg) + geom_point(mapping = aes(x = class, y = drv))
```

Но с точки зрения аналитики, такая информация не несёт большой пользы. В конкретном примере можно только сказать что, все автомобили класса `2seater` имеют задний привод. А в классе `subcompact` есть все типы привода.

### Эстетика визуализации
#### Упражнения 3.3.1  
<div class="question">
What’s gone wrong with this code? Why are the points not blue? 
</div>

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, colour = "blue"))
```

Всё потому что `colour` не вынес за скобки, потому что `colour` это параметр функции `geom_point()`, not `aes()` 
правильно вот так

```{r}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy), colour = "blue")
```


#### Упражнения 3.3.2  
<div class="question">
Which variables in `mpg` are categorical? Which variables are continuous? (Hint: type `?mpg` to read the documentation for the dataset). How can you see this information when you run `mpg`?  
</div>

Это те факторы, которые позволяют разделить на показатели. Чтобы понять какие факторы являются категориальными можно воспользоваться функцией `glimpse()`, которая показывает тип каждого столбца. Соответственно, те что `<chr>` и есть категориальные:

```{r}
glimpse(mpg)
```


#### Упражнения 3.3.3  
<div class="question">
Map a continuous variable to `color`, `size`, and `shape`. How do these aesthetics behave differently for categorical vs. continuous variables?  
</div>

Непрерывные переменные, это такие переменные которые принимают значения в некотором диапазоне. Непрерывной переменной является например `cty`, city miles per gallon, и показывает сколько проедет автомобиль в черте горда на один галлон топлива.
Если сопоставить этой переменной **цвет** то получится
```{r}
ggplot(mpg, aes(x = displ, y = hwy, colour = cty)) +
   geom_point()
```


Цвет распределяется в диапазоне переменной `cty`, то есть в пределах от примерно 10 до 35.
Попробуем теперь соспоставить **размер**
```{r}
ggplot(mpg, aes(x = displ, y = hwy, size = cty)) +
   geom_point()
```


В принципе получается такая же картина, только точки выделены не цветом, а размером.
И наконец, сопоставим **форму** непрерывной переменной
```{r}
#ggplot(mpg, aes(x = displ, y = hwy, shape = cty)) + geom_point()
```
А вот и нет. Программа выдаст `Ошибка: A continuous variable can not be mapped to shape`.
Непрерывные переменные не соотносятся с атрибутом `shape`, так сделано специально. Потому что фигур всего 24, а наборов значений у непрерывной переменной может быть сколь угодно много

#### Упражнения 3.3.4

<div class="question">
What happens if you map the same variable to multiple aesthetics? 
</div>

Связать можно, вот например, переменная `drv` для цвета и для формы
```{r}
ggplot(mpg, aes(x = displ, y = hwy, color = drv, shape = drv)) + geom_point()
```

но это будет избыточное выделение.

#### Упражнения 3.3.5 
<div class="question">
What does the `stroke` aesthetic do? What shapes does it work with? (Hint: use `?geom_point`)
</div>

`stroke` это размер границы фигуры. Он работает с фигурами, у которых помимо полной заливки есть цвет границы т.е. фигуры 21-24
![alt text](img/shapes.png)


Иллюстрирующий пример. Вот построение обычными точками
```{r}
ggplot(mpg, aes(hwy, cyl))+
 geom_point()
```

Теперь зададим красную заливку, и размер границы фигуры $2$

```{r}
ggplot(mpg, aes(hwy, cyl)) +
 geom_point(shape=21,colour="black",fill="red",size=3,stroke=2)
```

Ну а теперь $5$
```{r}
ggplot(mpg, aes(hwy, cyl)) +
 geom_point(shape=21,colour="black",fill="red",size=3,stroke=5)
```

#### Упражнения 3.3.6 
<div class="question">
What happens if you map an aesthetic to something other than a variable name, like `aes(colour = displ < 5)`?
</div>

Визуальные атрибуты можно задавать и логическими выражениями, как допустим в таком выражении:

```{r}
 ggplot(mpg, aes(displ,hwy, color = displ < 2)) +
   geom_point()
```

```{r}
 ggplot(mpg, aes(displ,hwy, color = displ < 4)) +
   geom_point()
```

```{r}
 ggplot(mpg, aes(displ,hwy, size = displ > 3)) +
   geom_point()
```

К тому же `R` ругается, что лучше бы такое не делать
### Распространённые ошибки
Проблемы случаются и это норм. Если что-то не получается,  чекни код.

Часто бывает что поставил `+` не туда. Он должен быть в конце строки, а не в начале.

### Панели
#### Упражнение 3.5.1 
<div class="question">
What happens if you facet on a continuous variable?
</div>

Как это работает. 

Построим график `highway miles per gallon` от `engine displacement, in litres`. 
```{r}
ggplot(mpg, aes(x = displ, y = hwy)) +
   geom_point()
```

Теперь разделим на "окошки" т.е. возьмём срез графиков с теми же дискретными переменными, но в разрезе типа привода автомобиля `drv` от количества цилиндров `cyl`.
```{r}
ggplot(mpg, aes(x = displ, y = hwy)) +
  geom_point() +
  facet_grid(drv ~ cyl)
```
Получилось $12$ панелей, потому что `drv` дискретная, ограниченная переменная, у неё всего три набора значения ($4, f, d$). Количество цилиндров `cyl` тоже ограниченная $4,5,6,8$. Поэтому получилось $3*4=12$ значений. Так как панелей получилось немного, такое представление осязаемо, с ним можно работать, оно информативно.

Если мы попробуем построить в одном измерении непрерывную переменную. То количество панелей возрастёт на количество значений этой переменной. Получится не очень информативно. Заменим в этом же построении количество цилиндров `cyl` на расстояние, пройденное за один галлон топлива в городской черте `cty`. Это непрерывная переменная, у которой много значений. 

```{r}
ggplot(mpg, aes(x = displ, y = hwy)) +
 geom_point() +
 facet_grid(drv ~ cty)
```
Вот что произойдет, если параметром для панели задать непрерывную переменную. Будет много окошек, информативность представленной информации падает.

#### Упражнение 3.5.2 
<div class="question">
What do the empty cells in plot with `facet_grid(drv ~ cyl)` mean? How do they relate to this plot?
</div>

Построим панели по заданному условию
```{r}
ggplot(mpg, aes(x = displ, y = hwy)) +
    geom_point() +
    facet_grid(drv ~ cyl)
```

Пустые ячейки 

* $cyl(5):drv(4)$;
* $cyl(4):drv(r)$;
* $cyl(5):drv(r)$;  

говорят о том, что нет точек удовлетворяющих этим разрезам данных. Иначе говоря, в наборе данных `mpg`

* нет полноприводных авто с 5 цилиндрами
* заднеприводных авто с 4 цилиндрами
* заднеприводных авто с 5 цилиндрами

Построим заданную функцию 
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = drv, y = cyl))
```  

Она соотносится с построенными выше панелями в том, что показывает отсутствие данных в комбинациях переменных `drv:cyl`

#### Упражнение 3.5.3 
<div class="question"> 
What plots does the following code make? What does `«.»` do?

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ .)
```

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(. ~ cyl)
```
</div>

Сравним с оригиналом:
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) +
  facet_grid(drv ~ cyl)
```

Как видно на самих построениях, точка убирает одно из измерений панели следующим образом:

*Если точка стоит в первой координате, `(. ~ param)`, то убираются строки
*Если точка стоит во второй координате, `(param ~ .)`, то убираются столбцы

#### Упражнение 3.5.4 

<div class="question"> 
Take the first faceted plot in this section:

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)
```

What are the advantages to using faceting instead of the colour aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset?
</div>

Для того чтобы сравнить это цветное выделение с выделением плитками. Посмотрим как выглядит выделение того же построения данных цветом:

```{r}
ggplot(data = mpg) + 
   geom_point(mapping = aes(x = displ, y = hwy, color = class))
```

* **Преимущество** построения плитками заключается в том, что каждая группы "очищена" от мусора других групп. Плитками проще оценить распределение точек в отдельно взятой группе. Кроме этого если выделять цветом построения с большим количеством групп, то необходимо более ответственно подходить к подбору цветов `-- нужно делать их более контрастными. Потому что при увеличении количества групп, цвета начинают сливаться, и уже трудно различать к какой категории относится точка.

* **Недостаток** построяния плитками заключается в том, что каждая группа строится в отдельной системе координат. Трудно сравнивать распределение точек между группами.

#### Упражнение 3.5.5 

<div class="question"> 
Read `?facet_wrap`. What does `nrow` do? What does `ncol` do? What other options control the layout of the individual panels? Why doesn’t `facet_grid()` have `nrow` and `ncol` arguments?
</div>

| аргумент        | что значит          |
| ------------- |:-------------:|
| `nrow`   | количество строк |
| `ncol`    | количество столбцов    |

Эти переменные нужны, так как срез графика в `facet_wrap()` происходит по одной дискретной переменной. В свою очередь `facet_grid` использует комбинации двех переменных поэтому для построения не нужно выбирать количество строк или колонок.

#### Упражнение 3.5.6 
<div class="question"> 
When using `facet_grid()` you should usually put the variable with more unique levels in the columns. Why?
</div>

Экраны наших компьютеров, книги, чертежи, имеют альбомную ориентацию и на одном носители умещается больше данных. Поэтому визуально проще сравнивать большее количество переменных по-горизонтали.

### Геометрические объекты
#### Упражнения 3.6.1 
<div class="question">
What geom would you use to draw a line chart? A boxplot? A histogram? An area chart?
</div>

На русский язык "boxplot перевели как "полосчатый график". Это конечно сбивает с толку, потому что boxplot это конечно "ящик с усами". Исходя из этого

| Название графика| Объект `geom`|
| ------------- |:-------------:|
| linechart | `geom_line` |
| boxplot    | `geom_boxplot`   |
| histogram | `geom_histogram` |
| area chart | `geom_area` |


#### Упражнения 3.6.2 
<div class="question">
Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions.
</div>

Это будет распределение `displ` от `hwy`. С цветом точек в зависимости от `drv`, т.е. три цвета - зелёный, красный и голубой. В этой же системе координат будет построена линия среднеквадратичного приближения без доверительного интервала с тем же цветом, что и точки.
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, colour = drv)) +
  geom_point() +
  geom_smooth(se = FALSE)
```

Поправочка - будет три линии приближений с цветом, соответсвующим цвету точек, по которым строится это приближение

#### Упражнения 3.6.3 
<div class="question">
What does `show.legend = FALSE` do? What happens if you remove it? Why do you think I used it earlier in the chapter?
</div>

Автор имеет в виду этот пример

```{r}
ggplot(mpg) +
  geom_smooth(
    mapping = aes(displ, hwy, colour = drv),
    show.legend = FALSE
  )
```

Инструкция `show.legend` распоряжает показывать легенду графика или нет. По умолчанию эта инструкция имеет значение `TRUE`. В примере из книги, инструкция `show.legend = FALSE` использовалась намеренно, чтобы в максимальном размере уместить в одну строку три графика. Тот же график с легендой выглядит вот так:
```{r}
ggplot(mpg) +
  geom_smooth(
    mapping = aes(displ, hwy, colour = drv)
  )
```


#### Упражнения 3.6.4 
<div class="question">
What does the `se` argument to `geom_smooth()` do?
</div>

Аргумент `se` распоряжает показывать ли доверительный интервал или нет. По умолчанию этот интервал показывается. В примере ниже доверительный интервал показывается:
```{r}
ggplot(mpg) + 
  geom_smooth(mapping = aes(displ, hwy))
```

Теперь уберём его:
```{r}
ggplot(mpg) + 
  geom_smooth(mapping = aes(displ, hwy), se = FALSE)
```

#### Упражнения 3.6.5 
<div class="question">
Will these two graphs look different? Why/why not?

```{r, eval = FALSE}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()
```

```{r, eval = FALSE}
ggplot() + 
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
```
</div>

Эти графики будут идентичными, потому что в первом случае в функции `ggplot()` задаются исходные условия сразу для всех функций, которые будут строится на этом поле построения. А во втором случае, все исходные условия для построений указаны в каждой функции индивидуально. И так как различий в этих условиях нет, то выглядеть они будут одинаково:
```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point() + 
  geom_smooth()
```

```{r}
ggplot() + 
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
```

#### Упражнения 3.6.6 
<div class="question">
Recreate the R code necessary to generate the following graphs.
![alt text](img/graphics3.6.6.png)
</div>


1. В левом верхнем графике наложено два построения. Первое `geom_point()` - обычное построение без какой либо группировки и цветового выделения. Второе `geom_smouth()` - построение распределения без группировки и цветового выделения, без построения доверительного интервала. Так как у обоих построений одинаковые исходные условия, их можно "вынести за скобки", то есть указать в "родительском" `ggplot()`:
```{r}
 ggplot(mpg, mapping = aes(displ, hwy)) +
   geom_point() +
   geom_smooth(se = FALSE)
```

2. В правом верхнем графике наложено два построения. Первое `geom_point()` - обычное построение без какой либо группировки и цветового выделения. Второе `geom_smouth()` - построение распределения с группировкой по признаку `drv`, без построения доверительного интервала. Так как у двух постройний разные условия, лучше для каждого прописать исходные данные индивидуально
```{r}
 ggplot(mpg) +
    geom_point(mapping = aes(displ, hwy)) +
    geom_smooth(mapping = aes(displ, hwy, group = drv), se = FALSE)
```

3. В левом среднем графике наложено два построения. Первое `geom_point()` - с цветовой группировкой  по признаку `drv`. Второе `geom_smouth()` - построение распределения с цветовой группировкой по признаку `drv`, без построения доверительного интервала. Так как у обоих построений одинаковые исходные условия, их можно "вынести за скобки", то есть указать в "родительском" `ggplot()`:
```{r}
 ggplot(mpg, mapping = aes(displ, hwy, colour = drv)) +
    geom_point() +
    geom_smooth(se = FALSE)
```

4. В правом среднем графике наложено два построения. Первое `geom_point()` - с цветовой группировкой  по признаку `drv`. Второе `geom_smouth()` - построение распределения без группировки и цветового выделения, без построения доверительного интервала. Так как у двух постройний разные условия, лучше для каждого прописать исходные данные индивидуально:
```{r}
 ggplot(mpg) +
    geom_point(mapping = aes(displ, hwy, colour = drv)) +
    geom_smooth(mapping = aes(displ, hwy), se = FALSE)
```

5. В левом нижнем графике наложено два построения. Первое `geom_point()` - с цветовой группировкой  по признаку `drv`. Второе `geom_smouth()` - построение распределения с группировкой по признаку `drv`, с выделением каждой кривой группы разным типом линии, без построения доверительного интервала. Так как у двух постройний разные условия, лучше для каждого прописать исходные данные индивидуально:
```{r}
 ggplot(mpg) +
    geom_point(mapping = aes(displ, hwy, colour = drv)) +
    geom_smooth(mapping = aes(displ, hwy, linetype = drv), se = FALSE)
```

6. В правом нижнем графике только одно построение `geom_point()` - с цветовой группировкой  по признаку `drv` и толстыми белыми границами у точек.
```{r}
 ggplot(mpg, mapping = aes(displ, hwy, fill = drv)) +
    geom_point(shape = 21, colour = "white", size = 4, stroke = 4)
```


### Статистические преобразования
#### Упражнения 3.7.1 
<div class="question">
What is the default geom associated with `stat_summary()`? How could you rewrite the previous plot to use that geom function instead of the stat function?
</div>


Для того чтобы ответить на этот вопрос, необходимо открыть help - `?stat_summary`

`stat_summary(mapping = NULL, data = NULL, geom = "pointrange", position = "identity", ..., fun.data = NULL, fun.y = NULL, fun.ymax = NULL, fun.ymin = NULL, fun.args = list(), na.rm = FALSE, show.legend = NA, inherit.aes = TRUE)`

 Это и есть ответ - со статистикой  `stat_summary()` связана геометрия `geom = "pointrange"`.
 
 Теперь ответим на вопрос, как можно переписать код
 
```{r}
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
```

Необходимо заменить `stat_summary()` на `geom_pointrange()` и вставить название необходимой статистики:
```{r}
ggplot(data = diamonds) + 
  geom_pointrange(
    mapping = aes(x = cut, y = depth),
    stat = "summary",
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
```

#### Упражнения 3.7.2 
<div class="question">
What does `geom_col()` do? How is it different to `geom_bar()`?
</div>

Функции имеют разные статистики по умолчанию. `geom_bar()` иметт `stat_count()`, а `geom_col()` имет `stat_identity()` Т.е. `geom_bar()` считает, сколько наблюдений попадает в просматриваемый диапазон и столбец показывает количество попавших наблюдений в диапазон. А `geom_col()` - строит столбцы по количеству наблюдений в диапазоне, а `geom_bar()` число наблюдений.

#### Упражнения 3.7.3 
<div class="question">
Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common?
</div>

Общие элементы у статистик и геометрий это `aes()`, `position`, а пары геометрия-статистика следующие:

| `geom_`        | `stat_`         |
| ------------- |:-------------:|
| `path`  | `eclipse`, `function`|
| `point`    | `identity`, `unique`  |
| `tile` | `summary_2d`    |
| `hex` | `summary_hex`    |
| `pointrange` | `summary_bin`, `summary`|

#### Упражнения 3.7.4 
<div class="question">
What variables does `stat_smooth()` compute? What parameters control its behavior?
</div>

* `y` - predicted value, прогнозируемое значение

* `ymin` -  lower pointwise confidence interval around the mean, нижний уровень доверительного интервала среднего значения

* `ymax` -  upper pointwise confidence interval around the mean, верхний уровень доверительного интервала среднего значения

* `se` - standard error, стандтартное отклонение

Я так полагаю, параметры которые регулируют поведение функции, это специальные методы. Если это не так, то я однажды вернусь сюда и дополню этот ответ.

#### Упражнения 3.7.5 
<div class="question">
In our proportion bar chart, we need to set group = 1 Why? In other words what is the problem with these two graphs?

Graph #1
```{r, eval = FALSE}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop..))
```

Graph #2
```{r, eval = FALSE}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..))
```
</div>

Если не указать значение `group`, то все столбики то есть построения будут иметь `prop = 1`. Функция `geom_bar` по умолчанию использует статистику `stat_count`, которая считает количество значений внутри группы.
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop..))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..))
```

Проблема с этими двумя графиками заключается в том, что пропорции вычисляются внутри групп. Чтобы исправить, нужно указать группы в этих графиках:
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1))

ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = color, y = ..prop.., group = color))
```

### Позиционные настройки

В заданиях часто используется фрейм данных `diamonds`, укажем его здесь:

|параметр| описание |
| ------------- |:-------------:|
| `price`| цена в долларах  (\$326–\$18,823)|
| `carat`| вес бриллианта (0.2–5.01)|
| `cut`| качество огранки (Fair, Good, Very Good, Premium, Ideal)|
| `color`|цвет бриллианта J (worst) to D (best)|
| `clarity`|чистота, или прозрачность (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best) |
| `x`| длинна в мм |
| `y`| ширина в мм |
| `z`| высота в мм|
| `depth`|  величина total depth percentage = z / mean(x, y) = 2 * z / (x + y) (от 43 до 79)|
| `table`| ширина верхней части алмаза относительно самой широкой точки (от 43 до 95)|

варианты использования аргумента `position`:

* `position = "identity"`. Строит столбцы с перекрыванием, т.е. в точности, где каждый объект должен находится. Это сложно заметить, поэтому если есть необходимость использовать эту настройку, то чтобы увидеть перекрытие нужно дополнительно указывать параметр прозрачности `alpha`:

```{r}
ggplot(
  data = diamonds,
  mapping = aes(x = cut, fill = clarity)) +
  geom_bar(alpha = 1/5, position = "identity")
```

или делать объекты незалитыми убирая у атрибута `fill` цвет:

```{r}
ggplot(
  data = diamonds,
  mapping = aes(x = cut, color = clarity)) +
  geom_bar(fill = NA, position = "identity")
```

* `position = "fill"` Создаёт стековые столбцы одинаковой высоты. Удобно сравнивать пропорции у значений.

```{r}
ggplot(diamonds) +
  geom_bar(
    mapping = aes(x = cut, fill = clarity),
    position = "fill"
    )
```

* `position = "dodge"`. Строит перекрывающиеся столбцы рядом друг с другом

```{r}
ggplot(diamonds) +
  geom_bar(
    mapping = aes(x = cut, fill = clarity),
    position = "dodge"
    )
```

* `position = "jitter"`. Не подходит для столбчатых диаграмм, но отлично подходит для диаграмм рассеивания. Если точки пересекаются, то чтобы показать истинное распределение значений `jitter` добавляет "шум"

```{r}
ggplot(mpg) + 
  geom_point(
    mapping = aes(displ, hwy),
    position = "jitter"
  )
```

#### Упражнения 3.8.1 
<div class="question">
What is the problem with this plot? How could you improve it?

```{r}
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point()
```  
</div>

Это иллюстрация приведённой в книге проблемы **наложение графиков**. Все значения наносимые на график округляются - поэтому в одной точке может быть наложено несколько значений. Чтобы показать истинное количество точек в одном положении можно воспользоваться функцией `geom_jitter`, которой добавит случайный шум каждой точке.

```{r}
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_jitter()
```

#### Упражнения 3.8.2 
<div class="question">
What parameters to `geom_jitter()` control the amount of jittering?
</div>

Согласно описанию [`geom_jitter()`](https://ggplot2.tidyverse.org/reference/geom_jitter.html) есть два параметра для управления флуктуациями:

-   `width` для вертикального распределения
-   `height` для горизонтального распределения

Разберём на примере. Возьмём диаграмму рассеивания:

```{r}
 ggplot(mpg, aes(cty, hwy)) + geom_point()
```

Добавим флуктуаций:
```{r}
 ggplot(mpg, aes(cty, hwy)) + geom_jitter()
```

Отрегулируем умеренные флуктуации, установив значение параметров `width` и `height` равным $0,5$

```{r}
ggplot(mpg, aes(cty, hwy)) + geom_jitter(width = 0.5, height = 0.5)
```

#### Упражнения 3.8.3 
<div class="question">
Compare and contrast `geom_jitter()` with `geom_count()`.
</div>

Возьмём данные из предыдущего примера, в которых уже известно, что происходит наложение данных:

```{r}
 ggplot(mpg, aes(cty, hwy)) + geom_point()
```

```{r}
 ggplot(mpg, aes(cty, hwy)) + geom_jitter()
```

Теперь посмотрим что делает `geom_count()`

```{r}
 ggplot(mpg, aes(cty, hwy)) + geom_count()
```

Функция `geom_count()` тоже демонстрирует, что точки в построении накладываются. Но она делает это изящнее - в зависимости от количества точек, попавших в одно построение, увеличивается диаметр окружности. 

* Преимущество `geom_count()` - не изменяются координаты точек.
* Недостаток `geom_count()` - в зависимости от количества точек, радиус окружности может перекрывать рядом лежащие точки.

Впрочем, в этом случае можно использовать дополнительное выделение цветом:

```{r}
 ggplot(mpg, aes(cty, hwy, color = drv)) + geom_count()
```

#### Упражнения 3.8.4 
<div class="question">
What’s the default `position` adjustment for `geom_boxplot()`? Create a visualization of the `mpg` dataset that demonstrates it.
</div>

Согласно описанию функции `geom_boxplot()` значение по умолчанию у параметра `position = "dodge2"`.
Оба парамтера `"dodge"` и `"dodge2"` строят рядом перекрывающиеся объекты рядом. Разница в том, что `"dodge"` лепит их вплотную, а `"dodge2"` добавляет промежуток. Или не совсем...

```{r}
ggplot(diamonds) +
  geom_bar(
    mapping = aes(x = cut, fill = clarity),
    position = "dodge"
    )
```

```{r}
ggplot(diamonds) +
  geom_bar(
    mapping = aes(x = cut, fill = clarity),
    position = "dodge2"
    )
```

Пример для визуализации. 

```{r}
ggplot(mpg, aes(cty, hwy, color = drv)) + geom_boxplot()
```

Если использовать другое значение для `position`, то ящики будут накладываться друг на друга:

```{r}
ggplot(mpg, aes(cty, hwy, color = drv)) + geom_boxplot(position = "identity")
```

### Системы координат
#### Упражнения 3.9.1 
<div class="question">
Turn a stacked bar chart into a pie chart using `coord_polar()`
</div>

Хорошо, сначала построим стековую диаграмму:

```{r}
ggplot(mpg, aes(x = factor(1), fill = factor(cyl))) +
 geom_bar()
```

**РАЗОБРАТЬСЯ ЧТО ДЕЛАЕТ `factor()`**

Всё описание работы есть [`coord_polar()`](https://ggplot2.tidyverse.org/reference/coord_polar.html) поэтому я ограничусь здесь только выполнением задания.
В документации к построению "пирогов" сказано что, нужно относится к этим построениям максимально острожно, что коррелирует с тем, что говорится в [дизайне и  визуализации](https://lpgenerator.ru/blog/2015/11/27/pochemu-vam-luchshe-perestat-ispolzovat-krugovye-diagrammy-ili-net/)

```{r}
ggplot(mpg, aes(x = factor(1), fill = factor(cyl))) +
 geom_bar() + coord_polar(theta = "y")
```

Можно использовать пример из упражнений

```{r}
ggplot(diamonds) +
  geom_bar(
    mapping = aes(x = cut, fill = clarity),
    position = "fill"
    )
```


```{r}
ggplot(diamonds) +
  geom_bar(
    mapping = aes(x = cut, fill = clarity),
    position = "fill") +
    coord_polar(theta = "y")
```    

#### Упражнения 3.9.2 
<div class="question">
What does `labs()` do? Read the documentation.
</div>

Функция `labs()` нужна для подписей всего того что отображается на графике. Всё описание есть в хэлпе.

```{r}
ggplot(mpg) +
    geom_point(mapping = aes(displ, hwy, colour = drv)) +
    labs(color = "Новое название", 
         x = "Ось абсцисс",
         y = "Ось ординат",
         title = "Заголовок", 
         subtitle = "описание", 
         tag = "тэг")
```

#### Упражнения 3.9.3 
<div class="question">
What’s the difference between `coord_quickmap()` and `coord_map()`?
</div>

`Coord_map` проецирует часть земли, которая к слову является приблизительно сферической, на плоскую 2D-плоскость, используя любую проекцию, определенную пакетом `mapproj`. Карты, как правило, не сохраняют прямых линий, поэтому это требует значительных вычислений. Coord_quickmap - быстрое приближение, которое сохраняет прямые линии. Он лучше всего подходит для небольших площадей ближе к экватору.

По умолчанию, `coord_map()` использует [проекцию Меркатора](https://ru.wikipedia.org/wiki/Проекция_Меркатора).
Собственно в хэлпе больше информации с примерами. [ggplot](https://ggplot2.tidyverse.org/reference/coord_map.html)

#### Упражнения 3.9.4 
<div class="question">
What does the plot below tell you about the relationship between city and highway mpg? Why is `coord_fixed()` important? What does `geom_abline()` do?
</div>

```{r}
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point() + 
  geom_abline() +
  coord_fixed()
``` 
 
Функция `coord_fixed()` представляет количество единиц по оси Y, эквивалентное одной единице по оси X. Что в свою очередь гарантирует, что линия, созданная `geom_abline()`, имеет угол $45^{\circ}$. 45-градусная линия позволяет легко сравнить пробег по шоссе и городу с корпусом, в котором город и шоссе MPG были равны.

```{r}
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
  geom_point() + 
  geom_abline()
```

### Многослойная грамматика графики
Шаблон кода после всего пройденного материала выглядит следующим образом:
```
ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(
     mapping = aes(<MAPPINGS>),
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>
```

<!--chapter:end:01_data_visualisation.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
## Рабочий процесс: основы
```{r}
library("tidyverse")
library("viridis")
library("forcats")
library("nycflights13")
library("Lahman")
library("dplyr")
```
### Основы написания кода
Для вывода символа присвоения `<-` на MacBook, необходимо нажать комбинацию клавиш <option> + <-> (минус)
### Что представляют собой имена
`R` чувствителен к регистру.

### Вызов функций
Не было упражнений

#### Упражнение 4.4.1
<div class="question">
  Why does this code not work?
  
```{r, eval = FALSE}
my_variable <- 10
my_varıable
```

Look carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.)
</div>
  
  Код не работает, потому что допущена опечатка при вызове функции. Обратите внимание на `i`. Пишите без ошибок.

#### Упражнение 4.4.2
<div class="question">
```{r, eval = FALSE}
library(tidyverse)

ggplot(dota = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))

fliter(mpg, cyl = 8)
filter(diamond, carat > 3)
```
</div>
  
  Должно быть так. В названии библиотеки забыли кавычки `""`

```{r, eval = FALSE}
library("tidyverse")
```

При объявнлении исходных данных допущена ошибка. Вместо `data` написано `dota`

```{r, eval = FALSE}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```

В следующем примере пришлось чуть повозиться. Тут одновременно несколько ошибок. Вместо `filter()` написано `fliter()`. А при объявлении, нужно было правильно сравнивать вместо `=` надо `==`

```{r, eval = FALSE}
filter(mpg, cyl = 8)
```

И в последнем примере при объявлении фрейма данных допущена опечатка. Вместо `diamond` надо писать `diamonds`.
```{r, eval = FALSE}
filter(diamonds, carat > 3)
```

#### Упражнение 4.4.3
<div class="question">
  Press Alt + Shift + K. What happens? How can you get to the same place using the menus?
</div>
  
Это открывает меню шорт-катов, чтобы открыть его "вручну" нужно пройти по адресу `Tools -> Keyboard Shortcuts Help`.

<!--chapter:end:02_workflow_basics.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Преобразование данных с помощью пакета `dplyr`
### Введение
#### Используемые ресурсы

```{r}
library("tidyverse")
library("viridis")
library("forcats")
library("nycflights13")
library("Lahman")
library("dplyr")
```

Некоторые имена функций в разных библиотеках дублируются. Когда в `R` подключается несколько пакетов, в которых названия функций дублируются, программа выдает сообщение об ошибке

```{}
# ── Conflicts ─────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
# ✖ dplyr::filter() masks stats::filter()
# ✖ dplyr::lag()    masks stats::lag()
```

Для того чтобы обратится к необходимой функции, нужно использовать полное имя `stats::filter()`, `stats::lag()`

#### Пакет `nycflights13`

|Переменная  | Описание       |
| ---------- |:--------------:|
| `int`      | целые числа    |
| `dbl`      | числа с плавающей точкой    |
| `chr`      | символьные векторы или строки    |
| `dttm`     | дата + время    |
| `lgl`      | булевы векторы    |
| `fctr`     |факторы   |
| `date`     | даты    |

#### Основные сведения о пакете `dplyr`

Минимум для работы с этим пакетом:

|Функция       | Описание    |
| ------------ |:----------------------------------------------:|
| `filter()`   | выбор наблюдений по их значениям |
| `arrange()`  | перестановка строк |
| `select()`   | выбор переменных по их именам|
| `mutate()`   | создание новых переменных с использованием существующих|
| `summarize()`| сведение нескольких значений в одно итоговое |
| `group_by()` | изменяет область действия функции от всего набора данных до отдельных участков|

Все глаголы подчиняются одному и тому же синтаксису

1. Первый аргумент $-$ это фрейм данных

1. Последующие аргументы описывают действия, которые должны быть выполнены по отношению к фрейму данных.

1. Результат $-$ это новый фрейм данных

### Фильтрация строк с помощью функции `filter()`

Функция `filter()` позволяет что бы вы думали? позволяет фильтровать! Первым аргументом указываем фрейм данных, последующие аргументы, это параметры (столбцы) которые мы желаем отфильтровать через операторы сравнения.

```{r}
filter(flights, month == 1, day != 1)
```

Функция `filter()`, как и многие другие расширения пакета `dplyr`, не изменяют исходных данных. Желаемый фильтр нужно присвоить в новую переменную

```{r}
jan1 <- filter(flights, month == 1, day == 1)
```

Если нужно выполнить присвоение и вывод на экран, нужно обнять выражение скобками.

```{r}
(jan1 <- filter(flights, month == 1, day == 1))
```


#### Сравнения

Операторы сравнения стандартные `>`, `>=`, `<`, `<=`, `==`, `!=` 

Компьюьеры используют арифметику конечной точности. Поэтому

```{r}
sqrt(2) ^ 2 == 1
```

#### Логические операторы

Булевы операторы: И - `&`, ИЛИ - `|`, НЕ - `!`, исключающее ИЛИ - `xor()`.
Полный набор булевых операций показан на рисунке.

![alt text](img/transform-logical.png)

Что следует помнить. Добавляя булевы операторы в функцию `filter()` необходимо помнить, что сравнивать нужно программно, а не так как это звучит лексически. То есть, если мы хотим все авиарейсы отправленные в декабре и ноябре, нужно писать так.

```{r}
(filter(flights, month == 11 | month == 12))
```

Что дословно произносится как "отфильтровать все полёты из набора данных `flights`, вылетавших в месяце ноябре или в месяце декабре". Можно следовать лексическому соответствию, но для этого нужно использовать оператор `%in%`

```{r}
(filter(flights, month %in% c(11, 12)))
```

**Закон Моргана:**

* `!(x & y) == !x | !y`

* `!(x | y) == !x & !y`

Проверь на рисунке выше.

#### Отсутствующие значения

Функция `filter()` включает в вывод лишь те строки, для которых условие имеет значение `TRUE`. `FALSE` и `NA` исключаются.

Для того чтобы проверить является ли используемое значением отсутствующим можно использовать функцию `is.na()`

#### Упражнение 5.2.4.1 
<div class="question">
Найдите все авиарейсы, которые
</div>

* а) задержались с прилётом на два и более часа

```{r}
(arr_delay <- filter(flights, arr_delay >= 120))
```

* б) вылетали в Хьюстон (аэропорты IAH и HOU)

```{r}
(hou_flight <- filter(flights, dest == "IAH" | dest == "HOU"))
```

* в) Обслуживались авиакомпаниями United, American or Delta

Для того чтобы узнать аббревиатуры перевозчиков, смотрим `airlanes` в хэлпе

Получается: United - это `UA`, American - `AA`, Delta - `DL`. Тогда искомые данные это:

```{r}
(three_carriers <- filter(flights, carrier %in% c("UA", "AA", "DL")))
```

* г) Вылетали в летнее время (июль, август, сентябрь). Странное у них летнее время

```{r}
(sum_flights <- filter(flights, month %in% c(7, 8, 9)))
```

* д) Прилетали с опозданием более чем на два часа но не задерживались с вылетом

```{r}
(dep_arr_delay <- filter(flights, arr_delay > 120, dep_delay <= 0))
```

* е) Вылетали с задержкое не менее чем на час, но наверстывали более 30 минут во время полёта. Если полёт проходит ровно, то задержка отправления равна задержке прибытия. `Или dep_delay - arr_delay == 0`. Так как самолёт наверстал в пути, значит разница равна не нулю, она больше 30.

```{r}
(speedy_flights <- filter(flights, dep_delay >= 60, dep_delay - arr_delay > 30 ))
```

* ж) Вылетали между полуночью и 6 часами утра включительно

```{r}
(moon <- filter(flights, dep_time == 2400 | dep_time <= 600))
```

#### Упражнение 5.2.4.2 
<div class="question">
Another useful `dplyr` filtering helper is `between()`. What does it do? Can you use it to simplify the code needed to answer the previous challenges?
</div>

Из описания в хэлпе, функция `between()` это короткая запись для `>= left & x <= right`. Или если быть точным: `between(x, left, right)`. Конечно её гораздо удобнее использовать. Эту функцию можно применить к упражнению  *г*. Сравним:

```{r}
(sum_flights <- filter(flights, month %in% c(7, 8, 9)))
```

```{r}
(sum_flights <- filter(flights, between(month, 7, 9)))
```

#### Упражнение 5.2.4.3 
<div class="question">
How many flights have a missing `dep_time`? What other variables are missing? What might these rows represent?
</div>

```{r}
(filter(flights, is.na(dep_time)))
```

Ответ 8255 рейсов. Так же отсутствуют: `dep_delay`, `arr_time`, `arr_delay`. Вероятно это отменённые рейсы.

#### Упражнение 5.2.4.4 
<div class="question">
Why is `NA ^ 0` not missing? Why is `NA | TRUE` not missing? Why is `FALSE & NA` not missing? Can you figure out the general rule? (`NA * 0` is a tricky counterexample!)
</div>

1. `NA ^ 0 == 1`. Всё в точности с математикой, которая говорит, что любое значение в степени 0 == 1 или точнее $x^0=1$

1. `NA | TRUE`. Всё или ПРАВДА всегда правда :

| $a$ | $b$ | $a\lor b$ |
|:-:|:-:|:-:|
| 0 | 0 | 0 |
| 0 | 1 | 1 |
| 1 | 0 | 1 |
| 1 | 1 | 1 |

1. `FALSE & NA`. Всё и ЛОЖЬ всегда Ложь.

| $a$ | $b$ | $a\land b$ |
|:-:|:-:|:-:|
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 1 | 0 | 0 |
| 1 | 1 | 1 |

1. `NA * 0`. Причина по которой значение неопределено. Это то что умножение чего угодна на бесконечность, равно бесконечности, или правильнее - неопределённое значение. [нечисло](https://ru.wikipedia.org/wiki/NaN)


### Перестановка строк с помощью функции `arange()`

Синтаксис у этой функции такой же как у фильтра. `arranga()` сортирует по убыванию, а не фильтрует список. При этом отсутствующие значения всегда остаются в конце. При этом для сортировки по возрастанию используется функция `desc()`

#### Упражнение 5.3.1.1 
<div class="question">
How could you use `arrange()` to sort all missing values to the start? (Hint: use `is.na()`).
</div>

Берём пример из учебника.

```{r}
arrange(flights, desc(arr_delay))
```

Добавляем как подсказывают, функцию `is.na()`

```{r}
arrange(flights, desc(is.na(arr_delay)))
```

#### Упражнение 5.3.1.2
<div class="question">
Sort `flights` to find the most delayed flights. Find the flights that left earliest.
</div>

Чтобы найти рейсы с самыми большими задержками, сортируем по возрастанию соответствующий столбец `dep_delay`

```{r}
arrange(flights, desc(dep_delay))
```

Первые десять рейсов задерживались на время от 896 минут до 1301, это почти сутки (21 час) в аэропорте. Уффф.

Чтобы найти рейсы с самым ранним временем вылета, сортируем по убыванию соответствующий столбец `dep_time`

```{r}
arrange(flights, dep_time)
```

Ожидаемо, это время вылетов в полночь и минутой позднее.

#### Упражнение 5.3.1.3
<div class="question">
Sort `flights` to find the fastest flights.
</div>

Чтобы найти самые быстрые полёты, отсортируем все полёты по времени проведённому в воздухе. Это столбец `air_time` отсортированный по возрастанию.

```{r}
arrange(flights, air_time)
```

#### Упражнение 5.3.1.4
<div class="question">
Which flights traveled the longest? Which traveled the shortest?
</div>

Сделаем так, сначала отсортируем по расстоянию, а потом по времени проведённому в воздухе

```{r}
arrange(flights, desc(distance))
```

Самые длинные полёты из `JFK` в `HNL`. Из Нью-Йорка в Гонолулу - 4983 мили.

```{r}
arrange(flights, desc(distance))
```

[Полёт длится 691 минуту](https://www.google.com/maps/dir/Гонолулу+(HNL),+300+Rodgers+Blvd,+Honolulu,+HI+96819,+США/JFK+International+Airport,+New+York,+NY,+USA/@27.4344347,-126.6384014,4.03z/data=!4m14!4m13!1m5!1m1!1s0x7c006f943168f55f:0x7ed111b1cbf331df!2m2!1d-157.9250736!2d21.3245132!1m5!1m1!1s0x89c26650d5404947:0xec4fb213489f11f0!2m2!1d-73.7781391!2d40.6413111!3e4)


```{r}
arrange(flights, distance)
```

Самый короткий из `EWR` в `LGA`. Перелёт в пределах Нью-Йорка, который по всей видимости не состоялся, так как у него нету времени полёта. Следующий за ним это полёт из Нью-Арка в Филадельфию - 80 миль. Посмотрим ещё и по времени, проведённому в воздухе:

```{r}
arrange(flights, distance, air_time)
```

### Выбор столбцов с помощью функции `select()`

Функция `select()` помогает отобрать из фрейма данных необходимые столбцы. Синтаксис простой и привычный

* Указать конкретные столбцы можно через запятую 
```{r}
select(flights, year, month, day)
```

* Указать столбцы в промежутке
```{r}
select(flights, year:day)
```

* Выбрать всех столбцов за исключением тех, которые находятся между столбцами включая последние
```{r}
select(flights, -(year:day))
```

* `start_with("abc")` - соответствует именам, начинающимся с последовательности символов "abc"

* `end_with("abc")` - соответствует именам, заканчивающимся последовательностью символов "abc"

* `contains("abc")` - соответствует именам, содержащим последовательности символов "abc"

* `matches("(.)\\1")` - выбирает переменные, соответствующие регулярному выражению.

* `num_range("x", 1:3)` - соответствует `x1`, `x2`, `x3`

* Переименовать переменные, сохраняя все переменные не указанные в явном виде
```{r}
rename(flights, tail_num = tailnum)
```

* Переместить в начало переменные.
```{r}
select(flights, time_hour, air_time, everything())
```

#### Упражнение 5.4.1.1
<div class="question">
Brainstorm as many ways as possible to select `dep_time`, `dep_delay`, `arr_time`, and `arr_delay` from `flights`.
</div>


1. Указать конкретные столбцы через запятую
```{r}
select(flights, dep_time, dep_delay, arr_time, arr_delay)
```

1. Указать столбцы в промежутке и исключить лишние
```{r}
select(flights, dep_time:arr_delay, -sched_dep_time, -sched_arr_time)
```

1. Изощренный способ. Перенесём в начало нужные столбцы, отбросим лишние в промежутке
```{r}
new_flights <- select(flights, dep_time, dep_delay, arr_time, arr_delay, everything())
select(new_flights, -(year:time_hour))
```

1. Укажем номера столбцов
```{r}
select(flights, 4, 5, 6, 9)
```

1. Столбцы начинающиеся на `dep_` и `arr_`
```{r}
select(flights, starts_with("dep_"), starts_with("arr_"))
```

1. Столбцы содержащие и не содержащие
```{r}
select(flights, contains("_time"), contains("_delay"), -contains("sched"), -contains("air"))
```

#### Упражнение 5.4.1.2
<div class="question">
What happens if you include the name of a variable multiple times in a `select()` call?
</div>

Если одна и та же переменная указана несколько раз, она всё равно отобразится один раз
```{r}
select(flights, dep_time, dep_time, dep_time)
```

#### Упражнение 5.4.1.3
<div class="question">
What does the `one_of()` function do? Why might it be helpful in conjunction with this vector?
</div>

Функция `one_of()` берёт переменные в символьном векторе. Это может быть полезно, если как в примере у нас есть символьный вектор значений, которые необходимо взять

```{r}
vars <- c("year", "month", "day", "dep_delay", "arr_delay")
select(flights, one_of(vars))
```

#### Упражнение 5.4.1.4
<div class="question">
Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default?
</div>

```{r}
select(flights, contains("TIME"))
```

Удивительно, что `contains()` невосприимчив к регистру:

```{r}
select(flights, contains("time"))
```

Оказывается, это регшулируется параметром `ignore.case` который по умолчанию `TRUE`:

```{r}
select(flights, contains("TIME", ignore.case = FALSE))
```


Вот список всех функций, согласно хэлпу, невосприимчивых по умолчанию к регистру:

* `starts_with(match, ignore.case = TRUE, vars = peek_vars())`

* `ends_with(match, ignore.case = TRUE, vars = peek_vars())`

* `contains(match, ignore.case = TRUE, vars = peek_vars())`

* `matches(match, ignore.case = TRUE, vars = peek_vars())`

### Добавление столбцов с помощью функции `mutate()`

Функция `mutate()` позволяет добавлять в конец исходного фрейма данных столбцы. 

Сделаем чуть более показательный набор данных:
```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)
```


Теперь добавим в конец этого набора дополнительные вычисления
```{r}
mutate(flights_sml,
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
)
```

Чтобы сохранить только вычисления, без указания дополнительных столбцов, используется функция `transmute()`

```{r}
transmute(flights,
  gain = dep_delay - arr_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
```

#### Полезные функции создания объектов

* Арифметические операторы `+`, `-`, `*`, `/`, `^`

* Модулярная арифметика. Целочисленное деление - `%/%`. Взятие остатка - `%%`. Показательный пример:

```{r}
transmute(flights,
  dep_time,
  hour = dep_time %/% 100,
  minute = dep_time %% 100
)
```

* Логарифмические функции `log()`, `log2`, `log10()`

* Смещения. Вперёд - `lag()`. Назад - `lead()`

* Кумулятивные и скользящие агрегаты. `cumsum()`, `cummin()`, `cumprod()`, `cummax()`, `cummean()`

* Логические операторы `<`, `>`, `>=`, `<=`, `!=`

* Ранжирование. Функции ранжирования `row_number(x)`, `ntile(x, n)`, `min_rank(x)`, `dense_rank(x)`,`percent_rank(x)`, `cume_dist(x)`. В этих функциях `desc()` меняет направление.

#### Упражнение 5.5.2.1
<div class="question">
Currently `dep_time` and `sched_dep_time` are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight.
</div>

Заданные параметры `dep_time` and `sched_dep_time` записаны в формате HHMM. Чтобы получить из исходных данных последовательный формат, необходимо произвести целочисленное деление на 100, и к результату добавить остаток от деления.

```{r}
transmute(flights,
  dep_time,
  sched_dep_time,
  dep_time_minute = ((dep_time %/% 100) * 60) + dep_time %% 100,
  sched_dep_time_minute = ((sched_dep_time %/% 100) * 60) + sched_dep_time %% 100
)
```

Можно добавить эти значения в исходную выборку:
```{r}
mutate(flights,
  dep_time_minute = ((dep_time %/% 100) * 60) + dep_time %% 100,
  sched_dep_time_minute = ((sched_dep_time %/% 100) * 60) + sched_dep_time %% 100
)
```

#### Упражнение 5.5.2.2
<div class="question">
Compare `air_time` with `arr_time - dep_time`. What do you expect to see? What do you see? What do you need to do to fix it?
</div>

Значения данных `dep_time` и `arr_time` это время отправления и время прибытия соответственно записанные в формате HHMM. `air_time` - это время полёта, записанное в минутах. Естественно, если мы просто вычтем из времени прибытия время отправления в текущем формате, мы не получим `air_time`.

Таким образом, моё предположение сводится к следующему - чтобы разность `arr_time - dep_time` и `air_time` совпадали, необходимо:

1. для начала привести их к общей форме записи в минутах.

```{r}
transmute(flights,
  air_time,
  arr_minus_dep = (((arr_time %/% 100) * 60) + arr_time %% 100) - (((dep_time %/% 100) * 60) + dep_time %% 100)
)
```

1. затем необходимо учесть прилёт на другой день

1. и ещё необходимо учитывать разное время часовых поясов отлёта и прибытия, так как время в данных указано локальное

Так как два последних предположения текущим набором данных мне проверить не предвидится возможным, я заглядываю в подсказку

В имеющимся в сети [решении](https://jrnold.github.io/r4ds-exercise-solutions/data-transformation.html) заданий от пользователя jrnold я нашёл что, в своём предположении я не учёл особенность сбора данных. Особенность заключается в том, что время отправления и время прибытия считаются от момента когда самолёт оторвал шасси и коснулся земли соответсвенно. В это время не входит время проведённое при посадке и прохождении регистрации, которое учитано в `air_time`.

#### Упражнение 5.5.2.3
<div class="question">
Compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you expect those three numbers to be related?
</div>

Разберёмся в том, что каждый столбец данных представляет.

* `sched_dep_time` - это запланированное время вылета в формате HHMM по местному времени

* `dep_time` - это актуальное время вылета в формате HHMM по местному времени

* `dep_delay` - это время задержки вылета в минутах. Отрицательное время будет показывать ранний вылет.

То есть по сути `dep_delay` это разность между актуальным временем вылета и запланированным временем. Чтобы разность `dep_time - sched_dep_time` соотносилась с `dep_delay`, формат HHMM необходимо перевести в минуты.

```{r}
flights_new_dep <- mutate(flights,
  dep_delay_ng = dep_time - sched_dep_time,
  dep_delay_ok = (((dep_time %/% 100) * 60) + dep_time %% 100) - 
    (((sched_dep_time %/% 100) * 60) + sched_dep_time %% 100))
```

Однако подобный формат записи приводит к тому, что если вылет фактический и вылет планируемый находятся по разную сторону от полуночи, то разница будет большой либо в отрицательную, либо в положительную сторону. Что конечно же не соответствует фактическому времени задержки. 
Тут вроде бы `dep_delay` и полученный в результате приведения к одному формату и разности планируемого и фактического времени `dep_delay_ok` сходятся. Однако уже даже при обратной сортировке видно, что есть большие различия, связанные, как я уже сказал, с особенностью внесения этих данных:

```{r}
new_delay <- select(flights_new_dep, dep_delay_ok, dep_delay, dep_delay_ng)
arrange(new_delay, desc(dep_delay))
```

#### Упражнение 5.5.2.4
<div class="question">
Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for `min_rank()`.
</div>

Задрежка вылета `dep_delay`. Найти 10 авиарейсов, можно функцией `arrange()`

```{r}
(arrange(flights, desc(dep_delay)))
```

Но так мы возьмём все связанные данные.
Чтобы ограничить выдачу, можно использовать функцию `min_rank()`.
Я воспользуюсь этой функцией чтобы взять первые 10 авиарейсов по рангу.
Сначала посмотрим что делает `min_rank()`:

```{r}
(transmute(flights, dep_delay_rank = min_rank(-dep_delay)))
```

Теперь добавим к имеющемуся набору данных новых столбуц с обратным ранжированным столбцом `dep_delay()`

```{r}
(flights_delayed <- mutate(flights, dep_delay_rank = min_rank(-dep_delay)))
```

Затем возьмём первые 10 значений:
```{r}
(filter(flights_delayed, dep_delay_rank <= 10))
```

#### Упражнение 5.5.2.5
<div class="question">
What does `1:3 + 1:10` return? Why?
</div>

```{r}
1:3 + 1:10
```

Это возвращает такой странный результат, потому что при складывании двух векторов разной длинны, происходит "дополнение" длинного вектора, повторением сначала значениями короткого. Проще говоря: `c(1 + 1, 2 + 2, 3 + 3, 1 + 4, 2 + 5, 3 + 6, 1 + 7, 2 + 8, 3 + 9, 1 + 10)`

#### Упражнение 5.5.2.6
<div class="question">
What trigonometric functions does R provide?
</div>

В R есть следующие тригонометрические функции.

* Простые: `cos(x)`, `sin(x)`, `tan(x)`

* Арки `acos(x)`, `asin(x)`, `atan(x)`, `atan2(y, x)`

* И ещё `cospi(x)`, `sinpi(x)`, `tanpi(x)`

### Получение групповых итогов с помощью функции `summarize()`
#### Объединение нескольких операций с помощью канала
Мы хотим исследовать связь между расстоянием `distance` и средним временем задержки рейса `arr_delay` для всех пунктов приема и вылета.

Для этого необходимо.

1. Группирование рейсов по пунктам назначения

```{r}
by_dest <- group_by(flights, dest)
```

1. Получение сводных данных (суммарных), касающихся расстояний `distance`, среднего времени задержки `mean(arr_delay)` и количества авиарейсов `count()`.

```{r}
delay <- summarise(by_dest,
  count = n(),
  dist = mean(distance, na.rm = TRUE),
  delay = mean(arr_delay, na.rm = TRUE)
)
```

1. Фильтрация данных с целью исключения точек данных, создающих информационный шум, и аэропорта Гонолулу `NHL`, который распологется на расстоянии, почти вдвое превышающем расстояние до следующего ближайшего аэропорта.

```{r}
delay <- filter(delay, count > 20, dest != "NHL")
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
    geom_point(aes(size = count), alpha = 1/3) +
    geom_smooth(se = FALSE)
```

Это решение, но такой код трудно писать, поскольку нужно присваивать каждому промежуточному фрейму данных отдельное имя.
Есть такая штука как канал `%>%`. Канал фактически позволяет говорить "затем". 

Сначала сгруппируй %>% (затем) просуммируй по количеству значений и посчитай среднее в группах по `distance` и `arr_delay` %>% (затем) отфильтруй. Получаются все те же самые блоки, только без промежуточных присваиваний имён.

```{r}
delays <- flights %>%
  group_by(dest) %>%
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>%
  filter(count > 20, dest != "NHL")
```

#### Отсутствующие значения

Я предполагал, что параметр `na.rm` отвечает за нормальное распределение. Но это было неверное предположение. Разберём пример.

Если суммировать число с пропущенным значением (неизвестным), результат будет тоже неизвестным:

```{r}
1 + NA
```

Параметр `na.rm` отвечает за пропущенные значения. Точнее за игнорирование пропущенных значений. 

```{r}
flights %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay))
```

```{r}
flights %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay, na.rm = TRUE))
```

В последующем будет использоваться этот срез данных, так что здесь же объявим его:

```{r}
not_canceled <- flights %>%
  filter(!is.na(dep_delay), !is.na(arr_delay))
not_canceled %>%
  group_by(year, month, day) %>%
  summarise(mean = mean(dep_delay))
```

#### Счетчики

Счётчик наблюдений это `n()`. Счетчик отсутствующих значений это `sum(!is.na(x))`.
Проведём лабораторную работу.

Предположим что нас интересуют самолёты с наибольшим средним временем задержки.

```{r}
delays <- not_canceled %>%
  group_by(tailnum) %>%
  summarise(delay = mean(arr_delay))
ggplot(delays, aes(x = delay)) + geom_freqpoly(binwidth = 10)
```

Такой график показывает распределение, почти как гистограммы, только  вместо столбцов тут линии. Как и в гистограммах, такие графики показывают количество наблюдений, попавших в заданный диапазон. Постройнный график имеет диапазон 10. Поиграемся немного:

Установив значение диапазона 1 - получаем "зашумлённый" график
```{r}
ggplot(delays, aes(x = delay)) + geom_freqpoly(binwidth = 1)
```

Устанавливая значение диапазона = 100, получаем график в котором потеряно много ценной информации, график получился переглаженным
```{r}
ggplot(delays, aes(x = delay)) + geom_freqpoly(binwidth = 100)
```

Соответственно 1000 не даёт понять даже общую тенденцию, потому что крайние точки выборки, находятся далеко от 1000.
```{r}
ggplot(delays, aes(x = delay)) + geom_freqpoly(binwidth = 1000)
```

Но вернёмся к нашему распределению с диапазоном в 10 точек. Можно посмотреть под другим углом на эти данные если построить диаграмму рассеяния:

```{r}
delays <- not_canceled %>%                  # Присвой значению `delays` данные `not_canceled` ЗАТЕМ
  group_by(tailnum) %>%                     # Сгруппируй эти данные по номерам самолётов ЗАТЕМ
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),  # Посчитаем среднее значение по параметру `arr_delay`, не учитывая пропуски
    n = n()                                 # Со счётчиком количества наблюдений
  )
ggplot(delays, aes(x = n, y = delay)) +     # Построим точечную диаграмму рассеяния количества наблюдений от времени задержки
  geom_point(alpha = 1/10)                  # Точки сделаем прозрачными
```

На этой диаграмме видно, что хвост у основного распределения длинный. Тоесть от основного количества точек в "районе" нуля есть единичные выбросы вплоть до 300 по оси ординат `delay`. Часто от такого хвоста, то есть выбросов, необходимо будет избавляться. 
Как советуют в книге, помогает в этом использование пакета `ggplot` в потоке `dplyr`.

```{r}
delays %>%                                   # Возьми данные `delays` ЗАТЕМ
  filter(n > 25) %>%                         # отфильтруй группы, в которых количество наблюдений меньше `25` ЗАТЕМ
  ggplot(mapping = aes(x = n, y = delay)) +  # Построй точечную диаграмму `n` от `delay`. Точки сделай прозрачными на 1/10.
  geom_point(alpha = 1/10)
```

Рассмотрим связь между средней результативностью отбивающих в бейсболе и количеством их вызовов на удар.

```{r}
batting <- as_tibble(Lahman::Batting)      # Из большого набора данных `Lahman` возьми фрейм данных `Batting`.

batters <- batting %>%                     # Присвой переменной `batters` значение `batting` ЗАТЕМ
  group_by(playerID) %>%                   # группируй данные по ID игрока ЗАТЕМ
  summarise(                               # посчитай средний коэффициент результативности
    ba = sum(H, na.rm = TRUE) / sum (AB, na.rm = TRUE),     
    ab = sum(AB, na.rm = TRUE)             # Определи суммарное количество возможностей выполнить удар `ab`. 
  )

batters %>%                                # Возьми данные `batters` ЗАТЕМ
  filter(ab > 100) %>%                     # Возьми данные с количеством возможностей на удар больше 100 ЗАТЕМ
  ggplot(mapping = aes(x = ab, y = ba)) +  # Построй диаграмму рассеяния возможностей удара от от коэффициента результативности
  geom_point() +
  geom_smooth(se = FALSE)                  # А так же сглаженную прямую без построения доверительного интервала
```

Средний коэффициент результативности - суммарное количество ударов, делённое на суммарное количество возможностей сделать удар?. 

Этот график показывает положительную зависимость коэффициент результативности от количества ударов.

Тут есть одна закономерная интересность - чем меньше количество наблюдений, тем существеннее влияет единичное наблюдение на среднее значение. Следствием этого утверждения является тот факт, что самые высокие коэффициенты у тех кому просто повезло разочек ударить по мячу и больше не вызываться к отбиванию:

```{r}
batters %>%
  arrange(desc(ba))
```

#### Полезные итоговые функции

* Меры положения - `mean(x)`, `median(x)`

* Меры изменчивости - среднеквадратичное отклонение `sd()`, межквартильный размах - `IQR()`, медианное абсолютное отклонение - `mad()`

* Меры ранжирования - максимум `max(x)`, минимум`min(x)`, квантиль 25% `quantile(x, 0,25)`, квантиль 75% `quantile(x, 0,75)`

* Порядковые меры - первый `first(x)`, последний `last(x)`, точная позиция `nth(x, 2)`

* Счетчики - размер текущей группы `n()`, количество значений не являющихся отсутствующими `sum(!is.na(x))`, количество уникальных значений`n_distinct(x)`

* Подсчет количества и долей логических значений `sum(x > 10)`, `mean(y == 0)`

#### Группирование по нескольким переменным
Когда мы группируем данные по нескольким переменным, каждый сформированный итог уменьшает колтчество уровней группировки на единицу. Это упрощает последовательное свёртывание.

```{r}
daily <- group_by(flights, year, month, day)
(per_day <- summarize(daily, flights = n()))
(per_month <- summarize(per_day, flights = sum(flights)))
(per_year <- summarise(per_month, flights = sum(flights)))
```

Буду аккуратен когда буду свёртывать например медианы. Сумма групповых сумм равна общей сумме, но медиана групповых медиан не равна общей медиане.

#### Разгруппирование
Тут всё просто - нужно что-то разгруппировать, пользуемся функцией `ungroup()`

```{r}
daily %>%
  ungroup() %>%            # больше не группировать по дате
  summarize(flights = n()) # все рейсы
```

#### Упражнение 5.6.7.1
<div class="question">

Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios:

* A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time.

* A flight is always 10 minutes late.

* A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time.

* 99% of the time a flight is on time. 1% of the time it’s 2 hours late.

Which is more important: arrival delay or departure delay?
</div>

Разобьём ответ на части.

* Часть 1. Вначале напридумываем как минимум пять типичных характеристик времени задержки для групп авиарейсов:

1. Мера положения - *среднее время* задержки вылета самолёта

2. Мера положения - *среднее время* задержки прилёта самолёта

3. Мера изменчивости - *среднеквадратичное отклонение* времени задержки вылета самолёта

4. Мера изменчивости - *среднеквадратичное отклонение* времени задержки прилёта самолёта

5. Мера ранжирования - *максимальное* время задержки вылет самолёта

6. Мера ранжирования - *максимальное* время задержки прилёта самолёта

Далее будем придумывать способы доступа к придуманным характеристикам. Группировать будем по дню вылета. В зависимости от задачи, группировать можно по разным параметрам - аэропорт прилёта, аэропорт вылета, время в пути, по любому доступному временному срезу, по номеру авиарейса.

*Cреднее время* задержки вылета самолёта
```{r}
dep_delay_mean <- flights %>%                                # Присвой в dep_delay_mean значения из набора данных flights ЗАТЕМ
  group_by(year, month, day) %>%                             # Сгруппируй по дням прилёта
  summarise(dep_mean = mean(dep_delay, na.rm = TRUE))        # В dep_mean посчитай среднее время задержки вылета
ggplot(dep_delay_mean) +                                     
    geom_smooth(mapping = aes(day, dep_mean), se = FALSE) +  # Построй прямые по дням без стандартного отклонения
    facet_wrap(~ month, nrow = 3)                            # Сгруппируй построения по месяцам в три строки
```

*Cреднее время* задержки прилёта самолёта
```{r}
arr_delay_mean <- flights %>% 
  group_by(year, month, day) %>%                           
  summarise(arr_mean = mean(arr_delay, na.rm = TRUE))        
ggplot(arr_delay_mean) +                                     
    geom_smooth(mapping = aes(day, arr_mean), se = FALSE) +  
    facet_wrap(~ month, nrow = 3)                            
```

*Cреднеквадратичное отклонение* времени задержки вылета самолёта
```{r}
arr_delay_sd <- flights %>%                               
  group_by(year, month, day) %>%       
  summarise(arr_sd = sd(arr_delay, na.rm = TRUE))      
ggplot(arr_delay_sd) +                                     
    geom_smooth(mapping = aes(day, arr_sd), se = FALSE) +  
    facet_wrap(~ month, nrow = 3)                   
```

*Cреднеквадратичное отклонение* времени задержки прилёта самолёта
```{r}
dep_delay_sd <- flights %>%     
  group_by(year, month, day) %>%                    
  summarise(dep_sd = sd(dep_delay, na.rm = TRUE))     
ggplot(dep_delay_sd) +                                     
    geom_smooth(mapping = aes(day, dep_sd), se = FALSE) +  
    facet_wrap(~ month, nrow = 3)                         
```

*Максимальное* время задержки вылета самолёта
```{r}
dep_delay_max <- flights %>%               
  group_by(year, month, day) %>%         
  summarise(dep_max = max(dep_delay, na.rm = TRUE))        
ggplot(dep_delay_max) +                                     
    geom_smooth(mapping = aes(day, dep_max), se = FALSE) + 
    facet_wrap(~ month, nrow = 3)
```

*Максимальное* время задержки прилета самолёта
```{r}
arr_delay_max <- flights %>%               
  group_by(year, month, day) %>%         
  summarise(arr_max = max(arr_delay, na.rm = TRUE))        
ggplot(arr_delay_max) +                                     
    geom_smooth(mapping = aes(day, arr_max), se = FALSE) + 
    facet_wrap(~ month, nrow = 3)
```

* Часть 2 Рассмотрим предложенные сценарии

- Я буду группировать по номеру авиарейса, перевозчику, пункту вылета и пункту назначения. Делаю так, посколько номер авиарейса в данном наборе данных не является уникальным. Под одним номером, в зависимости от перевозчика могут авиарейсы с разными пунктами вылета и назначения
Итак, авиарейсы, опережающие график на 15 минут в 50% случаев. Таких рейсов немного:

```{r}
fast <- not_canceled %>%                          # присвой в fast фрейм данных not_canceled (это flights без пропусков)
  group_by(flight, carrier, origin, dest) %>%     # сгруппируй по номеру полёта, аэропорту вылета и аэропорту прилёта
  summarise(fast_15min = mean(dep_delay == -15))  # посчитай долю рейсов, которые опережали график на 15 минут
filter(fast, fast_15min == 0.5)                   # отфильтруй рейсы, у которых задержка 15 минут составляет 50% от всех случаев
```

- Поиск авиарейсов, опаздывающих на 15 минут в 50% случаев, отличается только знаком в задержке вылета

```{r}
slow <- not_canceled %>%
  group_by(flight, carrier, origin, dest) %>%
  summarise(slow_15min = mean(dep_delay == 15))
filter(slow, slow_15min == 0.5)
```

- Авиарейсы, которые постоянно опаздывают на 10 минут

```{r}
instant_slow <- not_canceled %>%                     # Постоянно опаздывающие, означает, что доля вылетов с опозданием
  group_by(flight, carrier, origin, dest) %>%        # в 10 минут, дл таких рейсов равна 100%
  summarise(inst_slow_10min = mean(dep_delay == 10))
filter(instant_slow, inst_slow_10min == 1) 
```

- Авиарейсы, опережающие график на 30 минут в 50% случаев (таких нету)

```{r}
fast_30 <- not_canceled %>%
  group_by(flight, carrier, origin, dest) %>%
  summarise(fast_30min = mean(dep_delay == -30))
filter(fast_30, fast_30min == 0.5)
```

- Авиарейсы, опаздывающие на 30 минут в 50% случаев

```{r}
slow_30 <- not_canceled %>%
  group_by(flight, carrier, origin, dest) %>%
  summarise(slow_30min = mean(dep_delay == 30))
filter(slow_30, slow_30min == 0.5)
```


- Авиарейсы, которые в 99% случаев укладывались в график и в 1% случаев опаздывали на 2 часа

```{r}
interest_flight <- not_canceled %>%                  # Так как условия два, поэтому и параметра будем вводить два
  group_by(flight, carrier, origin, dest) %>%        # то и критерия будет два
  summarise(interest1 = mean(dep_delay == 120),      # Первый для условия в 1% с опозданием на два часа
            interest2 = mean(dep_delay == 0))        # Второй для условия в 99% со своевременным вылетом
filter(interest_flight, interest1 == 0,01, interest2 == 0,99) 
```

* Часть 3 Отвечаю на вопрос о более важном факторе

Для ответа на тот вопрос необходимо определить критерии оценки.

С одной стороны, если говорить о своевременности предоставляемых данных, то задержка прилёта несёт больший урон. Поскольку находясь в воздухе, пассажир не сможет предупредить кого-то о своей задержке (в случае деловой встречи, например) и от пассажира в воздухе ничего не зависит. Получив информацию о том, что рейс задерживает вылет ещё на земле, пассажир может скоординировать свои планы, поменять в конце концов способ перемещения.

#### Упражнение 5.6.7.2
<div class="question">
Come up with another approach that will give you the same output as `not_canceled %>% count(dest)` and `not_canceled %>% count(tailnum, wt = distance)` (without using `count()`).
</div>

Для вывода количества значений используется счётчки `count()` входящий в пакет `dplyr`. Можно обойти и просуммировать другими доступными средствами, например используя функцию `sum(!is.na(x)`, которая считает количество различных  уникальных значений.
```{r}
not_canceled %>%                          # в наборе данных
  group_by(dest) %>%                      # сгруппируй по направлению вылета
  summarise(sum_dest = sum(!is.na(dest))) # создай переменную в которую просуммируй уникальные значения по направлениям
```

или можно посчитать через счётчик `n()`, что видится более изящным решением, и делает код более читаемым.
```{r}
not_canceled %>%
  group_by(dest) %>%
  summarise(sum_dest = n())
```

Чтобы посчитать сумму по всем перемещениям из второго условия, достаточно сделать следующее:
```{r}
not_canceled %>%
  group_by(tailnum) %>%
  summarise(sum_dist = sum(distance))
```

#### Упражнение 5.6.7.3
<div class="question">
Our definition of cancelled flights (`is.na(dep_delay) | is.na(arr_delay)` ) is slightly suboptimal. Why? Which is the most important column?
</div>

Потому что мы берём и те рейсы у которых нет данных о задержки вылета, и те рейсы у которых нет данных о задержки прилёта. Во второе множество могут попасть самолёты, у которых был вылет. Таким образом, фактически такой рейс неправильно называть отменённым. Определяющим столбцом в этом случае будет время в полёте, если нет информации и о времени полёта, то с большей вероятностью этот рейс отменили.
В довесок, лучше заменить логическое ИЛИ на логическое И:

```{r}
filter(flights, is.na(dep_delay) & is.na(arr_delay))
```

Таким образом, выражение выше, больше похоже на отменённые рейсы

#### Упражнение 5.6.7.4
<div class="question">
Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay?
</div>

Это была задача на внимательность. Сначала я искал закономерности в наборе данных `not_canceled`. И естественно у меня не получалось найти отменённые рейсы, поскольку набор данных `not_canceled` изначально не содержит пропущенных значений. Остальное дело техники:

```{r}
canceled_delayed <- flights %>%                                # Присвой результаты в переменную
  mutate(canceled = (is.na(dep_delay) & is.na(arr_delay))) %>% # Добавь параметр отменённых рейсов
  group_by(year, month, day) %>%                               # Сгруппируй по дате
    summarise(
      prop_canceled = mean(canceled),                          # Посчитай долю отмененных рейсов
      avg_dep_delay = mean(dep_delay, na.rm = TRUE))           # Посчитай среднее время задержки

ggplot(canceled_delayed, aes(avg_dep_delay, prop_canceled)) +  # Построй график для иллюстрации зависимости
  geom_point() +
  geom_smooth()
```

Как видно на приведённом графике, зависимость между отменёнными авиарейсами и сдреним временем задержки есть - она прямая и близка к линейной

Интересно, как сильно на график влияет выбор оси ординат:
```{r}
ggplot(canceled_delayed, aes(prop_canceled, avg_dep_delay)) +
  geom_point() +
  geom_smooth()
```

#### Упражнение 5.6.7.5
<div class="question">
Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about `flights %>% group_by(carrier, dest) %>% summarise(n())`)
</div>

Что является задержкой? задержка вылета или задержка прилёта? Так как однозначного ответа нет, я буду использовать задержку вылета `dep_delay`.

```{r}
flights %>%
  group_by(carrier) %>%
  summarise(
    dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  arrange(desc(dep_delay))
```

Перевозчик `F9` чаще остальных допускал задержки.

Разделить эффекты плохих перевозчиков и плохих аэропортов можно. 
Если плохой *аэропорт*, то у всех перевозчиков будут задержки в этом аэропорте.
Если плохой *перевозчик*, то в сравнении с другими перевозчиками, у него будет выше средняя задержка в каждом аэропорте.
Возможно ли это? Да возможно.



Код из подсказки считает количество рейсов который каждый перевозчик совершил в конкретный аэропорт:

```{r}
flights %>%    
  group_by(carrier, dest) %>% 
  summarise(count = n())
```

Можно найти количество рейсов, который совершил каждый перевозчик по маршруту. Для этого надо добавить аэропорт вылета и изменить порядок группировки:
```{r}
flights %>%    
  group_by(origin, dest, carrier) %>% 
  summarise(count = n(),
            dep_delay = mean(dep_delay, na.rm = TRUE))%>%
  arrange(origin, dest, dep_delay)
```
 С этим уже можно работать. Я бы построил по каждому направлению вылета, столбчатую диаграмму, высота которой определялась бы параметром `dep_delay` и соответствовала каждому перевозчику. Но пока не могу придумать как это лучше сделать. Хотя в принципе и с этой информацией уже можно работать.

#### Упражнение 5.6.7.6
<div class="question">
Подсчитайте для каждого воздушного судна количество авиарейсов, совершенных до первой задержки более чем на 1 час.
</div>

```{r}
not_canceled %>%                                      # Будем брать те судна, у которых состоялся полёт
  group_by(tailnum, carrier) %>%                      # Воздушное судно определяется номером самолёта 
  summarise(                                          # и перевозчиком
    n_first_hour = sum(dep_delay >= 60)) %>%          # Количество авиарейсов с условием dep_delay >= 60
  arrange(desc(n_first_hour))                         # Самые неопаздывающие судна и перевозчики
```

#### Упражнение 5.6.7.7
<div class="question">
What does the `sort` argument to `count()` do. When might you use it?
</div>

Аргумент `sort` если он `TRUE`, сортирует в порядке убывания. Сортировка очень часто используется. Взять к примеру предыдущие упражнения.

### Групповое видоизменение (и фильтрация)

Группировку полезно сочетать не только с `summerise()` но так же с `filter()` или `mutate()`:

* Найти члены каждой группы имеющие наихудшие показатели

```{r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time)

flights_sml %>% 
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

* Найти все группы которым соответствует превышение порогового значения

```{r}
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests
```

* Стандартизировать для вычисления метрик групп

```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

#### Упражнение 5.7.1.1
<div class="question">
Refer back to the table of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping.
</div>

Они работают для каждого параметра по отдельности, а не по всему фрейму данных. Например среднее будет вычислять среднее значение в каждой группе.

#### Упражнение 5.7.1.2
<div class="question">
Which plane (`tailnum`) has the worst on-time record?
</div>

```{r}
not_canceled %>%                  # беру состоявшиеся рейсы
  group_by(tailnum) %>%           # группирую по номеру самолёта
  summarise(
    worst = mean(arr_delay)) %>%  # подсчитываю в группе среднее время задержки прибытия
  arrange(desc(worst))            # сортирую список по убыванию
```

#### Упражнение 5.7.1.3
<div class="question">
What time of day should you fly if you want to avoid delays as much as possible?
</div>

Так как есть две задержки, есть два пути осмысления того, какое время считать благоприятным для вылета.
Если рассуждать исходя из времени задержки вылета, то мы не будем знать, сколько времени самолёт проведёт в воздухе. В свою очередь нулевая задержка прилёта, говорит о том, что даже если самолёт опаздал с вылетом, он прибыл во время.

Я буду считать по времени прилёта.

```{r}
not_canceled %>%                     # считаем по состоявшимся рейсам
  group_by(hour) %>%                 # Группируем по запланированному времени вылета
  summarise(
    best_time = mean(arr_delay)) %>% # считаем среднее время задержки прибытия в каждой часовой группе
  arrange(best_time)                 # сортируем итог по возрастанию
```

Для ответа, вероятнее всего нужна была одна цифра - время вылета. Но, чтобы иметь более широкое представление я покажу в порядке убывания "лучшести", благоприятные часы вылета.

#### Упражнение 5.7.1.4
<div class="question">
For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.
</div>


```{r}
not_canceled %>%              # Берём состаявшиеся рейсы
  filter(arr_delay > 0) %>%   # Берём только рейсы с задержками
  group_by(dest) %>%          # Сортируем по направлению вылета
  mutate(                     
    zad = sum(arr_delay)) %>% # Добавляем в выборку параметр суммарной задержки рейса
  group_by(flight) %>%        # Группируем по номеру судна
  mutate(                
    fu = mean(zad)) %>%       # Добавляем в выборку параметр средней задержки рейса
  arrange(fu)                 # Сортируем данные по возрастанию средней времени задержки рейса
```

#### Упражнение 5.7.1.5
<div class="question">
Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using `lag()` explore how the delay of a flight is related to the delay of the immediately preceding flight.
</div>

Следующий код, показывает задержку вылета из того же аэропорта. Похоже на расписание вылетов из каждого аэропорта.
```{r}
(lagged_delays <- flights %>%                       # Берём исходный набор данных
  arrange(origin, year, month, day, dep_time) %>%   # Сортируем по возрастанию с указанным порядком
  group_by(origin) %>%                              # Группируем по пункту назначения
  mutate(dep_delay_lag = lag(dep_delay)) %>%        # Добавляем временное смещение
  filter(!is.na(dep_delay), !is.na(dep_delay_lag))) # Убираем отсутствующие значения
```


```{r}
lagged_delays %>%                                       # Берём набор данных с указанными задержками вылета
  group_by(dep_delay_lag) %>%                           # Группируем по временному смещению
  summarise(
    dep_delay_mean = mean(dep_delay)) %>%               # Считаем среднюю задержку
  ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) +  # Строим диаграмму рассеяния и сглаженную прямую
  geom_point() +
  geom_smooth() +
  labs(                                                 # Задаём названия осям
    y = "Задержка вылета, мин", 
    x = "Предыдущая задержка вылета, мин")
```


#### Упражнение 5.7.1.6
<div class="question">
Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?
</div>

Мой изначальный код:
```{r}
flights %>%
  group_by(origin, dest) %>%
  mutate(n = mean(air_time, na.rm = FALSE),
         fu = air_time - n) %>%
  filter(fu < 0) %>%
  arrange(fu) %>%
  select(-(day:carrier))
```

Я хотел просто посмотреть отклонение от среднего. Однако такой подход в корне неверен. Да и к тому же, я исключал отсутствующие значения только на этапе подсчёта среднего, а их необходимо было удалить сразу.
Изначально я хотел подсчитать средеквадратичное отклонение, но профакапился.

Модифицированный код, который я подсмотрел, основан на [z-Оценка](https://ru.wikipedia.org/wiki/Z-оценка), или другими словами стандартное отклонение. Стандартное отклонение, считается по формуле: ${\displaystyle z={x-{\bar {X}} \over S_{x}}}$

```{r}
flights %>%                                                # Берём все полёты
  filter(!is.na(air_time)) %>%                             # Исключаем отсутствующие значения
  group_by(origin, dest) %>%                               # Группируем по паре место вылета, место назначения
  mutate(air_time_mean = mean(air_time),                   # Добавляем в набор данных, параметр средного значения
         air_time_sd = sd(air_time),                       # Так же добавляем среднеквадратичное отклонение
         n = n()) %>%                                      # Добавляем счётчик рейсов
  ungroup() %>%                                            # Ангруппим чтобы вернуться к исходным данным, но с новыми параметрами
  mutate(z = (air_time - air_time_mean) / air_time_sd) %>% # Считаем стандартное отклонение
  arrange(z) %>%                                           # Сортируем по возрастанию стандартного отклонения
  select(-(day:carrier))                                   # Убираем "лишнее" при выводе в консоль
```

#### Упражнение 5.7.1.7
<div class="question">
Find all destinations that are flown by at least two carriers. Use that information to rank the carriers.
</div>

```{r}
flights %>%                                        # ЧАСТЬ 1. Берём все перелёты
  select(carrier, dest) %>%                        # Отбираем только направления и перевозчиков
  group_by(dest, carrier) %>%                      # Группируем по направлениям и перевозчикам
  filter(row_number() == 1) %>%                    # Ранжируем и берём только первые элементы
  group_by(dest) %>%                               # Группируем полученный список по направлениям
  mutate(n_carrier = length(unique(carrier))) %>%  # Добавляем столбец, с количеством уникальных элементов
  filter(n_carrier >= 2) %>%                       # Берём только те что имеют два и более перевозчика
  group_by(carrier) %>%                            # ЧАСТЬ 2. Группируем по перевозчикам
  summarise(n_dest = n()) %>%                      # Считаем количество пунктов назначения у каждого перевозчика
  arrange(desc(n_dest))                            # Сортируем перевозчиков по максимальному кол-ву пунктов назначения
```

<!--chapter:end:03_data_transformation.Rmd-->

---
editor_options: 
  chunk_output_type: console
output: html_document
---

## Организация рабочего процесса: скрипты

Здесь советуют юзать шорт-каты и окно скриптов.
Это забавно, потому что я с момента открытия книги использую R.markdown файлы, для ведения документа обучения.

```{r}
library("tidyverse")
library("viridis")
library("forcats")
library("nycflights13")
library("Lahman")
```

### Выполнение кода
Здесь снова советуют юзать шорт-каты. Спасибо, на самом деле очень своевременно. Без иронии.

А так же автор книги приучает к правилам хорошего тона - не вставлять в скрипты исполняющие на чужом компьютере строки кода типа скачивания пакетов `install.packeges()` или установки рабочей директории`setwd()`.

### Диагностические средства RStudio

Ошибки и предупреждения видны в окне исполнения скриптов.

#### Упражнение 6.3.1
<div class="question">
Go to the RStudio Tips twitter account, [https://twitter.com/rstudiotips](https://twitter.com/rstudiotips) and find one tip that looks interesting. Practice using it!
</div>

На самом деле, много интересных трюков - использование окна скрипта как в Vim для быстрого редактирования столбиком

Например, есть такое окно

```{}
А
А
А
А
```

нужно зажать "Option" на Маке, и "Alt" на Винде, курсор станет крестиком, необходимо выделить нужный столбец и можно редактировать сразу на всю строку. Это очень удобно.

```{}
"А", %>%
"А", %>%
"А", %>%
"А", %>%
```

А чтобы всё выстроить в линию, достачно сделать удаление после курсора - на маке комбинация клавиш `fn`+`delete`, на винде просто `bacspace`.

```{}
"А", %>% "А", %>% "А", %>% "А", %>%
```

Огонь просто.

#### Упражнение 6.3.2
<div class="question">
What other common mistakes will RStudio diagnostics report? Read [Code diagnostics](https://support.rstudio.com/hc/en-us/articles/205753617-Code-Diagnostics) to find out.
</div>

1. Проверка отсутствия, несогласованности, частично согласованности и большого количества аргументов для функций

1. Предупреждение, если переменная не определена

1. Предупреждение, если переменная определена, но не используется

1. [Hadley Wickham’s style guide](http://adv-r.had.co.nz/Style.html)

1. [Format R code automatically by Yihui Xie](http://yihui.name/formatr/)

1. А так же божественные комментарии об ошибках


Несколько советов от бати, собственно они применимы ко всей деятельности, и с ними я не раз сталкивался:

* Комментируй код. В комменте пиши "Почему", а не "Что".

* Не пиши в коде строку длиннее чем 80 символов. Тупо неудобно бегать по строке долго глазами. Позаботься о том, кто возможно будет читать твой код.

<!--chapter:end:04_workflow_scripts.Rmd-->

---
editor_options: 
  chunk_output_type: console
output: html_document
---

## Предварительный анализ данных
### Введение

По сути ПАД --- итеративный процесс, включающий три стадии

1. Формулирование вопросов относительно данных

1. Поиск ответов на поставленные вопросы путем их визуализации, преобразования и моделирования данных

1. Использование полученных знаний для уточнения вопросов и (или) формулировки новых запросов.

ПАД --- это способ мышления

#### Необходимые ресурсы
В этой главе закрепляем полученные навыки о пакетах `ggplot` & `dplyr`.

```{r}
library("tidyverse")
library("viridis")
library("forcats")
library("nycflights13")
library("Lahman")
```


### Вопросы

Главная цель ПАД --- добиться понимания данных.
Для понимания данных, может пригодится знания бизнес-аналитики и правильного формулирования вопросов.

Вопросов много, и научиться правильно их задавать, это целое искусство. Но в центре, по крайне мере этой главы будут два вопроса:

1. Вариации какого типа существуют среди переменных

1. Ковариации какого типа существуют между переменными

Определимся с терминологией:

* *Переменная* --- это количество, качество или свойство, которые можно измерить

* *Значение* --- это состояние переменной в момент ее измерения. Значение переменной может изменяться от измерения к измерению.

* *Наблюдение* или *случай* --- это набор измерений, выполненный в одинаоквых условиях обычно все измерения, входящие в наблюдение делаются в одно и тоже время для одного и того же объекта. Наблюдение содержит несколько значений, каждое из которых связано с отдельной переменной. Иногда вместо термина *наблюдение* мы будем использовать термин *точка данных*

* *Табличные данные* --- это набор значений, каждое из которых связано с переменной и наблюдением. Табличные данные считаются аккуратно организованными, если каждое значение находится в собственной ячейку, каждая переменная --- в собственном столбце, а каждое наблюдение --- в собственной строке. 

В столбцах --- переменная, в строке --- наблюдение, на пересечении --- значение.

### Вариация

Вариация --- это свойство значений переменных изменяться от измерения к измерению.

#### Визуализация распределений

Как именно стоит визуализировать переменную, зависит от того какого она типа:

* *Категориальными* --- называются переменные, которые имеют небольшой набор возможных значений.

Для визуализации категориальных переменных хорошо подходит столбчатая диаграмма

```{r}
ggplot(data = diamonds) +
  geom_bar(aes(cut))
```

Высота столбца соответсвует количеству наблюдений для каждого значения. Вычисление вручную:

```{r}
diamonds %>% 
  count(cut)
```

* *Непрерывная* переменная --- это такая переменная которая принимает любое из бесконечного можества упорядоченных значений.

Для визуализации непрерывного распределения нужно использовать гистограмму, она показывает сколько наблюдений попало в конкретный диапазон.

```{r}
ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
```

Вычисление вручную:

```{r}
diamonds %>% 
  count(cut_width(carat, 0.5))
```

Как учил ещё великий Скоморохов, проверять интервалы гистограмм нужно проверять. Потому что варьируя разбег, можно наткнуться на интересные закономерности. Пример из учебника:

```{r}
ggplot(data = diamonds) +
  geom_histogram(
    mapping = aes(x = carat), binwidth = 0.1) # Меняем значение для того чтобы показать, как изменится вид гистограммы
```

КОгда нужно наложить несколько гистограмм на один график, следует использовать вместо `geom_histogram` функцию `geom_freqpoly`. Статистику для вычисления последняя функция использует такую же как и гистограммы, однако для построения использует линии, а не столбцы.


```{r}
smaller <- diamonds %>% 
  filter(carat < 3)

ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
  geom_freqpoly(binwidth = 0.1)
```

#### Типичные значения

В этой части главы, открывается очень интересная грань статистического исследования. Она граничит с бизнес-аналитикой --- это постановка вопросов и обращение внимания на всякого рода закономерности.

Вопросы которые помогут всегда, я их на всякий случай оставлю тут, может когда-то пригодится:

* Какие значения встречаются наиболее часто? Почему?

* Какие значения являются редкими? Почему? Соответствует ли это вашим ожиданиям?

* Замечаете ли вы некоторые необычные закономерности? Чем их можно объяснить

* Хозяйке на заметку --- образование кластеров близких значений, указывает на существование подгрупп среди данных.

* Насколько близки друг к другу наблюдения в пределах каждого кластера?

* Насколько различаются между собой наблюдения, принадлежащие разным кластерам?

* Как можно объяснить или описать кластеры?

* Почему внешний вид кластеров может вводить в заблуждение?

#### Необычные значения

*Выбросами* называют необычные наблюдения --- точки данных, выпадющих из общего ряда.

Хороший пример из учебника. Наличие выбросов заметить нелегко, и только широкий диапазон построения может указывать на то, что здесь помимо построенных столбцов, существуют ещё значения.

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5)
```

На построеннии почти ничего не заметно. Для того чтобы увеличить масштаб необходимо воспользоваться функцией `coord_cartesian()`:
  
```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```

Мы обнаружили выбросы, теперь извлечём их:

```{r}
(unusual <- diamonds %>% 
  filter(y < 3 | y > 20) %>%
  arrange(y))
```

Таким образом мы нашли бриллианты, которые имеют нулевые размеры и имеют стоимость. А так же имеют гигантские размеры, но при этом стоят копейки. С выбросами всегда надо быть осторожным.

#### Упражнение 7.3.4.1
<div class="question">
Explore the distribution of each of the `x`, `y`, and `z` variables in `diamonds`. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.
</div>

Я хотел построить все три параметра на одной плоскости. Но это было бы не так информативно как панели.

Решение с панелями я подсмотрел [Jeffrey Arnold](https://github.com/jrnold). Но конечено же я не хочу бездумно копировать, поэтому прежде чем приводить его решение, я разберу новые неизвестные для меня, но используемые у Джефри функции.

* Функция `gather()` --- она используется, когда нужно несколько столбцов поместить в одну переменную. Такое иногда необходимо на практике, и я сам пару раз использовал подобный приём в Excel (В дополнении PLEX Еxcell для подобных нужд даже есть специальная функция) Продемонстрирую как работает `gather()`:


```{r}
#--------- Создаём набор данных, в котором есть 10 наблюдений трёх переменных записанных в стандартной форме
(stocks <- data.frame(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
))
```

Теперь мы хотим построить все три переменные за один приём. Чтобы это сделать, необходимо из трёх переменных сделать одну, и ввести идентификатор различия этой переменной. Эту операцию делает как раз функция `gather()`. Функция первым аргументом берёт набор данных, вторым необходимо указать название переменной, а последующими аргументами необходимо указать требумые переменные.
:

```{r}
gather(stocks, nazavanie_peremennoy, price, -time)
# stocks %>% gather(nazavanie_peremennoy, price, -time)
```

* Функция `geom_density()`. Это кривая распределения, построенная по вершинам гистограммы. Это полезная альтернатива гистограмме для непрерывных данных, которая исходит из лежащего в основе плавного распределения:

```{r}
#--Гистограмма
ggplot(diamonds, aes(carat)) +
  geom_histogram(binwidth = 0.05)
```

```{r}
#--Сглаженная кривая
ggplot(diamonds, aes(carat)) +
  geom_density()
```

А теперь приступим к разбору предлагаемого решения:

```{r}
diamonds %>%                         # Исходный набор данных с бриллиантами
  mutate(id = row_number()) %>%      # Добавить в набор параметр id который нумерует строки
  select(x, y, z, id) %>%            # Взять только изучаемые параметры и номера строк
  gather(variable, value , -id)  %>% # Преобразуем три набора параметров в один, исключаем id
  ggplot(aes(x = value)) +           # В атрибуте aes(), задаём параметр x = value, в котором у нас три переменные x, y, z
  geom_density() +                   # Строим сглаженную гистограмму
  facet_grid(variable ~ .)           # Группируем решение в панели, для визуализации распределния параметров x, y, z
```

Отвечая на вопрос о новых знаниях об этих переменных --- 

1. у всех трёх переменных есть необычные значения ближе к нулю и подальше 30.

1. Все три переменные имеют похожее распределение с двумя ярковыраженными пиками.


Отвечая на вопрос об измерениях --- Бриллианты, как правило, имеют круглую форму. Поэтому два измерения --- длинна и ширина, должны иметь примерно одинаковые значения. На графике выше видно, что `X` и `У` очень похожи между собой, выходит, что `Z` --- это глубина

#### Упражнение 7.3.4.2
<div class="question">
Explore the distribution of `price`. Do you discover anything unusual or surprising? (Hint: Carefully think about the `binwidth` and make sure you try a wide range of values.)
</div>

```{r}
ggplot(diamonds) +
  geom_histogram(aes(price), binwidth = 10) +
  coord_cartesian(xlim = c(0, 2500))
```

1. Цена на бриллианты в этом наборе данных начинается чуть больше чем с 250, я так полагаю ближе к 300 долларам

1. Существует провал в цене рядом со значением 1500

1. Есть всплеск в точках около 750

1. Распределение цены плавно убывает от всплеска 750, до примерно 19000

```{r}
ggplot(diamonds) +
  geom_histogram(aes(price), binwidth = 10) +
  coord_cartesian(xlim = c(0, 2500))
```

```{r}
ggplot(diamonds) +
  geom_histogram(aes(price), binwidth = 10) +
  coord_cartesian(xlim = c(15000, 19000))
```

```{r}
ggplot(diamonds) +
  geom_histogram(aes(price), binwidth = 100)
```

#### Упражнение 7.3.4.3
<div class="question">
How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?
</div>

разница ощутима:
```{r}
diamonds %>%
  filter(carat >= 0.99, carat <= 1) %>%
  count(carat)
```

Истинная природа может скрываться в округлении веса до сотой, ради цены:

```{r}
diamonds %>%
  filter(carat >= 0.99, carat <= 1) %>%
  group_by(carat) %>%
  summarise(mean_price = mean(price))
```

А может и не скрываться. Эта визуализация показывает пусть и нелинейную но прямопропорциональную зависимость средней цены от веса бриллианта
```{r}
diamonds %>%
  group_by(carat) %>%
  summarise(mean_price = mean(price)) %>%
  ggplot(aes(mean_price, carat)) +
  geom_point()
```

Вероятно бриллианты с "круглыми" каратами более популярны
```{r}
diamonds %>%
   filter(carat >= 0.9, carat <= 1.1) %>%
   count(carat) %>%
   print(n = 30)
```

Не то чтобы это правда, но очень на то похоже

#### Упражнение 7.3.4.4
<div class="question">
Compare and contrast `coord_cartesian()` vs `xlim()` or `ylim()` when zooming in on a histogram. What happens if you leave `binwidth` unset? What happens if you try and zoom so only half a bar shows?
</div>

Функция `coord_cartesian()` как бы увеличивает масштаб в указанных координатах
```{r}
ggplot(diamonds) +
  geom_histogram(aes(price), binwidth = 10) +
  coord_cartesian(xlim = c(1000, 2000))
```

В то время как `xlim()` удаляет все значение между указанными координатами. О чем `R` любезно предупреждает при построении графика.
```{r}
ggplot(diamonds) +
  geom_histogram(aes(price), binwidth = 10) +
  xlim(1000, 2000)
```

Если не задать аргумент `binwidth`, то ав


### Отсутствующие значения

Необычные значения можно:

* Отбросить, но это плохо

```{r}
diamonds2 <- diamonds %>%
  filter(between(y, 3, 20)) # Возьми только значения между 3 и 20 
```

* Лучше всего заменить необычные значения отсутствующими. Для замены можно использовать функцию `ifelse()`. Эта функция и по смыслу и по синтаксису похожа на функцию `ЕСЛИ` в Excel.

```{r}
diamonds2 <- diamonds %>%                   # В новый набор данных добавь новую переменную в которой,
  mutate(y = ifelse(y < 3 | y > 20, NA, y)) # Если значение "y" меньше 3 или больше 20, замени на NA, иначе, оставь их прежними
```

ВНИМАНИЕ. Это целая философия --- отсутствующие значения никогда не должны молчаливо исчезать. Самый приличный и профессиональный метод --- продублировать пресловутую переменную и заменить в ней аномальные значения на отсутствующие. Если возникнет необходимость визуализировать эту переменную, легко можно отбросить отсутствующие значения параметром `na.rm = TRUE`

```{r}
ggplot(diamonds2, aes(x,y)) +
  geom_point(na.rm = TRUE)
```

#### Упражнение 7.3.5.1
<div class="question">
What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference?
</div>

В гистограмме переменная `x` должна быть числовой, а `stat_bin()` группирует наблюдения по диапазонам в ячейки. Поскольку числовое значение наблюдений `NA` неизвестно, они не могут быть помещены в конкретный столбец и отбрасываются.

```{r}
ggplot(diamonds2, aes(y)) +
  geom_histogram(na.rm = TRUE, binwidth = 0.1)
```

В функции `geom_bar()` отсутствующие значения `NA` рассматриваются как другая категория. Аргумент `aes(x)` в `geom_bar()` требует дискретной (категориальной) переменной, а отсутствующие значения действуют как другая категория.

```{r}
diamonds2 %>%
  ggplot() +
  geom_bar(aes(y))
```

Пример лучше иллюстрирующий сказанное:

```{r}
diamonds %>%
  mutate(cut = if_else(runif(n()) < 0.1, NA_character_, as.character(cut))) %>%
  ggplot() +
  geom_bar(mapping = aes(x = cut))
```


#### Упражнение 7.3.5.2
<div class="question">
What does `na.rm = TRUE` do in `mean()` and `sum()`?
</div>

Аргумент `na.rm = TRUE` в функциях `mean()` и `sum()`, позволяет производить подсчёт не взирая на отсутствующие значения.

```{r}
x <- c(1, 3, 5, 7, 9, NA)
sum(x, na.rm = FALSE)
```

```{r}
x <- c(1, 3, 5, 7, 9, NA)
sum(x, na.rm = TRUE)
```
### Ковариация

Ковариация --- это тенденция к взаимосвязанному изменению значений двух и более переменных. И конечно лучший способ отследить ковариацию --- визуализирвоать переменные.

#### Категориальные и непрерывные переменные

При большом разбросе значений, мелкие интересности на фоне больших значений сложно разглядеть. Рассмотрим в качестве примера, как изменяется цена бриллиантов в зависимости от их качества.

```{r}
ggplot(diamonds, aes(price)) +
  geom_freqpoly(aes(color = cut), binwidth = 500)
```

Увидеть различия в распределении трудно, ввиду больших различий в размерах групп

```{r}
ggplot(diamonds) +
  geom_bar(aes(cut))
```

Чтобы облегчить сравнение распределений, необходимо поменять переменную отображаемую по оси `y`. Для этого воспользуемся стандартизированной количественной характеристикой --- плотностью.

```{r}
ggplot(diamonds, aes(x = price, y = ..density..)) +
  geom_freqpoly(aes(color = cut), binwidth = 500)
```

И наконец, мы дошли до ящиков с усами. Диаграммы размаха удобно использовать для визуальной экспресс оценки. Напомню что такое ящик с усами

![alt text](img/boxplot.png)
Рассмотрим распределение цены `price`в замивсимости от качества огранки `cut`, используя функцию `geom_boxplot()`

```{r}
ggplot(diamonds, aes(cut, price)) +
  geom_boxplot()
```

Ящики позволяют сравнивать между собой распределения. Очень удачно, что в текущем примере с бриллиантами все классы качества упорядочены по возрастанию качества от `Fair` удовлетворительного до `Ideal` идеального. Конечно же не всегда данные так упорядочены, и для того чтобы удобнее и логичнее выстравить построения можно использовать функцию `reorder()`. 

Рассмотрим например переменную `class`из набора данных про автомобили. Предположим, мы хотим выяснить как меняется показатель расхода топлива `hwy` в зависимости от класса автомобиля `class`

```{r}
ggplot(mpg, aes(class, hwy)) +
  geom_boxplot()
```

чтобы сделать тренд более наглядным, переставим значения класса, основываясь на медиане значений `hwy`

```{r}
ggplot(mpg) +
  geom_boxplot(
   mapping = aes(
     x = reorder(class, hwy, FUN = median), # меняем местами переменные, по возрастанию медианы
     y = hwy)) +
  coord_flip()                              # поворачиваем на 90 градусов, чтобы поместились надписи
```

#### Упражнение 7.5.1.1.1
<div class="question">
Use what you’ve learned to improve the visualisation of the departure times of cancelled vs. non-cancelled flights.
</div>

Используем построение ящиками с усами, для того чтобы сделать визуализацию нагляднее

```{r}
flights %>%
  mutate(canceled = is.na(dep_time),  # Добавляем категориальную переменную, FALSE соответствует отменённым рейсам
         sched_dep_time_minute = ((sched_dep_time %/% 100) * 60) + sched_dep_time %% 100) %>% # Переводим представление даты
ggplot() +
  geom_boxplot(mapping = aes(x = canceled, y = sched_dep_time_minute))  # Строим ящик с усами
```

#### Упражнение 7.5.1.1.2
<div class="question">
What variable in the `diamonds` dataset is most important for predicting the price of a diamond? How is that variable correlated with `cut`? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?
</div>

Хорошо, что в наборе данных `diaminds` не так много переменных, и все их можно проверить --- это займет не так много времени на первый взгляд. Но будем действовать разумнее и отсечём менее информативные показатели. На мой взгляд, с ценой должен хорошо коррелировать параметр `carat` --- это вес алмаза. Так как вес определяется размерами (и ещё плотностью, которой у нас нет), то параметры относящиеся к размеру мы отсекаем. Собственно после этого останется --- `cut`, `color`, `clarity`. В итоге четыре параметра для проверки. Начнем с веса.

Обе переменные `carat` и `price` непрерывные, для визуализации зависимости нужно будет немного исхитриться. Но для начала покажем на диграмме рассеяния зависимость цены от веса:

```{r}
ggplot(diamonds, aes(carat, price)) +
  geom_point()
```

Как видно с увеличением веса, по какой-то зависимости происходит и увеличение цены, значит мы в верном направлении. Осталось, для визуализации преобразовать непрерывные данные в категориальные. В этом нам поможет аргумент `cut_width()` --- который разрезат весь интервал на участки. Об этом как раз говорилось в начале главы.

```{r}
ggplot(data = diamonds, mapping = aes(x = carat, y = price)) +
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.2)))
```

Этот график нагляднее показывает скорость роста цены от веса бриллианта. От группе к группе --- медиана увеличивается, с некоторыми провалами в райое 3.0-3.5 карат. Посмотрим что с другими выбранными для анализа переменными

```{r}
ggplot(diamonds, aes(color, price)) +
  geom_boxplot()
```

Видно что есть некоторый рост цены с изменением цвета от D к J, однако он не такой существенный как рост цены от веса. Посмотрим как изменяется цена в зависимости чистоты бриллианта

```{r}
ggplot(diamonds, aes(clarity, price)) +
  geom_boxplot()
```

Ясность вообще выглядит удивительно --- чем прозрачнее степень бриллианта, тем меньше его средняя цена. Это контринтуитивно, но вероятно этому есть логическое объяснение. В поиски логического объяснения я пока уходить не буду, потому что изменение цены от ясности не такое большое как от веса бриллианта. Поэтому я остановлю свой выбор среди представленных переменных, для лучшего предсказания цены бриллианта на переменной `carat`. 

Теперь посмотрим как `carat` зависит от `cut`.

```{r}
ggplot(diamonds, aes(cut, carat)) +
  geom_boxplot()
```

Наблюдается небольшая обратная зависимость --- при улучшении качества огранки, немного изменяется цена. Примечательно, что самые большие бриллианты имеют плохую огранку. Это может быть связано с тем, что большие бриллианты это самородки. Маленьким бриллиантам нужно уделить больше внимания, чтобы они выглядели более презентабельно при продаже.

#### Упражнение 7.5.1.1.3
<div class="question">
Install the `ggstance` package, and create a horizontal boxplot. How does this compare to using `coord_flip()`?
</div>

Ранее мы использовали поворот системы координат в примере с визуализацией расхода топлива от класса автомобиля.
```{r}
ggplot(mpg) +
  geom_boxplot(aes(x = reorder(class, hwy, FUN = median), 
                   y = hwy)) +
  coord_flip()
```

Для того что сделать горизонтальную диаграмму размаха через функции пакета `ggstance`, необходимо подключить его и воспользоваться функцией `geom_boxploth()`. 

```{r}
library("ggstance")
ggplot(mpg) +
  geom_boxploth(aes(x = reorder(class, hwy, FUN = median),
                    y = hwy))
```

Похоже, что эта функция специально предназначена для построения горизонтальных диаграмм размахов (ящиков с усами).
```{r}
ggplot(mpg) +
  geom_boxploth(aes(y = reorder(class, hwy, FUN = median),
                    x = hwy))
```

#### Упражнение 7.5.1.1.4
<div class="question">
One problem with box plots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the `lvplot` package, and try using `geom_lv()` to display the distribution of `price` vs `cut`. What do you learn?

How do you interpret the plots?
</div>

Ух ты, много раз задумывался о том, что ящики это что-то старенькое, и на них ну уж очень много данных попадает порой в область выбросов. Оказывается это так и есть. Устанавливаем пакет и подключаем библиотеку

```{r}
library("lvplot")

ggplot(diamonds, aes(x = cut, y = price)) +
  geom_lv(aes(fill=..LV..))
```

[В статье](https://vita.had.co.nz/papers/letter-value-plot.pdf) объясняются преимущества Side-by-side LV boxplots, а так же показаны примеры и сравнения. Здесь объяснений приводить не буду, ограничусь тем, что скажу что новый вид диаграмм более информативен посравнению с ящиками с усами Джона Тьюки.

#### Упражнение 7.5.1.1.5
<div class="question">
Compare and contrast `geom_violin()` with a faceted `geom_histogram()`, or a colored `geom_freqpoly()`. What are the pros and cons of each method?
</div>

С построением `geom_freqpoly()` я уже знаком --- его основное преимущество это возможность построить на одном графике разными линиями несколько категориальных переменных. При этом можно бегло оценить их распределение и поверхностно сравнить. Основным недостатком является тот факт, что при большой дисперсии выборок, хотя бы в одной переменной, сравнивать более мелкие ковариации становится затруднительно, нужно либо изменять масштаб, либо отбрасывать данные вокруг рассматриваемого участка.
```{r}
ggplot(diamonds,aes(price, ..density..)) +
  geom_freqpoly(mapping = aes(color = cut), binwidth = 500)
```

Гистограммы в панелях тоже интересное решение, когда нужно сравнить распределение и возможные ковариации нескольких переменных. В этом варианте несколько попроще разгядеть зависимости
```{r}
ggplot(diamonds, aes(x = price)) +
  geom_histogram() +
  facet_wrap(~ cut, ncol = 1)
```

Однако и в этом случае, если встречаются разномасштабные данные, для лучшей визуализации необходимо "поиграться" с масштабом. Для этого устанавливается независимый масштаб у переменных

```{r}
ggplot(diamonds, aes(x = price)) +
  geom_histogram() +
  facet_wrap(~ cut, ncol = 1, scales = "free_y")
```

Теперь попробуем построить скрипичный график.
```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_violin()
```

Скрипичный график представляет собой компактную визуализацию непрерывного распределения. [Подробнее о построении скрипичного графика](http://www.stat.cmu.edu/~rnugent/PCMI2016/papers/ViolinPlots.pdf)

#### Упражнение 7.5.1.1.6
<div class="question">
If you have a small dataset, it’s sometimes useful to use `geom_jitter()` to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.
</div>

В описании встретилось два метода 

* `geom_quasirandom()` создает графики, которые представляют собой смесь джиттера и скрипки. Существует несколько разных методов, которые точно определяют, как генерируется случайное расположение точек.

* `geom_beeswarm()` создает построение, подобное построению скрипки, но компенсируя точки.

Вспомним построение язиков для визуализации расхода топлива в зависимости от класса автомобиля

```{r}
ggplot(mpg) +
  geom_boxplot(aes(x = reorder(class, hwy, FUN = median), 
                   y = hwy))
```

Теперь построим квазирандомом

```{r}
library("ggbeeswarm")
ggplot(mpg) +
  geom_quasirandom(aes(x = reorder(class, hwy, FUN = median),
                                 y = hwy))
```

Эта визуализация похожа на ящики с усами, но по количеству и плотности точек можно нагляднее представить характер распределения.
У этого построения есть несколько методов задания распределения рандомности точек.

```{r}
ggplot(mpg) +
  geom_quasirandom(aes(x = reorder(class, hwy, FUN = median),
                                 y = hwy),
                   method = "frowney")
```

```{r}
ggplot(mpg) +
  geom_quasirandom(aes(x = reorder(class, hwy, FUN = median),
                                 y = hwy),
                   method = "smiley")
```

Но перейдём теперь к `geom_beeswarm()`

```{r}
ggplot(mpg) +
  geom_beeswarm(aes(x = reorder(class, hwy, FUN = median),
                                 y = hwy))
```

В принципе у него тоже есть некий алгоритм рандомности, но в общих чертах выглядит похоже на предыдущие построения. У него плотность точек побольше.

#### Две категориальные переменные

Порой необходимо проверить как между собой связаны две категориальные переменные. Например когда необходимо установить, какая пара категориальных переменных чаще всего встречается. Для этого можно воспользоваться несколькими способами.

* Посчитать количество точек попавших в каждую пару внутренней функцией пакета

```{r}
ggplot(diamonds) +
  geom_count(aes(cut, color))
```

* Посчитать через `dplyr`

```{r}
diamonds %>% 
  count(color, cut)
```

и затем визуализировать

```{r}
diamonds %>% 
  count(color, cut) %>%  
  ggplot(mapping = aes(x = color, y = cut)) +
    geom_tile(mapping = aes(fill = n)) +
  coord_flip()
```

#### Упражнение 7.5.2.1.1
<div class="question">
How could you rescale the `count` dataset above to more clearly show the distribution of `cut` within `colour`, or `colour` within `cut`?
</div>

Сгруппируем по отдельности, сначала по цвету, потом по степени огранки и в каждом случае введём переменную вычисляющую пропорцию. Для того чтобы можно было сравнить в одних условиях.

```{r}
diamonds %>%
  count(color, cut) %>%                        # Считаем количество значений в парах
  group_by(color) %>%                          # Группирупм по цвету
  mutate(prop = n / sum(n)) %>%                # Добавляем переменную, в которой вычисляем пропорцию
  ggplot(aes(color, cut)) +
  geom_tile(aes(fill = prop))                  # Делаем заливку введённой переменной
```

Теперь проделаем всё тоже самое, но с группировкой по `cut`

```{r}
diamonds %>%
  count(color, cut) %>%
  group_by(cut) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot(aes(color, cut)) +
  geom_tile(aes(fill = prop))
```

Группировка по цвету имеет более упорядоченный вид.

#### Упражнение 7.5.2.1.2
<div class="question">
Use `geom_tile()` together with `dplyr` to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?
</div>

Итак, сначала построим распределение средней задержки в разрезе двух категориальных переменных  месяца отправки и направлению вылета.

```{r}
flights %>%
  group_by(month, dest) %>%                           # Группируем по месяцу и направлению
  summarise(mean = mean(dep_delay, na.rm = TRUE)) %>% # Вводим новую переменную, в которой считаем среднее время задержки в группах
  ggplot(aes(month, dest)) +
  geom_tile(aes(fill = mean)) +                       # Строим диаграмму распределения с заливкой по среднему значению
  labs(x = "Mесяц", y = "Направление", fill = "Задержка отправления")
```

Затрудняет чтение диаграммы отсутствие месяцев. Чтобы представить месяцы в более привычной форме нужно использовать функцию `factor()`, я пока не знаю как она работает. Но она помогла.

```{r}
flights %>%
  group_by(month, dest) %>%                           
  summarise(mean = mean(dep_delay, na.rm = TRUE)) %>% 
  ggplot(aes(factor(month), dest)) +
  geom_tile(aes(fill = mean)) +
  labs(x = "Mесяц", y = "Направление", fill = "Задержка отправления")
```

Мешают отсутсвующие значения. Удалим их. 

С этим пришлось повозиться, и сделать необычную конструкцию.
Её суть заключается в том, чтобы отображать на графике только те направления, по которым летали заданное количество месяцев. Нам интересно видеть круглогодично заполненные аэропорты, поэтому зададим количество месяцев равным 12.


```{r}
flights %>%
  group_by(month, dest) %>%                           
  summarise(mean = mean(dep_delay, na.rm = TRUE)) %>% 
  group_by(dest) %>%
  filter(n() == 12) %>%
  
  ggplot(aes(factor(month), dest)) +
  geom_tile(aes(fill = mean)) +
  labs(x = "Mесяц", y = "Направление", fill = "Задержка отправления")
```

Затрудняет алфавитный порядок, поскольку при беглом анализе несколько теряется информативность. Можно сортировать направление вылета не по алфавиту, а по какому-нибудь значимому параметру, например по среднему количеству полётов в году, или по средней задержки. Для того чтобы отсортировать переменную `dest` необходимо воспользоваться функцией `reorder()`. Эта функция«по умолчанию» рассматривает свой первый аргумент как категориальную переменную и переупорядочивает его уровни на основе значений второй переменной, обычно числовой, в нашем случае это будет среднегодовое время задержки вылета.

```{r}
flights %>%
  group_by(month, dest) %>%                           
  summarise(mean = mean(dep_delay, na.rm = TRUE)) %>% 
  group_by(dest) %>%
  filter(n() == 12) %>%
  ungroup() %>%
  mutate(dest = reorder(dest, mean)) %>%
  
  ggplot(aes(factor(month), dest)) +
  geom_tile(aes(fill = mean)) + 
  labs(x = "Mесяц", y = "Направление", fill = "Задержка отправления")
```

#### Упражнение 7.5.2.1.2
<div class="question">
Why is it slightly better to use `aes(x = color, y = cut)` rather than `aes(x = cut, y = color)` in the example above?
</div>

Всё просто. Ответ лежит в плоскости листа, точнее его ориентации. Дело в том, что чем больше переменных тем хуже воспринимается альбомная ориентация, поэтому рекомендуется параметр с большим количеством переменных распологать по оси абсцис. Не совсем удачно для этой задачи выбран пример, поскольку имена переменных прекрасно укладываются по обеим осям.

```{r}
diamonds %>%
  count(color, cut) %>%  
  ggplot(mapping = aes(y = color, x = cut)) +
    geom_tile(mapping = aes(fill = n))
```

```{r}
diamonds %>%
  count(color, cut) %>%  
  ggplot(mapping = aes(y = cut, x = color)) +
    geom_tile(mapping = aes(fill = n))
```

Однако эту ситуацию идеально иллюстрируют предыдущее упражнение, если поменять оси местами, то совершенно невозомжно будет различить какие где аэропорты:

```{r}
flights %>%
  group_by(month, dest) %>%                           
  summarise(mean = mean(dep_delay, na.rm = TRUE)) %>% 
  group_by(dest) %>%
  filter(n() == 12) %>%
  ungroup() %>%
  mutate(dest = reorder(dest, mean)) %>%
  
  ggplot(aes(factor(month), dest)) +
  geom_tile(aes(fill = mean)) + 
  labs(x = "Mесяц", y = "Направление", fill = "Задержка отправления") +
  coord_flip()
```

#### Две непрерывные переменные

С одним из способов визуализации двух непрерывных переменных я уже знаком. Это точечная диаграмма рассеяния.

```{r}
ggplot(diamonds) +
  geom_point(aes(carat, price))
```

Даже при таком построении просматривается экспоненциальный характер связи. Однако большое скопление точек затрудняет восприятие. Частично эту ситуацию может решит введение уже знакомой мне прозрачности

```{r}
ggplot(diamonds) +
  geom_point(aes(carat, price), 
             alpha = 0.01)
```

Однако это не панацея. Чуть более полезное решение --- использование карманов (интервалов значений). Так называем карманы создаются с помощью функций `geom_bin2d()` и `geom_hex()`. Для использования последней необходимо установить пакет `hexbin`. 

```{r}
#install.packages("hexbin")
ggplot(diamonds) +
  geom_bin2d(aes(carat, price))
```

```{r}
ggplot(smaller) +
  geom_hex(aes(carat, price))
```

Это красиво. Но есть старые добрые методы от Тьюки --- ящики с усами. 

```{r}
ggplot(smaller, aes(carat, price)) +
  geom_boxplot(aes(group = cut_width(carat, 0.1)))
```

Однако ящики с усами имеют один и тот же внешний вид, за исключением количества выбросов, независимо от количества наблюдений, которым они соответствуют. ПОэтому судить о том , какое количество наблюдений просуммировано в каждом кармане очень трудно. ОДин из способов сделать это возможным заключается в использовании карманов, ширина которых пропорциональна количеству точек данных `varwidth = TRUE`

```{r}
ggplot(smaller, aes(carat, price)) +
  geom_boxplot(aes(group = cut_width(carat, 0.1)),
               varwidth = TRUE)
```

Не очень наглядно, но говорят иногда выручает. Ещё один способ, заключается в том, чтобы отражать примерно одно и то же количество точек в каждом кармане. Это делается с помощью функции `cut_number()`

```{r}
ggplot(smaller, aes(carat, price)) +
  geom_boxplot(aes(group = cut_number(carat, 20)))
```

#### Упражнение 7.5.3.1.1
<div class="question">
Instead of summarizing the conditional distribution with a box plot, you could use a frequency polygon. What do you need to consider when using `cut_width()` vs `cut_number()`? How does that impact a visualization of the 2d distribution of `carat` and `price`?
</div>

Принимая решение о том какую из функций использовать, необходимо учитывать следующие факторы

* При использовании `cut_width()` необходимо указать ширину просматриваемого диапазона. 

* При использовании `cut_number()` необходимо указать количество ящиков, которое необходимо построить. 

#### Упражнение 7.5.3.1.2
<div class="question">
Visualize the distribution of `carat`, partitioned by `price`.
</div>

Как я понял это задание --- нужно сгруппировать данные в ящиках по переменной `price`. Это означает, что нужно указать группировку либо по количеству ящиков, которые будем строить, т.е.`cut_number()`. Сначала я построил вот такое распределение.

```{r}
ggplot(diamonds, aes(price, carat)) +
  geom_boxplot(aes(group = cut_number(price, 10))) +
  coord_flip()
```

Здесь построено 10 ящиков сгруппированных по переменной `price`, с примерно одним количеством точек в кармане или диапазоне. В принципе подобное же решение но с группировкой по переменной `carat` приведена в учебнике. Меня смущает здесь тот факт, что столбцы ящиков с усами имеют разную ширину хотя они и показывают количество точек попавших в карман. Чтобы построить ящики равной ширины и при этом отобразить количество точек попавших в наблюдение, можно убрать группировку при построении оставив только функцию `cut_number`

```{r}
ggplot(diamonds, aes(cut_number(price, 10), carat)) +
  geom_boxplot() +
  coord_flip()
```

Как видно такое построение не повлияло на характер распределения, однако сделало визуализацию чуть более аккуратной. Такой подход ситуативен, потому что повторюсь --- первый вариант даёт наглядное представление о количестве точек, попавших в карман.

#### Упражнение 7.5.3.1.3
<div class="question">
How does the `price` distribution of very large diamonds compare to small diamonds. Is it as you expect, or does it surprise you?
</div>

```{r}
ggplot(smaller, aes(carat, price)) +
  geom_boxplot(aes(group = cut_width(carat, 0.1)),
               varwidth = TRUE)
```

Как видно из распределения более тяжёлые бриллианты имеют больший межквартильный размах, это говорит о том, что плотность данных не высокая и в нутри выборки в пределах одного веса происходят большие флуктуации --- начиная с веса в один карат и выше, размах составляет от 5000 долларов за единицу веса. При этом чем меньше вес бриллианта, тем большая плотность цены у бриллиантов. 

По началу меня это удивило. Но если брать в расчёт ранее полученную информацию о прозрачности и цвете бриллиантов, то становится ясно, что чем меньше бриллиант, тем идеальнее он должен быть, чтобы его продать. Большой самородок проще продать, даже если он имеют не идеальные цвет, качество огранки и прозрачность.

#### Упражнение 7.5.3.1.4
<div class="question">
Combine two of the techniques you’ve learned to visualize the combined distribution of `cut`, `carat`, and `price`.
</div>

Попробуем несколько способов визуализации указанных переменных. Один из первых --- это объединение панелями.

Уже на этом этапе понятно, что интерпритируемость некоторых вариантов значительно хуже других.

```{r}
ggplot(diamonds, aes(carat, price)) +
  geom_boxplot(aes(group = cut_width(carat, 0.5))) +
  facet_wrap(~ cut, nrow = 2)
```

Построение в панелях ящиков с усами, даёт некоторое представление о взаимном распределении переменных, однако на сравнение необходимо затратить некоторое время. Чуть более интересную визуализацию панелями даёт построение шестигранных диаграмм

```{r}
ggplot(diamonds, aes(carat, price)) +
  geom_hex() +
  facet_wrap(~ cut, nrow = 2)
```

Следующий способ --- построить ящики с усами, разбить просматриваемый диапазон на равное количество карманов, и в каждом диапазоне разбить один ящик на несколько, согласно категориальной переменной. Так как категориальная переменная одна `cut`, то в зависимости от того, распределение какой переменной мы хотим изучить, будем создавать карманы либо по весу

```{r}
ggplot(diamonds, aes(x = cut_number(carat, 6), y = price)) +
  geom_boxplot(aes(color = cut)) +
  xlab("carat")
```

Либо по цене

```{r}
ggplot(diamonds, aes(x = cut_number(price, 6), y = carat)) +
  geom_boxplot(aes(color = cut)) +
  coord_flip() +
  xlab("price")
```

#### Упражнение 7.5.3.1.5
<div class="question">
Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the plot below have an unusual combination of `x` and `y` values, which makes the points outliers even though their `x` and `y` values appear normal when examined separately.
</div>

Почему в данном случае легче заметить необычные точки на диаграмме рассеяния, чем на диаграмме использующей карманы.

```{r}
ggplot(diamonds) +
  geom_point(aes(x = x, y = y)) +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
```

Потому что при построении ящиков или диаграмм с карманами, интересующие нас точки попадая в карман могут во-первых наклыдваться друг на друга. 

```{r}
ggplot(diamonds) +
  geom_boxplot(mapping = aes(x = cut_number(x, 10), y = y)) + 
   coord_cartesian(xlim = c(3, 11), ylim = c(4, 11))
```

### Шаблоны поведения переменных и модели

Если в поведении двух перменных наблюдается систематическая закономерность, то это может свидетельствовать о наличии устойчивой связи между данными. Как только я замечаю какую-либо закономерность, мне следует задать себе примерно такие вопросы:

* Может ли эта закономерность быть лишь кажущейся, другими словами --- не обусловлена ли она случайным совпадением?

* Как можно описать отношение между переменными, которое следует из наблюдаемой закономерности?

* Насколько сильна связь между переменными, которую можно предпологать, исходя из наблюдаемой закономерности?

* Какие другие пременные могут оказывать влияние на отношение между данными переменными?

* Изменяется ли это отношение при переходе к рассмотрению отдельных подгрупп данных?

Возьмём к примеру, извержения гейзера.

```{r}
ggplot(faithful) +
  geom_point(aes(eruptions, waiting))
```

Видно, что чем больше задержка перед извержением, тем дольше длится это извержение. Кроме этого, на графике отчётличво просматриваются два кластера. 

* Вариация --- явление, создающее неопредлённость.

* Ковариация --- это явление, уменьшающее неопрделённость.

Если между переменными существует ковариация, то значения одной переменной могут быть использованы для предсказания или улучшения предсказания другой переменной. Есть особые случаи --- когда ковариация обсуловлена причинно-следственной связью, тогда значения одной пременной могут быть испрльзованы для управления значениями другой переменной.

Модели --- это инструмент используемый для выявления закономерностей в поведении данных. Вернёмся снова к бриллиантам.

Понять природу отношения между переменными `cut`, `carat`, `price` не легко потому что они тесно связаны между собой.
МОжно использовать модель, которая исключает влияегие очень сильной связи между переменными `carat` и `price` и тем самым предоставляет возможность ислледовать более тонкие детали.

Приведённый ниже код соответствует модели, которая предсказывает ЦЕНУ по ВЕСУ, а затем вычисляет остатки (то есть разницу между предсказанием и фактическим значением). Остатки дают представление о цене бриллиантов после исключения из неё влияния веса.

```{r}
library(modelr)

mod <- lm(log(price) ~ log(carat), data = diamonds)

diamonds2 <- diamonds %>%
  add_residuals(mod) %>%
  mutate(resid = exp(resid))
  
ggplot(diamonds2) +
  geom_point(aes(carat, resid))
```

О том как работает этот код мы узнаем позже, пока важно ухватить суть --- исключив влияние сильной взаимосвязи переменных `carat` и `price` мы видим, что соотношение между переменными `cut` и `price` соответствует ожидаемому. Для алмазов сравнимого размера, более высокому качеству соответствует более высокая цена.

Данные без применения модели
```{r}
ggplot(diamonds) +
  geom_boxplot(aes(cut, price))
```


Данные, полсе применения модели

```{r}
ggplot(diamonds2) +
  geom_boxplot(aes(cut, resid))
```

### Вызов функций `ggplot`

В этой главе рассказано, что у некоторых функций есть короткая запись.
К моменту прочтения этой главы, я уже догадался об этом и использовал ранее в решениях.

### Дополнительная информация

Несколько хороших книг по пройденному материалу

* [Graphical Data Analysis with R (Chapman & Hall/CRC The R Series)](https://www.amazon.com/dp/1498715230/ref=cm_sw_su_dp)

* [R Graphics Cookbook](https://www.amazon.com/dp/1449316956/ref=cm_sw_su_dp)

* [ggplot2: Elegant Graphics for Data Analysis (Use R!)](https://www.amazon.com/dp/331924275X/ref=cm_sw_su_dp)


<!--chapter:end:05_exploratory_data_analysis.Rmd-->

---
editor_options: 
  chunk_output_type: console
output: html_document
---

## Организация рабочего процесса: проекты

### Что является вашим достоянием

1. Это конечно среда, где хранятся данные --- список Envirinment

1. Но в первую очередь это конечно скрипты.

В принципе, то что я фиксирую свои ответы в книге --- это уже хорошо.
Есть конечно большая задача по тому, чтобы изучить как работает букдаун, чтобы понять как это дело работает.
Однако, меня это уже мало по-малу приучает к тому, чтобы работать скриптами.

### Где находится ваш анализ

В каталогах. Чтобы проверить можно воспользоваться командой `getwd()`

### Пути и каталоги

* Необходимо помнить что разделителем В Windows --- является обратная косая черта ('\'). А в Mac прямая --- ('/'). НАм рекомендуют использовать стиль Mac.

### Проекты RStudio

Начиная работу с этой книгой, я заглянул вперёд и предусмотрительно создал проект.
А если сохранять графики и данные консольным способом, то при поиске в системе помимо найденного объекта, будет находится ещё и скрипт, который сохранил его. Это поистине чудо!!!

```{r}
library("tidyverse")

ggplot(diamonds, aes(carat, price)) +
  geom_hex()
ggsave("diamonds.pdf")

write_csv(diamonds, "diamonds.csv")
```

### Резюме

Ниже приведен краткий перечень тех возможностей работы с R-кодом, который предлагает RStudio:

* Создавать проект RStudio для каждого проекта анализа

* Хранить в проекте файлы данных.

* Хранить в проекте скрипты, редактировать их и выполнять по частям или целиком

* Сохранять в проекте свои выходные результаты (графики и очищенные данные)

* использовать только относительные пути, а не абсолютные

Всё необходимое будет собрано в одном месте и отделено от других проектов с которымт я буду работать.

Говоря словами Эрика Картмана --- ЩЩЩЩикарна!



<!--chapter:end:06_workflow_projects.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Подготовка данных

В этой части я узнаю о подготовке данных --- искусстве приведения исходных данных к виде, обеспечивающему возможность их визуализации и моделировании в среде R.

Без подготовки нельзя работать с данными. Это огромный пласт, который необходимо освоить

## Создание tibble-фреймов с помощью пакета `tibble`

### Введение
На протяжении всей книги, мы будем работать не с традиционными фреймами данных R (`data.frame`), а с так называемыми tibble-фреймами.

Так как R старенький язык, в нём многое устарело, но чтобы революционно что-то менять нужно потрать много времени, поэтому большая часть полезных функций реализуется пакетами. Это касается и фреймов данных, встроенный стандартный `data.frame` как говорят, не всегда удобный. Поэто при помощи пакета `tibble` реализовали возможность работать с упрощённой формой фреймов данных.

Получить более подробную информацию можно по команде `vignette("tibble")`

#### Необходимые ресурсы

Пакет `tibble` является частью ядра библиотеки `tidyverse`.

```{r}
library("tidyverse")
library("viridis")
library("forcats")
library("nycflights13")
library("Lahman")
library("dplyr")
```

### Создание tibble-фреймов 

Многие пакеты на выходе создают стандартный `data.frame`, частенько нужно будет приводить такие данные к виду тиббл. Это можно делать при помощи функции `as_tibble()`

```{r}
as_tibble(iris)
```

Можно создавать тиббл формат самому при помощи функции `tibble()`

```{r}
tibble(
  x = 1:5,
  y = 1,
  z = x ^ 2 + y
)
```

Тиббл не изменяет тип входных данных, не преобразует строки в факторы, не изменяет имена переменных и не создаёт имена строк.

Можно создавать  "несистемные" имена столбцов --- начинать с символов, пробелов, знаков.

```{r}
(tb <- tibble(
  `:)` = "smile", 
  ` ` = "space",
  `2000` = "number"
)) 
```

Чтобы задать непростое имя, следует, как видно выше, воспользоваться обратными апострофами. Точно такими же, которые открывают/закрывают чанк. 

Еще один способ задавать тиббл-фреймы. Пока не понятно зачем, но можно задавать следующим образом

```{r}
tribble(
  ~x, ~y, ~z,
  #--|--|----
  "a", 2, 3.6,
  "b", 1, 8.5
)
```

### Сравнение tibble-фреймов с фреймами `data.frame`

Различия двух типов касаются двух, описанных ниже операций

#### Вывод на печать

Tibble-фреймы спроектированы таким образом, чтобы случайно не перезагрузить консоль выводом данных. Они выводят на экран первые десять строк таблицы и столько столбцов, сколько поместится на экран. Это великое благо.

```{r}
tibble(
  a = lubridate::now() + runif(1e3) * 86400,
  b = lubridate::today() + runif(1e3) * 30,
  c = 1:1e3,
  d = runif(1e3),
  e = sample(letters, 1e3, replace = TRUE)
)
```

Полезной фичей иногда бывает указать напрямую сколько нужно отображать строк.

```{r}
nycflights13::flights %>% 
  print(n = 10, width = Inf) # Параметр width = Inf указывает что выводить нужно все столбцы
```

КРоме того можно управлять поведением при печати заданным по умолчанию, с помощью группы настроек `options`

* `options(tibble.print_max = n, tibble.print_min = m)`: если количество строк больше `m` вывести на печать лишь `n` строк. Чтобы всегда отображались все строки, используй вариант `ooptions(dplyr.print_min = Inf)`

* Чтобы всегда выводить на печать все столбцы, независимо от ширины экрана, используй `options(tibble.width = Inf)`

полный список возможных опций `packege?tibble`.

МОжно воспользоваться встроенным средством просмотра

```{r}
#nycflights13::flights %>% 
#  View()
```

#### Извлечение поднаборов

Если требуется извлечь одну переменную необходимо использовать операторы `$` и `[[`. Последний обеспечивает доступ к элементам по имени и по индексу, `$` --- только по имени, но требует ввода меньше символов.

```{r}
df <- tibble(
  x = runif(5),
  y = rnorm(5)
)
```

```{r}
# Извлечение элемента по имени
df$x

df[["x"]]
```

```{r}
# Извлечение элемента по индексу
df[[1]]
```

Применение этих операций в канале требует специального заместитеоя (`.`)

```{r}
df %>% .$x

df %>% .[[1]]
```

По сравнению с `data.frame` tibble-фреймы обладают большей строгостью --- они никогда не удовлетворяют частичным соответствиям и генерируют сообщение об ошибке, если столбец, к которому пробуют получить доступ не существует.

### Взаимодействие с разработанным ранее кодом

Некоторые функции не работают с tibble-фреймами, для таких функций необходимо перевести tibble обратно в `data.frame` с помощью функции `as.data.frame()`

```{r}
class(as.data.frame(tb))
```

#### Упражнение 10.6.1
<div class="question">
How can you tell if an object is a tibble? (Hint: try printing mtcars, which is a regular data frame). 
</div>

Для начала выведем привычный tibble-frame

```{r}
diamonds
```

Каждый столбец подписан типом данных --- это удобно.

Теперь выводим на печать объект `data.frame`

```{r}
mtcars
```

Вторым отличием является наличие именованных строк

```{r}
as_tibble(mtcars)
```

Такой способ узнать тип объекта, но является трудоемким. Для быстрой проверки типа объекта существует функция `class()`

```{r}
class(mtcars)

class(diamonds)
```

Если объект типа `data.frame`, то результатом запроса `class()` будет `"data.frame"`. Если объект класса tibble, то результатом будет `"tbl_df"     "tbl"        "data.frame"`

Больше информации в источнике [R для продвинутых](http://adv-r.had.co.nz/S3.html)

#### Упражнение 10.6.2
<div class="question">
Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviors cause you frustration?
</div>

```{r}
df <- data.frame(abc = 1, xyz = "a", yxq = 4)
df$x

df[, "xyz"]

df[, c("abc", "xyz")]
```

В первом примере, я его немного расширил --- программа возвращает содержимое столбца, который первый соответствует заданному параметру поиска. Т.е. первый столбец который содержит в названии `x`

Итак сопоставляем. Для начала меняем тип данных на тиббл
```{r}
tbl <- as.tibble(df)
```

Пример 1. Так как tibble очень требователен и имеет строгую нотацию, то в ответ на поиск заданного вектора, он ответит что не знает такого. С одной стороны это помогает экономить несколько нажатий клавиш, но с другой стороны это может стать причиной ошибки --- потому что могла иметься в виду другая переменная
```{r}
tbl$x
```

Пример 2. `data.frame`возвращает толькол значение указанношго аргумента. В то время как tibble возвращает полностью столбец.
```{r}
tbl[, "xyz"]
```

Пример 3. С больше чем с одной колонкой при использовании  `data.frame`, программа возвращает `data.frame`, но если колонка одна, то возвращается вектор. Вроде бы это прекрасно, но с другой стороны нужно предусматривать в случае чего такие ситуации в своём коде, а это чревато ошибкой.

```{r}
tbl[, c("abc", "xyz")]
```

#### Упражнение 10.6.3
<div class="question">
If you have the name of a variable stored in an object, e.g. `var <- "mpg"`, how can you extract the reference variable from a tibble?
</div>

```{r}
var <- "mpg"

# Используем двойные скобки, чтобы вытащить содержимое переменной
df[[var]]

# Не используем знак доллара $, потому что он будет искать
df$var
```


#### Упражнение 10.6.4
<div class="question">
Practice referring to non-syntactic names in the following data frame by:

1. Extracting the variable called 1.

1. Plotting a scatterplot of 1 vs 2.

1. Creating a new column called 3 which is 2 divided by 1.

1. Renaming the columns to one, two and three.
</div>

Итак попрактикуемся с вытаскиванием

```{r}
annoying <- tibble(
  `1` = 1:10,
  `2` = `1` * 2 + rnorm(length(`1`))
)
```

1. Извлекаем переменную
```{r}
# Эта запись возвращает тиббл-столбец
annoying[1]

# Извлекаем переменную 1 как вектор
annoying$"1"

# Эта запись возвращает вектор
annoying[[1]]

# И эта запись возвращает вектор
annoying[["1"]]

# И эта запись возвращает вектор
annoying$`1`
```

1. Строим точечный график для переменных `1` и `2`
```{r}
# Создаём точечный график либо вот так
ggplot(annoying, aes(x = annoying[[1]], y = annoying[[2]])) + 
  geom_point()

# Либо вот так
ggplot(annoying, aes(x = annoying$"1", y = annoying$"2")) + 
  geom_point()

# Но лучше всего вот так!
ggplot(annoying, aes(x = `1`, y = `2`)) + 
  geom_point()
```

1. Создаём ещё один столбец

```{r}
# Можно старым знакомым методом
annoying %>%
  mutate(`3` = `2` / `1`)
```

```{r}
# Можно попроще
annoying[["3"]] <- annoying$`2` / annoying$`1`
```


1. Изменяем названия столбцов

```{r}
annoying <- rename(annoying, one = `1`, two = `2`, three = `3`)
print(annoying)
```

#### Упражнение 10.6.5
<div class="question">
What does `tibble::enframe()` do? When might you use it?
</div>

`tibble::enframe()` преобразует атомные векторы или списки в двухколонные кадры данных. Для неназванных векторов естественная последовательность используется как столбец имен.

```{r}
1:6
```

```{r}
enframe(1:6)
```


```{r}
c(a = 5, b = 7)
```

```{r}
enframe(c(a = 5, b = 7))
```

Другими словами функция преобразует именованные векторы в data frame с именами и значениями

```{r}
enframe(c(a = 1, b = 2, c = 3))
```


#### Упражнение 10.6.6
<div class="question">
What option controls how many additional column names are printed at the footer of a tibble?
</div>

За возможность выводить столбцы отвечает функция `print()`. Количеством выводимых столбцов в колонтитуле управляет параметр `n_extra`

```{r}
print(nycflights13::flights)
```


```{r}
print(nycflights13::flights, n_extra = 2)
```



<!--chapter:end:07_tibbles.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---



## Импорт данных с помощью пакета `reader`

### Введение

В этой главе я узнаю как нужно импортировать данные.

#### Необходимые ресурсы

Загружать будем при помощи инструментов библиотеки `tidyverse`

```{r}
library("tidyverse")
```

### Приступаем к работе

Большинство функций пакета `reader` связано с перемезением данных из простых текстовых файлов во фреймы данных. Все эти функции имеют сходный синтаксис

* Функция `read_csv()` читает текстовые файлы с *запятой* в качестве разделителя

* Функция `read_csv2()` читает текстовые файлы с *точку с запятой* в качестве разделителя

* Функция `read_tsv()` читает текстовые файлы с *символом табуляции* в качестве разделителя

* Функция `read_delim()` файлы с любым разделителем

* Функция `read_fwf()` читает текстовые файлы с *фиксированной шириной* полей --- либо по ширине поля с `fwf_widths()`, либо по их позиции с `fwf_positions()`

* Функция `read_table()` читает текстовые файлы с фиксированной шириной полей, в которых столбцы разделены *пробелом*


Работать в качестве примера будем с самым популярным форматом --- `read_csv()`.

Первый аргумент играет наиболее важную роль --- путь к файлу, который мы хотим прочитать.

В качестве примера возьмём простенький набор данных.
```{r}
heights <- read_csv("weight-height.csv")
```

Примечательно, что при чтении файла функция выводит спецификацию столбцов, в которой указывает тип данных.

Кроме того, можно самому сгенерировать csv-file например таким образом:

```{r}
read_csv("a, b, c
1, 2, 3
4, 5, 6")
```

В качестве названий столбцов используется первая строка. Есть несколько ситуаций, когда может понадобится изменить это поведение.

1. Некоторые файлы начинаются с нескольких строк метаданных. Их можно скипнуть аргументом `skip = n`, чтобы пропустить `n`  первых строк. Или использовать аргумент `comment = "#"` чтобы пропустить все строки начинующиеся на заданный символ `#` 

```{r}
read_csv("The first line of metadata
  The second line of metadata
  x,y,z
  1,2,3", skip = 2)

read_csv("# A comment I want to skip
  x,y,z
  1,2,3", comment = "#")
```

1. Данные могут не иметь названий столбцов. ЧТобы не обрабатывать первую строку как строку заголовкой, необходимо использовать аргумент `col_names = FALSE`. В этом случае в заголовки столбцов будут автоматически помещены последовательные метки от `X1` до `Xn`

```{r}
read_csv("1,2,3\n4,5,6", col_names = FALSE)
```

Ещё один способ, когда необходимо обозвать переменные чтобы не запутаться, передать вместе с аргументом `col_names` символьный вектор с названиями столбцов.

```{r}
read_csv("1,2,3\n4,5,6", col_names = c("x", "y", "z"))
```

Можно читать и более сложные форматы, но для этого необходимо погрузиться в дебри пакета `readr`.


#### Сравнение с базовыми возможностями R

Я уже замечал при наборе функции что R предлагает мне функцию `read.csv()` вместо желаемой `read_csv()`. Оказывается функция с точкой это базовая функция. И предпочтительно её *не использовать*. По следующим веским причинам:

* Функция `read_csv()` из пакета `readr` работает быстрее

* Функция создаёт tibble-формат со всеми вытекающими бонусами

* Их поведение воспроизводимо и не зависит от используемой операционной системы

#### Упражнение 11.2.2.1
<div class="question">
What function would you use to read a file where fields were separated with “|”?
</div>

Функция `read_delim()` читает файлы с любым разделителем. Поэтому я бы использовал её

```{r}
# read_delim(file, delim = "|")
```

#### Упражнение 11.2.2.2
<div class="question">
Apart from `file`, `skip`, and `comment`, what other arguments do `read_csv()` and `read_tsv()` have in common?
</div>

`read_csv()` и `read_tsv()` имеют следующие аргументы:

* file - Либо путь к файлу, либо соединение, либо литеральные данные (либо одна строка, либо необработанный вектор).

* delim --- Один символ используется для разделения полей в записи.

* quote --- Один символ используется для цитирования строк.

* escape_backslash --- Использует ли файл обратную косую черту, чтобы избежать специальных символов? Это более общий, чем escape_double, поскольку обратные слэши могут использоваться для исключения символа разделителя, символа кавычки или для добавления специальных символов, таких как \ n.

* escape_double --- Сохраняет ли файл кавычки, удваивая их? т. е. если этот параметр имеет значение ИСТИНА, значение "" "" представляет собой одиночную кавычку \ ".

* col_names --- Или TRUE, FALSE или символьный вектор имен столбцов.
Если TRUE, первая строка ввода будет использоваться в качестве имен столбцов и не будет включена в фрейм данных. Если FALSE, имена столбцов будут сгенерированы автоматически: X1, X2, X3 и т. Д.
Если col_names является символьным вектором, значения будут использоваться в качестве имен столбцов, а первая строка ввода будет считана в первой строке кадра выходных данных.
Названия столбцов Missing (NA) генерируют предупреждение и заполняются фиктивными именами X1, X2 и т. Д. Дублирующие имена столбцов генерируют предупреждение и становятся уникальными с числовым префиксом.

* col_types --- тип данных в столбцу

* locale --- язык по умолчанию

* na --- Символьный вектор строк для использования для отсутствующих значений. Установите этот параметр для символа (), чтобы указать отсутствие пропущенных значений.

* quoted_na --- Если отсутствующие значения внутри кавычек должны рассматриваться как отсутствующие значения (по умолчанию) или строки.

* comment --- Строка, используемая для идентификации комментариев. Любой текст после символов комментария будет игнорироваться.

* trim_ws --- Следует ли обрезать передние и конечные пробелы из каждого поля перед его разбором?

* skip --- Количество строк для пропусков перед чтением данных.

* n_max --- Максимальное количество записей для чтения.

* guess_max --- Максимальное количество записей, используемых для угадывания типов столбцов.

* progress --- Отобразить индикатор выполнения? По умолчанию он будет отображаться только в интерактивном сеансе, а не во время вставки документа. Дисплей обновляется каждые 50 000 значений и будет отображаться только в том случае, если приблизительное время показа составляет 5 секунд или более. Автоматический индикатор выполнения можно отключить, установив параметр readr.show_progress в FALSE.

можно посмотреть список общих аргументов формулой
```{r}
union(names(formals(read_csv)), names(formals(read_tsv)))
```

Разберём написанный код:

* функция `formals()` получает или устанавливает аргументы функции и показывает значения по умолчанию этих аргументов.

```{r}
formals(read_csv)
```

* функция `names()` задаёт или получает названия объекта

```{r}
names(formals(read_csv))
```

* функция `union()` сравнивает по средствам оператора `И` и объединяет наборы данных

#### Упражнение 11.2.2.3
<div class="question">
What are the most important arguments to `read_fwf()`?
</div>

Так как функция `read_fwf()` читает форматы с фиксированной шириной, то наиболее важным аргументом `read_fwf()`, является `col_positions`, который сообщает функции, где столбцы данных начинаются и заканчиваются.

#### Упражнение 11.2.2.4
<div class="question">
Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like `"` or `'`. By convention, `read_csv()` assumes that the quoting character will be `"`, and if you want to change it you’ll need to use `read_delim()` instead. What arguments do you need to specify to read the following text into a data frame?

```{r}
"x,y\n1,'a,b'"
```
</div>

Привыкаем орудовать с именованием.
```{r}
# Сначала присваиваем заданный набор символов в переменную
x <- "x,y\n1,'a,b'"
# Для чтения этого набора символов как фрейм данных, используем функцию read_csv()
# Нам нужно выделить элемент, не нарушая его целостности
# Для этого нужно процитировать текст как есть. Это умеет аргумент quote
# Объявим знаком начала-окончания цитаты одинарную ковычку
read_csv(x, quote = "'")
```

#### Упражнение 11.2.2.5
<div class="question">
Identify what is wrong with each of the following inline CSV files. What happens when you run the code?
</div>

Разберём каждый пример

1. В этом примере в строке заголовка 2 объекта, а в строках значений по три.
```{r}
read_csv("a,b\n1,2,3\n4,5,6")
```

Программа "удаляет" или если угодно скрывает значения, для которых не объявлен заголовок. Чтобы прочитать всё как следует, необходимо добавить ещё одно название столбца:
```{r}
read_csv("a,b,c\n1,2,3\n4,5,6")
```

1. Этот пример можно интерпретировать разными способами, но я буду придерживаться следующего.
Примем за данность, что перенос всегда строки ставится корректно. Я делаю такое предположение, чтобы не вносить значения данных вручную.
```{r}
read_csv("a,b,c\n1,2\n1,2,3,4")
```

Тогда в этом случае в примере пропущено название одного столбца, и пропущены значения в первой строке в двух последнийх столбцах. Добавим ещё один столбец.
```{r}
read_csv("a,b,c,d\n1,2\n1,2,3,4")
```

1. В этом примере не совсем ясно что должно происходить.

```{r}
read_csv("a,b\n\"1")
```

НАчальная цитата "1 не рассматривается, потому что она не закрыта. И значения для столбца `а` рассматривается как целое число 1.
Даже не стану исправлять.

1. Тоже не совсем ясно. Оба столбца выводятся хорошо, и являются символьными, потому что вы каждом содержатся буквы.

```{r}
read_csv("a,b\n1,2\na,b")
```

Можно интерпретировать по разному, например вот так: что в столбец `а` автор хотел поместить значения `1,2`, а в столбец `b` --- `a,b`. 

1. В этом используется разделитель точка с запятой вместо просто запятой.

```{r}
read_csv("a;b\n1;3")
```

Это легко исправить, если использовать функцию `read_csv2`

```{r}
read_csv2("a;b\n1;3")
```

### Синтаксический анализ векторов

Парсинг --- это синтаксический анализ. 
Функции семейства `parse_*()` принимают символьный вектор и возвращают вектор специализированного типа.

```{r}
str(parse_logical(c("TRUE", "FALSE", "NA")))
str(parse_integer(c("1", "2", "3")))
str(parse_date(c("2010-01-01", "1979-10-14")))
```

Функция `str()` --- Компактно отображает внутреннюю структуру объекта R, диагностическую функцию и альтернативу сводке (и в некоторой степени, dput). В идеале отображается только одна строка для каждой «базовой» структуры. Он особенно хорошо подходит для компактного отображения (сокращенного) содержимого (возможно, вложенных) списков. Идея состоит в том, чтобы дать разумный результат для любого объекта R. Он вызывает args для (не-примитивных) объектов функции.

Функции этого семейства унифицированны --- их первый аргумент, это символьный вектор подлежащий анализу. Аргумент `na` указывает на то какие строки считать пропущенными значениями

```{r}
parse_integer(c("1", "231", ".", "456"), na = ".")
```

В случае неуспешного парсинга элемента выводится соответствующее сообщение

```{r}
x <- parse_integer(c("123", "345", "abc", "123.45"))
```

Такие элементы при выводе отмечаются как отсутсвующие элементы

```{r}
x
```

Чтобы изучить полный набор ошибок парсинга можно воспользоваться функцией `problems()`. Он возвращает tibble-frame которым можно манипулировать с помощью пакета `dplyr` 

```{r}
problems(x)
```

Эффективное выполнение парсинга требует знания того , какие парсеры имеются в вашем располряжении и как они обрабатывают различные типы входных данных. Чаще всего используются девять парсеров:

* `parse_logical()` и `parse_integer()` --- парсинг логических и целочисленных значений соответственно. Никаких затруднений при работе с ними в основном не возникает.

* `parse_double()` строгий числовой парсер, тогда как  `parse_number()` --- гибкий числовой парсер. Работать с ними сложнее, по скольку в разных странах числа записываются по разному.

* `parse_character()` --- символьный парсер, пригодится для того чтобы перекидывать символьные кодировки.


* `parse_factor()` --- создает факторы, или структуры данных, которые R использует для предоставления категориальных переменных, т.е. переменных, имеющих известный фиксированный набор возможных значений.

* `parse_datetime()`, `parse_date()`, and `parse_time()` --- позволяют анализировать значения даты и времени, заданные в соответствии с различными спецификащиями. Эти парсеры отличаются наибольшей сложностью ввиду существования множества различных форматов записи дат и времени.

#### Парсинг чисел

Парсинг чисел осложняется следующими обстоятельствами:

1. В разных странах числа записывают по-разному --- разделение бывает точкой, а бывает запятой

2. Числа окружены другими символами, обеспечивающими определённый контекст `100%` `$1007`

3. Числа часто содержат разделители групп разрядов `100,000,000`.  При чём в разных странах для этих целей могут использоваться разные символы.

Чтобы справиться с первой проблемой в введено понятие локали --- объекта определяющего правила парсинга. Можно задавать при помощи локали символ разделяющий десятичного разделителя.

```{r}
parse_double("1.23")

parse_double("1,23", locale = locale(decimal_mark = ","))
```

По умолчанию используется локаль для США. 

Чтобы справиться со второй проблемой нужно использовать `parse_number()` --- она игнорирует символы которые располагаются непосредственно перед числом и после него.

```{r}
parse_number("$100")
parse_number("20%")
parse_number("It cost $123.45")
```

Последняя проблема решается путём совместного использования фнкции `parse_number()` и локали, которая задает символ, группирующий цифры по разрядам.

```{r}
# Используется в США
parse_number("$123,456,789")
```

```{r}
# Используется во многих европейских странах
parse_number(
  "$123.456.789",
  locale = locale(grouping_mark = "."))
```

```{r}
# Используется в Швейцарии
parse_number(
  "$123'456'789",
  locale = locale(grouping_mark = "'"))
```

#### Парсинг строк

Разберёмся как строки представляются в компьютере. Чтобы в R получить строку в том виде, в каком она хранится в памяти компьютера, следует использовать функцию `charToRaw()`.

```{r}
charToRaw("Stanislav")
```

Выдача --- это числа в шестнадцатиричном формате. Каждое число это байт информации.  

КОдирование --- это отображение шестнадцатиричного числа в символ. Используемый в данном случае код называется ASCII (American Standard Code for Information Interchange --- американский стандартный код для обмена информацией).

В случае языков отличных от английского не всё так просто. Поэтому везде используется негласный стандарт --- UTF8.
Но не во всех случаях используется нужная кодировка. Иногда помогает определить кодировку функция `parse_character()`:

```{r}
x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"

parse_character(x1, locale = locale(encoding = "Latin1"))
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
```

Вот более подробная информация по кодированию-декодированию
[http://kunststube.net/encoding/](http://kunststube.net/encoding/)

#### Факторы

Факторы используются в R для представления *категориальных* значений, т.е. значений образующих известный набор.

```{r}
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)
```

#### Календарные даты, календарные дата и время, время суток

Есть три вида парсинга даты-времени, который зависит от того, что необходимо в конкретной задаче

* Функция `parse_datetime()` ожидает значение определяющее дату и время в соответствии со стандартом ISO8601. ФОрмат такой --- ГГГГ-ММ-ДД ЧЧ:ММ:СС

```{r}
parse_datetime("2010-10-01T2010")
```

* Функция `parse_date()` если нам надо вытащить дату, ожидает значение в одном из форматов ГГГГ-ММ-ДД или ГГГГ/ММ/ДД

```{r}
parse_date("2010-10-01")
```

* Функция `parse_time()` ожидает значение в формате ЧЧ:ММ:СС с необязательным спецификатором a.m./p.m (до полудня/после полудня). Так как в базовых пакетах отсутствует специальный класс, для работы со временем суток принято использовать для этого класс, предоставляемый пакетом `hms`

```{r}
library(hms)
parse_time("01:10 am")
```

Если эти форматы не подходят, можно задать свой.

Year
: `%Y` (4 цифры). 
: `%y` (2 цифры); 00-69 -> 2000-2069, 70-99 -> 1970-1999.

Month
: `%m` (2 цифры).
: `%b` (сокращенное название, например "Jan").
: `%B` (полное название, "January").

Day
: `%d` (2 цифры).
: `%e` (необязательный ведущий пробел).

Time
: `%H` 0-23 часовой формат.
: `%I` 0-12, следует использовать вместе `%p`.
: `%p` AM/PM indicator.
: `%M` минуты.
: `%S` целочисленные секунды.
: `%OS` вещественные секунды.
: `%Z` часовой пояс (as name, e.g. `America/Chicago`). 
: `%z` (смещение от UTC, e.g. `+0800`). 

Нецифровые символы
: `%.` пропуск одного нецифрового символа.
: `%*` пропуск любого количества нецифровых символов.

Лучший способ определить корректный формат --- создать несколько примеров в символьном векторе и протестировать их с помощью одной из функций анализаторов
```{r}
parse_date("01/02/15", "%m/%d/%y")
parse_date("01/02/15", "%d/%m/%y")
parse_date("01/02/15", "%y/%m/%d")
```

В случае использования элементов формата  `%b` или `%B` с названием месяцев не на английском необходимо задать аргумент  `lang` функции `locale`
```{r}
parse_date("3 сентября 2018", "%d %B %Y", locale = locale("ru"))
```

#### Упражнение 11.3.5.1
<div class="question">
What are the most important arguments to `locale()`?
</div>

Наиболее важными аргументами является
 
* `date_format, time format` которые указывают формат даты и времени

* `encoding` кодировка

* `decimal_mark, grouping_mark` разделитель

* `tz` часовой пояс 

#### Упражнение 11.3.5.2
<div class="question">
1. What happens if you try and set `decimal_mark` and `grouping_mark` to the same character? 

2. What happens to the default value of `grouping_mark` when you set `decimal_mark` to `","`? 

3. What happens to the default value of `decimal_mark` when you set the `grouping_mark` to `"."`?
</div>

1. Должна произойти ошибка, потому что интерпретатор попадёт в вилку, что считать десятичным разделитем а что группировкой (так и есть)

```{r}
#parse_number(
#  "$123.456.789",
#  locale = locale(grouping_mark = ".", decimal_mark = "."))
```

2. Не знаю, вероятно `grouping_mark` изменит своё значение на точку (так и есть)

```{r}
locale(decimal_mark = ",")
```

3. Вероятно так же как и в примере выше, `decimal_mark` изменит своё значение на запятую 

```{r}
locale(grouping_mark = ".")
```


#### Упражнение 11.3.5.3
<div class="question">
I didn’t discuss the `date_format` and `time_format` options to `locale()`. What do they do? Construct an example that shows when they might be useful.
</div>

```{r}
locale()
```

По умолчанию заданы форматы `%AD` и `%AT` для соответственно даты и времени.

```{r}
parse_date("1 января 2018", "%d %B %Y", locale = locale(date_names = "ru", date_format = ))

parse_date("21 окт. 1991", "%d %b %Y", locale = locale("ru", time_format ="ioojdpijsdf" ))
```

Сложно придумать пример, если они на что-то и влияют, то мне не удалось придумать пример


#### Упражнение 11.3.5.4
<div class="question">
If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly.
</div>

Да я живу за пределами Штатов, но пожалуй менять настройки пока что не буду. При случае, если это понадобится надо будет почитать хэлп к локали `?locale`

#### Упражнение 11.3.5.5
<div class="question">
What’s the difference between `read_csv()` and `read_csv2()`?
</div>

* Функция `read_csv()` читает текстовые файлы с *запятой* в качестве разделителя

* Функция `read_csv2()` читает текстовые файлы с *точку с запятой* в качестве разделителя

#### Упражнение 11.3.5.6
<div class="question">
What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out.
</div>

UTF-8 стандарт. Еще уважаемый Скоморохов завещал в любой непонятной ситуации юзать ютф. Вот небольшой расклад по странам и регионам.

* Japanese: JIS X 0208, Shift JIS, ISO-2022-JP
* Chinese: GB 2312, GBK, GB 18030
* Korean: KS X 1001, EUC-KR, ISO-2022-KR
* Western European Latin script languages: ISO-8859-1, Windows-1250 (also CP-1250 for code-point)
* Eastern European Latin script languages: ISO-8859-2, Windows-1252
* Greek: ISO-8859-7
* Turkish: ISO-8859-9, Windows-1254
* Hebrew: ISO-8859-8, IBM424, Windows 1255
* Russian: Windows 1251
* Japanese: Shift JIS, ISO-2022-JP, EUC-JP
* Korean: ISO-2022-KR, EUC-KR
* Chinese: GB18030, ISO-2022-CN (Simplified), Big5 (Traditional)
* Arabic: ISO-8859-6, IBM420, Windows 1256

почитать [http://kunststube.net/encoding/](http://kunststube.net/encoding/)

#### Упражнение 11.3.5.7
<div class="question">
enerate the correct format string to parse each of the following dates and times:
</div>

```{r}
d1 <- "January 1, 2010"
d2 <- "2015-Mar-07"
d3 <- "06-Jun-2017"
d4 <- c("August 19 (2015)", "July 1 (2015)")
d5 <- "12/30/14" # Dec 30, 2014
t1 <- "1705"
t2 <- "11:15:10.12 PM"
```


```{r}
parse_date(d1, "%B %d, %Y")
parse_date(d2, "%Y-%b-%d")
parse_date(d3, "%d-%b-%Y")
parse_date(d4, "%B %d (%Y)")
parse_date(d5, "%m/%d/%y")
parse_time(t1, "%H%M")
parse_time(t2, "%H:%M:%OS %p")
```

### Синтаксический анализ файлов

Разберём два момента

* как пакет `readr` автоматически определяет тип каждого столбца

* как изменить параметры, заданные по умолчанию

#### Стратегия

Для определения каждого типа столбца используется эвристический подход --- берутся первые 1000 строк, и для определения типа столбцов используются эвристические алгоритмы. Это выглядит примерно так --- функция `guess_parser` возвращает наилучшую догадку, `parse_guess` - использует эту догадку для анализа столбца.

```{r}
guess_parser("2010-10-01")
guess_parser("15:01")
guess_parser(c("TRUE", "FALSE"))
guess_parser(c("1", "5", "9"))
guess_parser(c("12,352,561"))

str(parse_guess("2010-10-10"))
```

Эвристика подсчитывает каждый из перечисленных ниже типов, останавливая процесс в случае совпадения:

* logical: содержит только "F", "T", "FALSE", or "TRUE".
* integer: содержит тольцо цифровые символы и ещё `-`.
* double: содержит только допустимые вещественные числа (включая `4.5e-5`).
* number: содержит вещественные числа с разделителями групп разрядов
* time: соответствует формату `time_format`, заданному по умолчанию
* date: соответствует формату `date_format`, заданному по умолчанию
* date-time: любая дата в формате ISO8601

Если ни одно из этих правил не применимо столбец остаётся в виде вектора строк.

#### Проблемы

* Первая тысяча строк может быть не показательной, вследствие чего догадки пакета `readr` окажутся не достаточно общими. Например может быть столбец вещественных значений в первых 1000 строках которого содержатся только целые числа

* СТолбец может содержать множество отсутствующих значений. Если первая тысяча строк содержит лишь значения `NA`, то пакет `readr` сочтет, что это символьный вектор, тогда как вероятно хотелось бы выбрать более специфический способ обработки

Пакет `readr` содержит текстовый csv-файл который иллюстрирует обе проблемы

```{r}
challenge <- read_csv(readr_example("challenge.csv"))
```

```{r}
problems(challenge)
```

*Неплохая стратегия обрабатывать столбец за столбцом пока проблемы не исчезнут.* В данном случае видно, что проблемы связаны со столбцом `x` --- в нем за целочисленными значениями следуют хвостовые символы. Это наводит на мысль что надо использовать парсер вещественных чисел.

Начнем с того, что скопируем и вставим спецификаци столбца в первоначальный вызов

```{r}
challenge <- read_csv(
  readr_example("challenge.csv"),
  col_types = cols(
    x = col_integer(),
    y = col_character()
  )
)
```

Попробуем, не получилось. Значит поправим тип столбца

```{r}
challenge <- read_csv(
  readr_example("challenge.csv"),
  col_types = cols(
    x = col_double(),
    y = col_character()
  )
)
```

Это помогло устранить первую проблему, но если мы присмотримся к нескольким последним строкам, то заметим что они содержат даты, сохраненные в символьном векторе.

```{r}
tail(challenge)
```

Это можно исправить, указав что этот столбец является столбцом дат

```{r}
challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double(),
    y = col_date()
  )
)
tail(challenge)
```

Для каждой функции `parse_xyz()` имеется соответствующая функция `col_xyz()`. Функция `parse_xyz()` используется в тех случаях, когда данные уже находятся в R в виде символьного вектора, а функция `col_xyz()` --- когда нужно сообщить пакету `readr` как нужно загружать данные.

Нам рекомендуют всегда предоставлять типы столбцов, отталкиваясь от вывода, обеспечиваемого пакетом `readr`. Так наш сценарий импорта данных всегда будет согласованным и воспроизводимым.

#### Другие страгтегии 

Существует несколько других общих стратегий

* В предыдущем примере нам просто не повезло, стоило просмтротреть файла всего на одну строку больше, и мы могли бы кооректно выпонлить анализз одним махом:

```{r}
(challenge2 <- read_csv(readr_example("challenge.csv"), guess_max = 1001))
```

* Иногда проще всего диагностировать проблему, прочитав все столбцы как символьные векторы
```{r}
challenge2 <- read_csv(readr_example("challenge.csv"),
                       col_types = cols(.default = col_character()))
```

Такой подход особенно полезно использовать в сочетании с функцией `type_convert()`. Она применяет эти эвристики парсинга к символьным столбцам фрейма данных.


```{r}
(df <- tribble(
  ~x, ~y,
  "1", "1.21",
  "2", "2.32",
  "3", "4.56"
))
```
Были строковые значения

```{r}
# обратите внимание на типы столбцов
type_convert(df)
```
Оп и теперь это числа, целые и натуральные

* При чтении очень больших файлов имеет смысл установить для параметра `n_max` меньшее значение например 100.000 или около того. Это ускорит итерации по странению распространенных проблем

* В случае более сложных проблем иногда проще читать данные в символьный вектор строк с помощью функции `read_lines()` или даже в символьный вектор длинной 1 с помощью функции `read_file()`. После этого вы сможете применить методы синтаксического анализа строк, с которыми ознакомитесь позже


### Запись в файл

В пакете `readr`  есть две функции `write_csv()` и `write_tsv()`, которые практически гарантируют что данные будут считываться корректно, потому что

* функции всегда используеют кодировку UTF8

* всегда сохраняют календарные даты и время в формате  ISO8601, и поэтому их последующий парсинг на других компьютерах не будет вызывать проблем

Можно экспортировать csv сразу в эксель при помощи функции `write_excel_csv()` вероятно тоже бывает полезно. `x` --- сам файл, `path` --- расположение, в котором должен быть сохранён файл, `na` --- как должны записываться отсутствующие данные

```{r}
write_csv(challenge, "challenge.csv")
```

Заметим однако, что при сохранении информация о типах теряется.
```{r}
challenge
```

Для кэширования csv-файлы не надёжны. Но в подобных ситуациях можно действовать двумя способами

* Можно воспользоваться функциями `write_rds()` и `read_rds`, которые служат оболочками для базовых функций `saveRDS()` и `readRDS()`. Они сохраняют данные в настриваемом двоичном формате R, носящем название RDS

```{r}
write_rds(challenge, "challenge.rds")
read_rds("challenge.rds")
```

* Пакет `feather` реализует быстрый двоичный формат файлов совместимый с другими языками программирования.

```{r}
#install.packages("feather")
library("feather")
write_feather(challenge, "challenge.feather")
read_feather("challenge.feather")
```

Обычно пакет работает быстрее RDS и преминим вне R. 


### Другие типы данных

Для переменщения других типов в R рекомендуют:

* Пакет `haven` читает файлы приложений SPSS, Stata, SAS

* Пакет `readxl` читает файлы  Эксель

* Пакет `DBI` совместно с серверами баз данных обеспечивает выполнение SQL-запросов к базам данных и возвращение фреймов данных.

* `jsonlite` для чтения JSON

* `xml2` для XML


<!--chapter:end:08_data_import.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---


## Аккуратизация данных с помощью пакета `tidyr`

### Введение

В этой главе будем узнавать что такое аккуратные данные. Больше про это рассказал Хэдли Уикем в своей [статье](http://www.jstatsoft.org/v59/i10/paper)

#### Необходимые ресурсы

Подключаем библиотеку

```{r}
library("tidyverse")
```


### Аккуратные данные

Существует три правила, соблюдение которых делает набор данных аккуратным:

* каждая переменная должна иметь собственный столбец

* каждое наблюдение должно иметь собственную строку

* каждое значение должно иметь собственную ячейку

Все они взаимосвязаны --- без одного не может быть дву других. Всё это хорошо иллюстрирует изображение

![alt text](img/tidy-1.png)

Всё можно упростить до двух правил 

1. Помещать каждый набор данных в tibble-фрейм

1. Помещеать каждую переменную в столбец

В учебнике было не понятно почему на оси лет такое странное отображение годов.
```{r}
library("ggplot2")
ggplot(table1, aes(year, cases)) +
  geom_line(aes(group = country), color = "grey50") +
  geom_point(aes(color = country)) 
```

Но когда построил сам врубился --- между точками построения двух годов программа просто добавила 4 промежутка по 0.25

#### Упражнения 12.2.1.1
<div class="question">
Using prose, describe how the variables and observations are organised in each of the sample tables
</div>

```{r}
table1
table2
table3
table4a
table4b
```

1. Таблица 1

Таблица состоит из четырех столбцов-переменных. 
Первый столбец --- категориальная переменная, в которую входят названия трёх стран. 
Второй столбец --- это тоже категориальная переменная, в которой содержатся года в которые происходили наблюдения их два. 
Третий столбец --- это непрерывная переменная "случаи", которая показывает количество случаев происходящих в каждой стране в указанный год
Четвёртый столбец --- тоже непрерывная переменная, которая показывает количество населения соотвтствующее комбинации страна-год-случай

Или если совсем просто:

* Одно наблюдение соответствует одной строке. 
* Одна переменная соответствует одному наблюдению. 
* Одна ячейка соответствует одному значению.

1. Таблица 2

* Одно наблюдение разбито переменной (type) на две строки. В остальном, всё хорошо:
* Одна переменная соответствует одному столбцу
* Одна ячейка соответствует одному значению.

1. Таблица 3

* Одно наблюдение соответствует одной строке. 
* Одна переменная соответствует одному наблюдению. 
* Но в одной ячейке содержится два значения --- (cases/population)

1. Таблицы 4а, 4b

В отдельности эти таблицы являются аккуратными. Но так как они описывают одно измерение, произведено неудобное разделение по переменным ---- (cases) таблица `а` и (population) таблица `b`

#### Упражнения 12.2.1.2
<div class="question">
Compute the rate for table2, and table4a + table4b. You will need to perform four operations:

a) Extract the number of TB cases per country per year.
b) Extract the matching population per country per year.
c) Divide cases by population, and multiply by 10000.
d) Store back in the appropriate place.
e) Which representation is easiest to work with? Which is hardest? Why?</div>
</div>

a) Не очень хорошо получилось. Потому что это просто один столбец значений, без указания года в котором произошло событие.

```{r}
t2_cases <- filter(table2, type == "cases")           # Извлекаем число случаев заболевания
t2_population <- filter(table2, type == "population") # Извлекаем число популяции
t2_rate <- t2_cases$count / t2_population$count * 10000     # Находим отношение
rate <- as_tibble(t2_rate)                            # Сохраняем куда-то
```

Поэтому немного переделаем, чтобы было по красоте

```{r}
t2_cases <- filter(table2, type == "cases") %>%            # Извлекаем число случаев заболевания
  rename(cases = count) %>%                                # Переименовываем стобец
  arrange(country, year)                                   # Сортируем, чтобы избежать ошибок
t2_population <- filter(table2, type == "population") %>%  # Действуем по аналогии и для популяции
  rename(population = count) %>%
  arrange(country, year)
t2_rate <- t2_cases %>% 
  mutate(population = t2_population$population,            # Добавляем переменную популяции
         cases_per_cap = (cases / population) * 10000) %>% # Добавляем переменную с отношением
  select(country, year, cases_per_cap)                     # Оставляем только нужное
```

b) Грязненько это вот так. Разделить отдельно каждый год, и объединить полученные вектора в одну матрицу, а её превратить в тиббл таблицу. Это решение в лоб.

```{r}
table4_1999 <- table4a$`1999` / table4b$`1999` * 10000
table4_2000 <- table4a$`2000` / table4b$`2000` * 10000
table4_rate <- as.tibble(cbind(table4_1999, table4_2000))
```

Элегантнее вот так вот:

```{r}
table4c <-
  tibble(country = table4a$country,
         `1999` = table4a[["1999"]] / table4b[["1999"]] * 10000,
         `2000` = table4a[["2000"]] / table4b[["2000"]] * 10000)
```

Я уже говорил выше, что таблицы 4а и 4b в отрыве друг от друга аккуратные tibble таблицы. Поэтому с ними проще и приятнее работать, чем с "грязной" таблицей номер 2.

#### Упражнения 12.2.1.3
<div class="question">
Recreate the plot showing change in cases over time using table2 instead of table1. What do you need to do first?
</div>

Для того чтобы построить график, нужно для начала высчитать то, что мы проделали в упражнении 2: извлечь все значения для каждого года в отдельности.

```{r}
ggplot(t2_rate, aes(year, cases_per_cap)) +
  geom_line(aes(group = country), color = "grey50") +
  geom_point(aes(color = country))
```

### Рассредоточение и сведение столбцов

Чаще всего придётся иметь дело с неаккуратными данными, потому что

* Большинство людей не знакомы с принципами аккуратных данных

* Чаще всего данные используют таким образом чтобы упростить ввод, а не анализ

Для большинства видов практического анализа мне чаще всего предстоит приводить данные в аккуратный вид. Для это прежде всего предстоит выяснить какие переменные и наблюдения имеются --- что у нас в столбцах и что в строках. Иногда это бывает просто, но в большинстве случаев необходимо интервьюировать тех людей, которые эти данные вносили. На этом этапе как правило предстоит реашть одну из некоторых задач:

* одна перменная может быть разнесена по нескольким столбцам

* одно наблюдение может быть рассредоточено по нескольким строкам

Типичные наборы данных страдают одним из этих недостатков. Столкнувшись сразу с двумя из них надо понимать, что мне крупно неповезло. Чтобы решать эти проблемы мне пригодятся две функции `gather()` и `spread()`.

#### Сведение столбцов (gather)

На примере набора данных `table4a` покажем что часто названия столбцов являются значениями переменных

```{r}
table4a
```

Названия столбцов здесь `1999` и `2000` это значения перменной `year`, а каждая строка представляет два наблюдения, а не одно

ЧТобы привести набор данных, подобный этому к аккуратному виду, мы должны свести стобцы в новую пару переменных. Для описания этой операции нам понадобится следующие три параметра

* Набор столбцов, которые прдеставляют значения, а не переменные. В данном примере таковым являются стобцы `1999` и `2000`.

* Имя переменной, значения которой образуют имена столбцов. Этот парамер `key`, а переменная в данном примере является `year`.

* Имя переменной, значения которой рассредоточены по ячейкам. Это параметр `value`, а переменной в данном случае является количество случаев заболевания.

Все эти параметры используются при вызове функции `gather()`

```{r}
table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")
```

Наглядно это делается следующим образом:
![alt text](img/tidy-9.png)

Столбцы, которые необходимо светсти, указываются с использованием нотации в стиле `dplyr::select()`. В данном случае таких столбцов только два, поэтому мы задаем их по отдельности.

ТО же самое проделывается по сути и для популяции

```{r}
table4b %>% 
  gather(`1999`, `2000`, key = "year", value = "population")
```

А теперь, чтобы их свести используется функция, о которой я узнаю чуть позже. Она чудесным образом (пока что)
 объединяет фреймы данных

 
```{r}
tidy4a <- table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")
tidy4b <- table4b %>% 
  gather(`1999`, `2000`, key = "year", value = "population")

left_join(tidy4a, tidy4b)
```
 
 Очень полезная функция для объединения столбцов.
 
#### Рассредоточение столбцов (spreading)

Это, по сути обратная операция сбору столбцов. Эту операцию используют когда наблюдения разбиты по нескольким строкам. Как в случае, например `table2` --- наблюдением является страна, в определённом году, но каждое наблюдение распределно по двум строкам

```{r}
table2
```

Чтобы привести эту таблицу к аккуратному виду, необъодимо определить ключевой столбец с названиями переменных. В данном примере это столбец `type`. И определить столбец со значениями переменных, это столбец `count`. Как только мы это определили можно использовать функцию `spread()`. 

```{r}
spread(table2, key = type, value = count)
```

Схематично это выглядит так, как показано на картинке:

![alt text](img/tidy-8.png)

Обе рассмотренные в этом параграфе функции `gather()` и `spread()` взаимодополняемые. Первая делает таблицы уже и длиннее, вторая длинные таблицы шире и короче

#### Упражнение 12.3.3.1
<div class="question">
Why are `gather()` and `spread()` not perfectly symmetrical?
Carefully consider the following example:

```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2016, 2016),
  half  = c(   1,    2,     1,    2),
  return = c(1.88, 0.59, 0.92, 0.17)
)
stocks %>% 
  spread(year, return) %>% 
  gather("year", "return", `2015`:`2016`)
```

(Hint: look at the variable types and think about column names.)

Both `spread()` and `gather()` have a `convert` argument. What does it do?
</div>

В объявленной переменной столбцы это численные значения с типом данных `<dbl>`. Функция `spread()` разбивает столбец `year` с числовыми значениями и делает из них названия столбцов. Затем функция `gather()` из названий столбцов делает значения для новой переменной. Новая переменная получается строковой с типом данных `<chr>`. Именно поэтому эти две функции *взаимодополняемые* а не *взаимообратные*!

Аргумент `convert()` позволяет конвертировать названия переменных при необходимости в числовой тип данных. По умолчанию у этого аргумента значение `FALSE`, поэтому не происходит конвертации при обычном вызове функции.

```{r}
stocks %>% 
  spread(year, return) %>% 
  gather("year", "return", `2015`:`2016`, convert = TRUE)
```

Забавно, однако и это не позволяет сделать эти функции идеально взаимообратными, по скольку даже в этом примере видно, что сконвертированная перменная имеет тип данных `<int>`, вместо изначального `<dbl>`.


#### Упражнение 12.3.3.2
<div class="question">
Why does this code fail?
```{r}
# table4a %>% 
#  gather(1999, 2000, key = "year", value = "cases")
```
</div>

Потому что названия столбцов здесь указаны числами в явном виде. Тогда как для того чтобы объявить числовые названия столбцов необходимо заключить их в апострофы

```{r}
table4a %>% 
  gather('1999', '2000', key = "year", value = "cases")
```


#### Упражнение 12.3.3.3
<div class="question">
Why does spreading this tibble fail? How could you add a new column to fix the problem?

```{r}
# people <- tribble(
#  ~name,             ~key,    ~value,
#  #-----------------|--------|------
#  "Phillip Woods",   "age",       45,
#  "Phillip Woods",   "height",   186,
#  "Phillip Woods",   "age",       50,
#  "Jessica Cordero", "age",       37,
#  "Jessica Cordero", "height",   156
# )
```
</div>

Не получается выполнить разбиение по переменным, потому что не проставлен номер измерения.

```{r}
# people %>%
#  mutate(observation = c(1, 1, 2, 1, 1)) %>% # Проставил номер измерения
#  spread(key, value)
```

#### Упражнение 12.3.3.4
<div class="question">
Tidy the simple tibble below. Do you need to spread or gather it? What are the variables?

```{r}
preg <- tribble(
  ~pregnant, ~male, ~female,
  "yes",     NA,    10,
  "no",      20,    12
)
```
</div>

Для того чтобы в строках были наблюдения, а в столбца параметры, нам нужно сводить этот фрейм данных. Делать более длинную таблицу.

```{r}
preg1 <-  preg %>%
  gather("male", "female", key = "sex", value = "count")
```

Тут можно пойти дальше и увидеть что два столбца принимают только два возможных знаения. Это значит, что их можно перевести в вектор логических значений

```{r}
(preg2 <- preg1 %>%
  mutate(female = sex == "female",
         pregnant = pregnant == "yes") %>%
  select(pregnant, count, female))         # Для того чтобы отсечь ненужный столбец sex
```

Тут можно ещё подумать о необходимости отбросить наблюдение беременных мужчин, но об этом узнаем чуть позже.

### Разделение и объединение столбцов

Взглянем ещё раз на фрейм данных
```{r}
table3
```

В ней в одной переменной `rate` содержится два значения --- `cases` и `population`, для того чтобы разделить эти переменные нам понадобится функция `separate()`.


#### Разделение столбцов при помощи функции `separate()`

Разделение производится всякий раз когда встречается символ разделитель. Это происходит автоматически:

```{r}
table3 %>%
  separate(rate, into = c("cases", "population"))
```

Но можно задать разделитель в явном виде при помощи аргумента `sep`

```{r}
table3 %>%
  separate(rate, into = c("cases", "population"), sep = "/")
```

Формально, `sep` это регулярное выражение, но об этом чуть позже.

При разделении столбцов полученные новые столбцы имеют символьный тип. Это поведение в функции `separate()` задано по умолчанию --- для того чтобы оставлять тип столбца таким, какой он есть. В этой функции однако, предусмотрена возомжность конвертировать получаемые столбцы, как и у предыдущих функций этого семейства.

```{r}
table3 %>%
  separate(rate,
           into = c("cases", "population"),
           convert = TRUE
           )
```

МОжно так же отделять столбцы по количеству символов. Это можно осуществить передавая в аргумент `sep` целочисленное значение. При этом необходимо придерживаться правил:

* При разбиение строк с использованием целых чисел, длина `sep` должна быть на единицу меньше количества имён в `into`.
* Положительные значения начинаются с 1 и отсчитываются от крайней слева позиции в строках
* Отрицательные значения начинается с -1 и отсчитываются от крайней правой позиции в строках

#### Объединение столбцов при помощи функции `unite()`

Объединение используется реже, но тоже бывает полезно. Например, нам пригодится соединить два столбца, чтобы получить год
```{r}
table5 %>%
  unite(new, century, year)
```

По умолчанию используется разделитель `_`. Нам он тут не нужен, поэтому зададим разделитель в явном виде

```{r}
table5 %>%
  unite(new, century, year, sep = "")
```


#### Упражнение 12.4.3.1
<div class="question">
What do the extra and fill arguments do in separate()? Experiment with the various options for the following two toy datasets.

```{r}
tibble(x = c("a,b,c", "d,e,f,g", "h,i,j")) %>% 
  separate(x, c("one", "two", "three"))

tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
  separate(x, c("one", "two", "three"))
```
</div>

Параметр `extra` определяет что делать с переполняющими значениями. У `extra` есть три опции 
```{r}
t1 <- tibble(x = c("a,b,c", "d,e,f,g", "h,i,j"))

separate(t1, x, c("one", "two", "three"), extra = "warn")
# «warn» (по умолчанию): выдаёт предупреждение и отбрасывает дополнительные значения.

separate(t1, x, c("one", "two", "three"), extra = "drop")
# «drop»: отбрaсывает любые дополнительные значения без предупреждения.

separate(t1, x, c("one", "two", "three"), extra = "merge")
# «merge»: добавляет переполняющие значения в месте где они есть

```

Теперь посмотрим второй пример, и параметр `fill`. Этот параметр используется, когда не хватает значений, он определяет что делать, если значений не хватает,

```{r}
t2 <- tibble(x = c("a,b,c", "d,e", "f,g,i"))

separate(t2, x, c("one", "two", "three"), fill = "warn")
# «warn» (по умолчанию): выдаёт предупреждение и заполняет справа пропущенным значением NA

separate(t2, x, c("one", "two", "three"), fill = "right")
# заполняет справа пропущенным значение NA

separate(t2, x, c("one", "two", "three"), fill = "left")
# заполняет слева пропущенным значение NA
```

#### Упражнение 12.4.3.2
<div class="question">
Both `unite()` and `separate()` have a `remove` argument. What does it do? Why would you set it to FALSE?
</div>

Параметр `remove`, если `TRUE` удаляет входной стобец из выходных данных. 

Входной столбец может понадобится например в случаях объединения. Когда нам важна информация во входном столбце, отдельно от объединяемого столбца. Например, в случае ниже, нам может пригодится век измерения для совокупной проверки по одному столетию

```{r}
table5 %>%
  unite(new, century, year, sep = "", remove = FALSE)
```

#### Упражнение 12.4.3.3
<div class="question">
Compare and contrast `separate()` and `extract()`. Why are there three variations of separation (by position, by separator, and with groups), but only one unite?
</div>

Разделение при помощи `separate()` является частным и статичным, нужно знать либо разделяющий символ, либо позицию

```{r}
# разделение с разделителем
tibble(x = c("male-34", "female-12", "male-19", "female-42")) %>%
  separate(x, c("sex", "age"), sep = "-")

# разделение по позиции - второй с конца
tibble(x = c("male34", "female12", "male19", "female42")) %>%
  separate(x, c("sex", "age"), sep = c(-2))
```

Разделение при помощи `extract()` является более гибким, поскольку для него не требуются общие разделители или конкретные позиции столбцов.

```{r}
tibble(x = c("male-34", "female-12", "male-19", "female-42")) %>%
  extract(col = x, into = c("sex", "age"), regex = "([a-z]+)-([0-9]+)")
```

 Параметр группы задается при помощи аргумента `regex = "([условие])-([условие])"`. Опция `"+"` ставится в том случае, если необходимо взять все символы до разделителя которые соответствуют условию.

```{r}
tibble(x = c("male-34", "female-12", "male-19", "female-42")) %>%
  extract(col = x, into = c("sex", "age"), regex = "([a-z])-([0-9])")
```

Обе функции `separate ()` и `extract ()` преобразуют один столбец во многие столбцы. Однако `unite()` преобразует много столбцов в один, причем выбор разделителя включает значения столбцов.

Другими словами, с помощью `extract()` и `separate()` можно выбрать только один столбец, но есть много вариантов разделения этого столбца на разные столбцы. С `unite()`, есть много вариантов того, какие столбцы включать, но только один выбор, как объединить их содержимое в один вектор.

### Отсутствующие значения

Есть два типа отсутствующих значений

* явное --- имеющее маркер `NA`

* неявное --- то есть буквальное отсутствие значения среди данных

```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
```

* значение для 2015 года 4 квартала --- явное отсутствие

* значение для 2016 года 1 квартала --- неявеное

Можно сделать неявное отсутсвие явным:
```{r}
stocks %>%
  spread(year, return)
```

Но по скольку эти пропущенные значения могут не играть важной роли от них можно избавиться, задав аргумент `na.rm = TRUE` и объединить столбцы.

```{r}
stocks %>%
  spread(year, return) %>%
  gather(year, return, `2015`:`2016`, na.rm = TRUE)
```

Есть ещё функция `complete()`

```{r}
stocks %>%
  complete(year, qtr)
```

Это очень крутая функция. Она принимает набор столбцов и находит все уникальные комбинации. Далее она убеждается в том, что исходный набор данных содержит все эти значения, вставояя маркеры явного отсутствия значений (NA) там, где это необходимо.

Существует ещё один важный вид отсутсвующих значений. Иногда, когда источник данных используется главным образом для ввода данных, отсутствующее значение указывает на то, что предыдущее значение должно быть перенесено в следующую запись.

```{r}
treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)
```

Как в этом случае --- ячейки с именеме якобы объединены. Эти отсутствующиее значения можно заполнить с помощью функции `fill()`. Она принимает набор столбцов, отсутвующие значения в которых мы хотим заменить ближайшими предыдущими значениями, не являющиеся отсутвующими.

```{r}
treatment %>%
  fill(person)
```

Это тоже очень крутая функция, которой я часто пользовался "ручками" в экселе.

#### Упражнение 12.5.1.1
<div class="question">
Compare and contrast the `fill` arguments to `spread()` and `complete()`.
</div>

В `spread()` аргумент `fill` явно устанавливает значение для замены `NA`. В `complete()` аргумент `fill` также устанавливает значение для замены `NA`, но это именованный список, позволяющий использовать разные значения для разных переменных. Кроме того, оба случая заменяют как неявные, так и явно отсутствующие значения.

В `spread()` eсли установлено, отсутствующие значения будут заменены этим значением. Обратите внимание, что во входном файле есть два типа пропусков: явные пропущенные значения (т. Е. NA) и неявные пропуски, строки, которых просто нет. Оба типа недостающего значения будут заменены заполнением.

В `complete()` именованный список, который для каждой переменной предоставляет единственное значение для использования вместо NA для отсутствующих комбинаций.

#### Упражнение 12.5.1.2
<div class="question">
What does the `direction` argument to `fill()` do?
</div>

Аргумент `direction` задаёт направление заполнения --- по умолчанию, сверху вниз `"down"`, но можно поменять на снизу вверх `"up"`

```{r}
treatment %>%
  fill(person, .direction = "up")
```

### Учебный пример

Очень клёво --- у нас типичный пример неряшливых данных. Мы будем использовать реальный пример данных о заболеваемости туберкулёзом
```{r}
who
```

По этому представлению, всё что пока что понятно это:

* Для определения страны используется избыточное количество переменных

* Столбец  `year` является переменной

* Остальные столбцы, можно предположить, являются значениями а не переменными.

Теперь перейдём к более аккуратному виду. Для этого объединим все столбцы с предполагаемыми значениям в одну переменную

```{r}
(who1 <- who %>%
  gather(
    new_sp_m014:newrel_f65, key = "key",
    value = "cases",
    na.rm = TRUE
  ))
```

Мы можем получить некое представление о структуре значений в новой переменной `key` подсчитав их.

```{r}
who1 %>%
  count(key)
```

Что означает символьная кодировка в ключе (о возрасте и поле догодался сам)

* Первые три буквы --- случай заболевания, `new` новый и  `ul` старый

* Следующие две буквы описывают тип туберкулёза
  - `reel` --- рецидивный
  - `up` --- внелёгочный
  - `sun` --- лёгочный, не диагностируемый с помощью мазка
  - `spa`  --- лёгочный, диагностируемый с помощью мазка
  
* Шестая буква --- Пол пациента

* оставшиеся цифра --- возрастная группа

Есть особенность, которую я заметил, когда набирал названия столбцов в коде --- есть столбцы которые именуются `new_rel`, а есть те что именуются `newrel`. Чтобы все дальнейшие действия над данными не были проблематичными, нужно привести все записи к одному виду. Для этого, просмотрев весь фрейм данных выбираем форму записи `new_rel` --- их больше.

```{r}
(who2 <- who1 %>%
  mutate(key = stringr::str_replace(key, "newrel", "new_rel")))
```

Разделим столбцы в `key` на параметры при помощи `separete()`, знак разделитель `"_"`

```{r}
who3 <- who2 %>%
  separate(key, c("new", "type", "sexage"), sep = "_")
```

Посмотрим что в новом столбцк "new":

```{r}
who3 %>%
  count(new)
```

В изначальном фрейме данных содержится информация только о новых заболеваниях, поэтому этот столбец избыточный, избавимся от него, вместе со столбцами `iso2`, `iso3` по той же причине.

```{r}
who4 <- who3 %>%
  select(-new, -iso2, -iso3)
```

Далее разделим столбец с возрастом и полом, разбиение делаем после первого символа

```{r}
who5 <- who4 %>%
  separate(sexage, c("sex", "age"), sep = 1)
```

Можно сказать что набор данных приведён к аккуратному виду. Я проделал это всё, назначая промежуточный результат переменной. Но как правило такая работа делается в канале.

```{r}
who %>%
  gather(key, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
  separate(key, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1)
```

#### Упражнение 12.6.1.1
<div class="question">
In this case study I set `na.rm = TRUE` just to make it easier to check that we had the correct values. Is this reasonable? Think about how missing values are represented in this dataset. Are there implicit missing values? What’s the difference between an NA and zero?
</div>

```{r}
who1 %>%
  filter(cases == 0) %>%
  nrow()
```

В этом наборе данных `NA` означает отсутствие измерения на конкретный тест, а наличие нуля означает что тест проводился, и его результат отрицательный. Поэтому в данной ситуации было уместно убрать отсутствующие значения, а не заменять их нулями, так как мы не теряем информации о проведённых исследованиях.

Чтобы продемоснтрировать разницу между нулём и отсутствующим значением я приведу картинку. Потому что лучше один раз увидеть, чем сто раз услышать. 

![alt text](img/NA.jpg)

#### Упражнение 12.6.1.2
<div class="question">
What happens if you neglect the `mutate()` step? (`mutate(key = stringr::str_replace(key, "newrel", "new_rel"))`)
</div>

Эта строчка кода приводит записи наблюдений к одинаковой форме. Без этой строчки один и тот же по своей природе параметр будет встречаться дважды в виде двух разных записей `"newrel"`и `"new_rel"`.

Нельзя простро пропустить этот шаг в этом коде:

```{r}
who %>%
  gather(key, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
  separate(key, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1)
```

Потому что последующая логика разделения столбца `key` по параметрам, базируется на том, что группы разбивает разделитель `"_"`.


#### Упражнение 12.6.1.3
<div class="question">
I claimed that `iso2` and `iso3` were redundant with country. Confirm this claim.
</div>

Для того чтобы установить, что столбцы `iso2` и `iso3` избыточны надо сгруппировать по `country` и столбцам `iso2-3`.
Если хотя бы в одном столбце есть отличие в регистрации страны, то при группировке по предыдущему уровню получится две уникальных записи.

```{r}
select(who3, country, iso2, iso3) %>%
  distinct() %>%
  group_by(country) %>%
  filter(n() > 1)
```

ЧТД --- столбцы `iso2` и `iso3` дублируют полное название страны

#### Упражнение 12.6.1.4
<div class="question">
For each country, year, and sex compute the total number of cases of TB. Make an informative visualization of the data.
</div>

Для удобства работы с набором данных, определим аккуратизированный фрейм в переменную
```{r}
who_visual <- who %>%
  gather(key, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(key = stringr::str_replace(key, "newrel", "new_rel")) %>%
  separate(key, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1)
```

Для первоначальной прикидки, посмотрим как распределено количество случаев зарегистрированных заболеваний с течением времени.
```{r}
ggplot(who_visual, aes(year, value)) +
  geom_point()
```

По этому представлению, можно предположить, что до 95 года, данные скорее всего не вносились. Или информация есть не по всем странам. Исходя из этого, отбросим все наблюдения до 95-го года.

Далее, так как в конкретной задаче, нам необходимо получить результаты зарегистрированных случаев заболевания среди всех возрастных групп, просуммируем только по полу, году и стране.

```{r}
who_visual %>%
  group_by(country, year, sex) %>%
  filter(year >= 1995) %>%
  summarise(cases = sum(value)) %>%
  ggplot(aes(x = year, y = cases, color = sex)) +
  geom_point()
```

Этот график показывает некое превосходство количества регистрируемых случаев туберкулёза среди мужчин в разное время. Но не даёт понять тенденции.

Так как стран очень много, построенный без ограничений график на одной координатной плоскости будет не информативен.

```{r}
who5 %>%
  group_by(country, year, sex) %>%
  filter(year >= 1995) %>%
  summarise(cases = sum(cases)) %>%
  unite(country_sex, country, sex, remove = FALSE) %>%
  ggplot(aes(x = year, y = cases, group = country_sex, colour = sex)) +
  geom_line()
```

На построенном графике видна тенденция от года к году, но не понятно к какой стране относится какая линия. Для более детальной визуализации можно воспользоваться панелями и ограничить просматриваемый диапазон зарегистрированных случаев заболевания:

```{r}
who5 %>%
  group_by(country, year, sex) %>%
  filter(year >= 1995) %>%
  summarise(cases = sum(cases)) %>%
  unite(country_sex, country, sex, remove = FALSE) %>%
  filter(between(cases, 50000, 800000)) %>%
  ggplot(aes(x = year, y = cases, group = country_sex, colour = sex)) +
  geom_line() + 
  facet_wrap(.~country)
```

### Неаккуратные данные

Неаккуратные данные не всегда плохи. Есть ситуации когда они могут быть хороши

* альтернативные представления могут обеспечаить существенный выигрыш в производительности и объёме используемой памяти.

* для специализированных полей могут существовать собственные соглашения относительно хранения данных, которые могут заметно отличаться от соглашений, принятых для аккуратных данных

Аккуратные данные не являются единственным возможным выбором



<!--chapter:end:09_tidy_data.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Аккуратизация данных с помощью пакета `tidyr`

### Введение

Есть три семейства глаголов, предназначенных для выполнениях следуюзщий операций над реляционными данными:

* видоизменение соединений

* фильтрация соединений

* операции над множествами

#### Необходимые ресурсы

```{r}
library(tidyverse)
library(nycflights13)
library("datamodelr") # Пакет для моделирования схем баз данных
library(viridis)

```

### Пакет `nycflights13`

Этот пакет содержит четыре связанных tibble-frame их взаимосвязь хорошо продемонстрирована на рисунке

![alt text](img/relational.png)

#### Упражнение 13.2.1.1
<div class="question">
Imagine you wanted to draw (approximately) the route each plane flies from its origin to its destination. What variables would you need? What tables would you need to combine?
</div>

Для того чтобы построить маршрут перелёта, необходимо понимать точные данные о местах отправления и назначения. Информацию о перелётах из аэропорта в аэропорт можно получить из фрейма данных `flights` --- переменны `origin` и `dest`, для определения точек отправления и назначения. А информацию о городе в котором расположен конкретный аэропорт можно получить из фрейма данных `airports` --- переменные `lat` и `lon` для получения широты и долготы, т.е. координат аэропорта.

#### Упражнение 13.2.1.2
<div class="question">
I forgot to draw the relationship between `weather` and `airports`. What is the relationship and how should it appear in the diagram?
</div>

На самом деле между ними косвенно указана связь через `flights`. Но если быть точным, то `airports$faa` это внешний ключ `weather$origin`

#### Упражнение 13.2.1.3
<div class="question">
Weather only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with `flights`?
</div>

Если бы в `weather` содержались данные о погодных условиях во всех аэропортах, то 'необходимо было бы установить  это обеспечило бы погоду для `dest` каждого рейса. Соответственно необходимо было бы установить соответствие в таблицах между `dest`.

#### Упражнение 13.2.1.4
<div class="question">
We know that some days of the year are “special”, and fewer people than usual fly on them. How might you represent that data as a data frame? What would be the primary keys of that table? How would it connect to the existing tables?
</div>

Можно добавить отдельную таблицу, например `special date`, в которой перечислить эти специальные даты. Первичным ключом была бы комбинация даты из `flights` вплоть до дня `year`, `month`, `day`.

```{r}
special_date <- tribble(
  ~year, ~month, ~day, ~holiday,
  2013, 01, 01, "New Years Day"
)
```

#### Ключи

Ключи бывают двух видов:

* Первичный ключ идентифицирует наблюдение в собственной таблице. Например `planes$tailnum` однозначно идентифицирует каждый самолет в таблице `planes`

* Внешний ключ однозначно идентифицирует наблюдение в другой таблице. Наприме, `flights$tailnum` --- внешний ключ, поскольку он появляется в таблице `flights`, в которой он устанавливает для каждого авиарейса однозначно определяемый самолёт.

Переменная может одновременно служить первичным и внешним ключом. Например переменная `origin` является частью первичного ключа для таблицы `weather` и одновременно внешним ключом для таблицы `airports`

Чтобы убедится в том, что переменная которую мы определили как внешний ключ, действительно является таковой, можно проверить следующим способом:

```{r}
planes %>%
  count(tailnum) %>%
  filter(n > 1)
```

Так как первичный ключ устанавливает однозначной соответствие, то количество раз которое встречается эта переменная должно быть строго не больше одного раза.

Бывает, что таблица не имеет явного первичного ключа: каждая строка является наблюдением, но ниодна комбинация не обеспечивает её надежную идентификацию.

Например, что является первичным ключом во `flights`? Комбинация даты и номера вылета? Это было бы так, если бы в день самолёт совершал один полёт, но это не так:

```{r}
flights %>%
  count(year, month, day, flight) %>%
  filter(n > 1)
```

Если в таблице отсутствует первичный ключ, иногда его бывает удобно добавить с помощью функций `mutate()` и `row_number()`. Такой улюч называют суррогатным.

#### Упражнение 13.3.1.1
<div class="question">
Add a surrogate key to `flights`.
</div>

Однозначно описать строку может её порядковый номер:

```{r}
flights %>% 
  mutate(id = row_number())
```

Ещё лучше сначала упорядочить текущий набор данных и только затем присваивать идентификационный номер:

```{r}
flights %>%
  arrange(year, month, day, sched_dep_time, carrier, flight) %>%
  mutate(flight_id = row_number())
```

#### Упражнение 13.3.1.2
<div class="question">
Identify the keys in the following datasets

1. `Lahman::Batting`

1. `babynames::babynames`

1. `nasaweather::atmos`

1. `fueleconomy::vehicles`

1. `ggplot2::diamonds`

(You might need to install some packages and read some documentation.)
</div>

1. Для меня совершенно не очевидный ответ, к которому я пришёл интуитивно:

```{r}
Lahman::Batting %>%
  count(playerID, yearID, stint) %>%
  filter(n > 1)
```

Таким образом, первичным ключом в этих данных будет связка параметров `playerID`, `yearID`, `stint`.
Эти данные --- статистика по игре в бейсбол. Первые два параметра это как не трудно догадаться ID игрока, и года в котором он играл. Сначала я проверил на однозначность описания совокупность этих двух параметров. Но так как в течении года у игрока может изменяться положение/роль (параметр `stint`), то первичным ключом будет комбинация трёх параметров.

Больше информации по этим данным содержится в оригинальном наборе данных <http://www.seanlahman.com/files/database/readme2012.txt>

1. Для работы с эим набором данных необходимо скачать пакет `babynames`. В этом наборе данных содержится информация о количестве имён используемых в каждом году и их популярность.

```{r}
# install.packages("babynames")
library(babynames)

babynames::babynames %>%
  # count(year, sex, name) %>%
   filter(n > 1) # Обрати мнимание, что в исходном наборе данных уже есть параметр n, поэтому для подсчёта количества вхождений используеться переменная nn
```

Первичным ключом будет комбинация из трёх параметров --- имя, пол (потому что есть бисексуальные имена) и год в котором было использовано это имя.

Больше информации по этому набору данных <https://github.com/hadley/babynames>

1. Для работы с этим набором данных необходимо установить пакет `nasaweather`. Данные представляют собой географические и атмосферные измерения на очень грубой сетке 24 на 24, охватывающей Центральную Америку. Переменными являются: высота, температура (поверхность и воздух), озон, давление воздуха и облачный покров (низкий, средний и высокий). За исключением повышения, все переменные являются среднемесячными с наблюдениями за январь 1995 года по декабрь 2000 года. Эти данные были получены из Центра данных атмосферных наук NASA Langley Research Center

```{r}
# install.packages("nasaweather")
library(nasaweather)
```

Таким образом, первичным ключом будет комбинация параметров --- ширина-долгота для идентификации местоположения, и месяц-год для идентификации события во времени. Другими словами:

```{r}
nasaweather::atmos %>%
  count(lat, long, year, month) %>%
  filter(n > 1)
```

Больше информации по этим данным содержится в оригинальном наборе данных <http://stat-computing.org/dataexpo/2006/>

1. Для работы с этим набором данных необходимо установить пакет `fueleconomy`. Данные об экономии топлива являются результатом испытаний транспортных средств, проведенных в Национальной лаборатории Агентства по охране окружающей среды и выбросов топлива в Анн-Арборе, штат Мичиган, в 1985-2015. А также производителями транспортных средств под надзором EPA. Данные об экономии топлива из EPA, 1985-2015. Этот набор данных содержит выбранные переменные и удаляет транспортные средства с неполными данными (например, без данных трансмиссии)

```{r}
# install.packages("fueleconomy")
library(fueleconomy)

fueleconomy::vehicles %>%
  count(id) %>%
  filter(n > 1)
```

В изначальном наборе данных введён первичный ключ --- переменная `id`.

Больше информации по этим данным содержится в оригинальном наборе данных <https://www.fueleconomy.gov/feg/download.shtml>

1. В наборе данных `ggplot2::diamonds`  изначально нет первичного ключа. Его нельзя задать комбинацией параметров, потому что теоретически в природе может существовать два идентичных бриллианта как по размерам и физико-химическим свойствам, так и по цене, запращиваемой за эти бриллианты. Таким образом, для определения первичного ключа, нужно вводить новую переменную (суррогатный первичный ключ).

#### Упражнение 13.3.1.3
<div class="question">
Draw a diagram illustrating the connections between the `Batting`, `Master`, and `Salaries` tables in the `Lahman` package. Draw another diagram that shows the relationship between `Master`, `Managers`, `AwardsManagers`.

How would you characterise the relationship between the `Batting`, `Pitching`, and `Fielding` tables?
</div>

Чтобы фиксировать взаимоотношения данных в таблицах можно использовать множество разных ресурсов. Вероятно на специализированных ресурсах отношения и стрелочки будут выглядеть лучше, но мне помнравилась идея отображать отношения в той рабочей среде в которой проводится анализ.

Для этого необходимо установить два пакета:

```{r}
#install.packages("datamodelr")
#install.packages("DiagrammeR")
```

Второй пакет необходим для отображения работы первого.

Подробно работа с пакетом описана в репозитории разработчика <https://github.com/bergant/datamodelr#model-diagram-of-interconnected-data-frames>

Общий подход такой --- для начала определяем первичные ключи:

-   `Master`

    -   Первичный: `playerID`

-   `Batting`

    -   Первичный: `playerID`, `yearID`, `stint`

    -   Внешний:

        -   `playerID` = `Master$playerID` (many-to-1)

-   `Salaries`

    -   Primary keys: `yearID`, `teamID`, `playerID`

    -   Foreign Keys

        -   `playerID` = `Master$playerID` (many-to-1)

После этого задаём их связи `Batting$playerID == Master$playerID`, `Salaries$playerID == Master$playerID`

И на третьем шаге можно строить отношения:
    
```{r}
dm1 <- dm_from_data_frames(list(Batting = Lahman::Batting,
                                Master = Lahman::Master,
                                Salaries = Lahman::Salaries)) %>%
  dm_set_key("Batting", c("playerID", "yearID", "stint")) %>%
  dm_set_key("Master", "playerID") %>%
  dm_set_key("Salaries", c("yearID", "teamID", "playerID")) %>%
  dm_add_references(
    Batting$playerID == Master$playerID,
    Salaries$playerID == Master$playerID
  )

dm_create_graph(dm1, rankdir = "LR", columnArrows = TRUE)
```

Теперь проделаем эту же процедуру для `Master`, `Managers`, `AwardsManagers`


-   `Master`

    -   Первичный: `playerID`

-   `Managers`

    -   Первичный: `yearID`, `teamID`, `inseason`

    -   Внешний:

        -   `playerID` = `Master$playerID` (many-to-1)

-   `AwardsManagers`:

    -   Первичный: `playerID`, `awardID`, `yearID`
    
    -   Внешний:
    
        -   `playerID` = `Master$playerID` (many-to-1)
    
```{r}
dm2 <- dm_from_data_frames(list(Managers = Lahman::Managers,
                                Master = Lahman::Master,
                                AwardsManagers = Lahman::AwardsManagers)) %>%
  dm_set_key("Managers", c("teamID", "yearID", "inseason")) %>%
  dm_set_key("Master", "playerID") %>%
  dm_set_key("AwardsManagers", c("yearID", "awardID", "playerID")) %>%
  dm_add_references(
    AwardsManagers$playerID == Master$playerID,
    Managers$playerID == Master$playerID
  )

dm_create_graph(dm2, rankdir = "LR", columnArrows = TRUE)
```


Таблицы `Batting`, `Pitching` и `Fielding` имеют первичный ключ, состоящий из переменных `playerID`, `yearID` и `stint`. Все они имеют отношения 1-1 друг к другу, потому что `Batting`, `Pitching` и `Fielding` это названия игровых позиций.


### Мутирующие соединения 

Мутирующее соединение позволяет объединять переменные из двух таблиц. Сначала оно находит соответсвующие наблюдения по их ключам, а затем копирует переменные из одной таблицы в другую. 

Мутирующие соединения добавляют столбцы в правый конец таблицы.

Чтобы было проще понять происходящее с данными, возьмём тренировочный набор данных.

```{r}
(flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier))
```

Предположим, мы хотим соединить два фрейма данных `flights2` и `airlines`. Напомню, что последний фрейм это:

```{r}
airlines
```

Фреймы можно соединить при помощи `left_join()`

```{r}
flights2 %>%
  select(-origin, -dest) %>%
  left_join(airlines, by = "carrier")
```

#### Что представляют собой соединения

Проще всего понять как работает соединение продемонстрировать это графически. Введём две переменные для демонстрации:

```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)
```

Их объединение будет происходить по ключу. Количество точек на диаграмме = количеству совпадений = количеству строк в результате
![alt text](img/join-inner.png)

#### Внутреннее соединение

Это простейший тип соединения, которое устанавливает соответствие между парами наблюдений, если их ключи совпадают. Собственно оно и было указано в демонстрации выше

![alt text](img/join-inner.png)

Строго говоря, этот тип соединения является **внутренним соединением по эквивалентности**, так как для сопоставления ключей используется оператор равенства. Поскольку большинство ключей относится к этому типу, мы будем опускать это уточнение. 

Результатом внутреннего соединения является новый фрейм данных, котороый содержит ключе, значения `x` и значения `y`. Для того чтобы сообщить пакету `dplyr` какая переменная является ключом, мы используем параметр `by`

```{r}
x %>%
  inner_join(y, by = "key")
```

Самым важным свойством внутреннего соединения является тот факт, что несовпадающие значения не включаются в новый фрейм данных. Это означает, что обычное внутреннее соединение, как правило нельзя использовать в анализе, так как можно очень легко потерять наблюдения.

#### Внешние соединения

Внутреннее соединение сохраняет наблюдения которые встречаются в обеих таблицах (логическое И)

Внешнее соединение сохраняет наблюдения встречающиеся хотя бы в одной из таблиц. Различают три вида внешних соединений:

* левое соединение, сохраняет все наблюдения в `x`

* правое соединение, сохраняет все наблюдения в `y`

* полное соединение, сохраняет все наблюдения в `x` и `y`

Эти соединения работают, добавляя дополнительное "виртуальное" наблюдение в каждую таблицу. Данное наблюдение имеет ключ, который совпадает с любым ключом (если никакой другой ключе не совпадает), и значение `NA`

![alt text](img/join-outer.png)
Так как левое соединение оставляет исходную выборку нетронутой, то этот тип соединения используется практически по умолчанию всегда.

Для графического изображения различных типов соединений используется диаграмма Венна

![alt text](img/join-venn.png)

Однако она обладает одним существенным недостатком --- она не сообщает что делать в тех случаях, когда ключи не обечспечивают однозначную идентификацию.

#### Неуникальные ключи

Есть две ситуации неуникальных ключей

* Неуникальные ключи есть в одной таблице. Это модет быть полезно, если необходимо добавить информацию в тех случаях, когда имеется типичное отношение "один ко многим". 

![alt text](img/join-one-to-many.png)

* Неуникальные ключи есть в обеих таблицах. При соединении таких таблиц получаются все возможные соединения

![alt text](img/join-many-to-many.png)

#### Определение ключевых столбцов

До сих пор соединение происходило только по одной переменной, задаваемой параметром `by = "key"`. Есть другие способы:

* Заданному по умолчанию значению `by = NULL` соответствует использование всех переменных, встречающихся в обеих таблицах. Это естественное соединение. Например таблицы `flights` и `weather` согласуются по общим переменным: `year`, `month`, `day`, `hour` и `origin`.

```{r}
flights2 %>%
  left_join(weather)
```

* Символьный вектор, `by = "x"`. Можно соединять не по ключу, а по любой общей переменной. НАпример, переменная `year` содержится в обеих таблицах, `flights` и `planes`, но имеет в них разный смысл, и потому для соединения таблиц мы используем только переменную `tailnum`

```{r}
flights2 %>%
  left_join(planes, by = "tailnum")
```

Неоднозначность переменных устранена при помощи суффиксов `year.x` и `year.y`


* Именованный символьный вектор `by = c("a" = "b")`. Соединения этого типа сопоставляют переменную `a` в таблице `x` с перменной `b` в таблице `y`. В результате будут использованы перменные их `x`.

Это сильный инструмент --- этакий аналог этой функции в Excell это `ВПР()`. Но только по заданному ключу здесь, функция проводит поиск, устанавливает соответствие по всем доступным столбцам в таблице `y`. 

Например, если мы хоти нарисовать карту, необходимо соединить данные таблицы `flights` с данными таблицы `airports`, которая содержит широту и долготу каждого аэропорта. Каждый авиарейс характеризуется аэропортом вылета и аэропортом назначения, поэтому мы должны конкретизировать, какой из вариантов соединения нам необходим.

```{r}
flights2 %>%
  left_join(airports, c("dest" = "faa"))
```

```{r}
flights2 %>%
  left_join(airports, c("origin" = "faa"))
```

#### Упражнение 13.4.6.1

<div class="question">
Compute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States:
</div>


```{r}
airports %>%
  semi_join(flights, c("faa" = "dest")) %>%
  ggplot(aes(lon, lat)) +
    borders("state") +
    geom_point() +
    coord_quickmap()
```

Вычислим для начала среднее время задержки по пунктам назначения. Для этого необходимо сгруппировать по направлению вылета `group_by(dest)`. Затем вычислить среднее значение задержки `delay = mean(arr_delay, na.rm = TRUE)`. И наконец просуммировать по группе --- summarise()

```{r}
flights %>%
  group_by(dest) %>%
  summarise(delay = mean(arr_delay, na.rm = TRUE))
```

Теперь выполним задачу по соединению для фрейма данных `airports`

```{r}
avg_dest <- flights %>%
  group_by(dest) %>%
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
  inner_join(airports, by = c(dest = "faa"))
```

Теперь нанесём значения времени задержки на карту

```{r}
avg_dest %>%
  ggplot(aes(lon, lat, color = delay)) +
    borders("state") +
    geom_point() +
    coord_quickmap()
```

#### Упражнение 13.4.6.2

<div class="question">
Add the location of the origin and destination (i.e. the `lat` and `lon`) to `flights`.
</div>

Чтобы не плодить сущностей, т.е. параметров сверх необходимых, мы изначально ограничим исходные наборы данных, требуемыми параметрами. В таблице аэропортов останется всего три параметра ключ `faa` и координата долготы и широты

```{r}
airports_locations <- airports %>%
  select(faa, lat, lon)
```

И далее в наборе данных с полётам возьмём только необходимые параметры даты вылета и направлений. Только после этого присоединим данные при помощи именнованного символьного вектора

```{r}
flights %>%
    select(year:day, hour, origin, dest) %>%
    inner_join(airports_locations, by = c(origin = "faa")) %>%
    inner_join(airports_locations, by = c(dest = "faa"))
```

В очередной раз спасибо [Jeffrey Arnold](https://github.com/jrnold) за отличный совет: всегда давать понятные названия переменным, а главное за подсказку способа реализации --- добавление параметра `suffix`

```{r}
flights %>%
    select(year:day, hour, origin, dest) %>%
    inner_join(airports_locations, by = c(origin = "faa")) %>%
    inner_join(airports_locations, by = c(dest = "faa"), suffix = c("_origin", "_dest"))
```

#### Упражнение 13.4.6.3

<div class="question">
Is there a relationship between the age of a plane and its delays?
</div>

Для того чтобы вспомнить, как между собой связаны таблицы полётов и самолётов, вспомним схему:

![alt text](img/relational.png)

Чтобы не тащить все данные, ограничимся несколькими переменными в таблице самолётов --- внешним ключом `tailnum`, и годом производства самолёта `year`

```{r}
year_planes <- planes %>%
  select(year, tailnum)
```

В исходной таблице полётов тоже много смежной информации, она избыточна для решения задачи. Возьмём информацию о дате полёта, времени задержки, и номере самолёта (внешний ключ).

Для того чтобы установить некую связь между сроком эксплуатации и задержками самолёта пойдём следующей логикой. Сджойним две таблицы по номеру самолёта, затем сгруппируем по дате производства. Посчитаем в группах средннее время задержки и построим график даты производства от средней времени задержки. Для того чтобы установить возраст самолёта возьмём разность между датой полёта и датой производства.

```{r}
flights %>%
  select(year:day, dep_delay, arr_delay, tailnum) %>%           # Убираем избыточные данные
  left_join(year_planes, 
            by = "tailnum",                                     # Присоединяем по внешнему ключу инфу о самолётах
            na.rm = TRUE, 
            suffix = c("_of_plane", "_of_manufactered")) %>%    # Переименовываем параметры `year`, чтобы не запутаться 
  mutate(age = year_of_plane - year_of_manufactered) %>%        # Вычисляем возраст самолёта
  filter(!is.na(age)) %>%                                       # Чтобы нарисовать график, фильтруем отсутствующие значения
  group_by(age) %>%                                             # Группируем самолёты по возрасту
  summarise(dep_delay_mean = mean(dep_delay, na.rm = TRUE)) %>% # чтобы посчитать среднее время задержки в возрасте
  ggplot(aes(age, dep_delay_mean)) +                            # Строим диаграмму рассеяния и сглаженную прямую по ним
  geom_point() +
  geom_smooth()
```

На этой диаграмме рассеяния видно, что самолёты в возрасте до 10 лет, имеют восходящий тренд задержки. Самолёты в возрасте от 10 до 20 лет, имеют плавный нисходящий тренд. Далее, чем старше самолёты тем меньше задержка отправления.

Уменьшение задержки вылета может быть связано с тем, что старые самолеты со многими механическими неисправностями выведены из эксплуатации или потому, что воздушные линии планируют эти самолеты с достаточным временем, чтобы механические неисправности не задерживали их. 

Этот график обладает рядом особенностей

* чтобы сказать сколько лет самолёту, нужно знать как минимум дату совершения полётов.

* Примерно между 30 и 40 годами, существенный разброс средних. 

* Кроме того, график отображает только задержки отправления, возможно связь с задержками по прибытию носит другой характер.

Учитывая указанные особенности строим график, на котором будут все точки попадающие в каждый год. Для проверки того, отличается ли характер распределения задержек по прибытию, объединим данные задержек и построим на одном графике две панели с задержками по прибытию и отправлению.

```{r}
flights %>%
  select(year:day, dep_delay, arr_delay, tailnum) %>%
  left_join(year_planes, by = "tailnum", na.rm = TRUE, suffix = c("_of_plane", "_of_manufactered")) %>%
  group_by(tailnum, year_of_manufactered) %>%
  summarise(departure = mean(dep_delay, na.rm = TRUE),
            arrival = mean(arr_delay, na.rm = TRUE)) %>%
  gather(departure, arrival, key = "delay", value = "value") %>%
  ggplot(aes(year_of_manufactered, value)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~delay) +
  scale_x_continuous("Year of manufactured") +
  scale_y_continuous("Mean Delay, minutes")
```

На графике выше видно, что на рейсы редко пускают самолёты младше 1980 года. Количество полётов на самолётах старше 1980 года существенно ниже, чем полётов на более современных самолётах. Посмотрим какое распределение полётов между 1980 и  

```{r}
flights %>%
  select(year:day, dep_delay, arr_delay, tailnum) %>%
  left_join(year_planes, 
            by = "tailnum", 
            na.rm = TRUE, 
            suffix = c("_of_plane", "_of_manufactured")) %>%
  group_by(tailnum, year_of_manufactured) %>%
  summarise(departure = mean(dep_delay, na.rm = TRUE),
            arrival = mean(arr_delay, na.rm = TRUE)) %>%
  ggplot(aes(year_of_manufactured, departure)) + 
  geom_boxplot(aes(group = cut_width(year_of_manufactured, 1))) +                 # Группируем по году
  geom_smooth() +
  scale_y_log10("Logorithmic mean departure delay") +                             # Логарифмическая ось
  scale_x_reverse("Year of manufactured", breaks = seq(1930, 2013, by = 4)) +  # Указываем на сетке каждые 4 года
  labs(title = "Dependence of flight delay on the plane manufactured year. 2013")
```

Я сконцентрировался на данных о задержках отправления, так как показал выше, что задержки по прилёту не имеют существенных различий в распределении.

Этот график представляет улучшенную версию первого графика. На нём показано распределение времени задержки вылета в зависимости от года производства самолёта. Как говорилось выше --- в представленном наборе данных мало наблюдений о полётах самолётов старше 1986 года. Это может свидетельствовать о том, что компании обновляют лётный парк и старые аппараты реже выпускают в рейс. Судя по представленным графикам компании тщетельнее и щепитильнее отнсятся к старым самолётам отправляя их в рейс, так как чем старее самолёт тем меньше у него задержка перед вылетом. 

Однако в возрасте до 10 лет, наблюдается увеличение год от года времени задержки, затем до 20 лет время задержки выравнивается.

#### Упражнение 13.4.6.4

<div class="question">
What weather conditions make it more likely to see a delay?
</div>

Задаём ключевые столбцы, по которым будет происходить соединение

```{r}
flights_with_weather <- flights %>%
    inner_join(weather, by = c("origin" = "origin",
                            "year" = "year",
                            "month" = "month",
                            "day" = "day",
                            "hour" = "hour"))

```

Есть несколько параметров характеризующих погодные условия, разберём каждый. Для начала, возьмём температуру

```{r}
flights_with_weather %>%
  group_by(temp) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(temp, delay)) +
  geom_point() +
  geom_smooth()
```

На диаграмме рассеяния не наблюдается зависимость температуры от времени. Рассмотрим влияение влажности на задержки вылетов.

```{r}
flights_with_weather %>%
  group_by(humid) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(humid, delay)) +
  geom_point() +
  geom_smooth()
```

Есть небольшой рост времени задержки при относительно высокой влажности. Между 26 и 60 единицами влажности не наблюдается корреляции с временем задержки. Рассмотрим скорость ветра

```{r}
flights_with_weather %>%
  group_by(wind_speed) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(wind_speed, delay)) +
  geom_point() +
  geom_smooth()
```

При увеличении скорости ветра от 0 до 20 миль в час, наблюдается увеличениее времени задержки. Однако характер зависимости при высоких значениях скорости ветра (от 20 до 35 миль в час) носит нелинейный характер и уменьшается практически до уровня задержки при отсутсвии ветра.

Рассмотрим порывы ветра

```{r}
flights_with_weather %>%
  group_by(wind_gust) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(wind_gust, delay)) +
  geom_point() +
  geom_smooth()
```

Есть небольшой рост времени задержки при увеличинии скорости порывов, однако это рост не значительный. При больших порывах (50-60 мил в час) не всегда увеличивается время задержки. Рассмотрим как влияют осадки на время задержки

```{r}
flights_with_weather %>%
  group_by(precip) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(precip, delay)) +
  geom_point() +
  geom_smooth()
```

Пожалуй, самая показательная зависимость, приближенная к линейной, с увеличением количества осадков, компании медлят с разрешением полёта. Рассмотрим как влияет атмосферное давление на задержки:

```{r}
flights_with_weather %>%
  group_by(pressure) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(pressure, delay)) +
  geom_point() +
  geom_smooth()
```

Увеличение давления, наоборот --- уменьшает время задержки вылета, хоть и не значительно.

```{r}
flights_with_weather %>%
  group_by(visib) %>%
  summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(visib, delay)) +
  geom_point() +
  geom_smooth()
```

ВИдимость практически не влияет на время задержки.

Резюмируя: на время задержки вылета самолёта в большей степени влияют выпадаемые осадки (вероятно потому что необходимо расчищать взлётную полосу в зимнее время). Заметно на время задержки вылета влияет скорость и порывы ветра (вероятно потому что сложно взлетать при сильном ветре). Остальные представленные показатели погоды (температура, атмосферное давление, видимость) слабо увеличивают или вовсе уменьшают время задержки вылета.

#### Упражнение 13.4.6.5

<div class="question">
What happened on June 13 2013? Display the spatial pattern of delays, and then use Google to cross-reference with the weather.
</div>

Гуглим. Оказывается в этот день, точнее в дни 12-13 июня произошла [серия шторвом](https://en.wikipedia.org/wiki/June_12–13,_2013_derecho_series) на южном побережье. Вероятно это может вызвать задержки

Сравним к примеру два дня --- день шторма и любой другой день

```{r}
flights %>%
  filter(year == 2013, month == 6, day == 13) %>%
  group_by(dest) %>%
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
  inner_join(airports, by = c("dest" = "faa")) %>%
  ggplot(aes(y = lat, x = lon, size = delay, colour = delay)) +
  borders("state") +
  geom_point() +
  coord_quickmap() +
  scale_colour_viridis()
```

```{r}
flights %>%
  filter(year == 2013, month == 1, day == 13) %>%
  group_by(dest) %>%
  summarise(delay = mean(arr_delay, na.rm = TRUE)) %>%
  inner_join(airports, by = c("dest" = "faa")) %>%
  ggplot(aes(y = lat, x = lon, size = delay, colour = delay)) +
  borders("state") +
  geom_point() +
  coord_quickmap() +
  scale_colour_viridis()
```

Заметно существенное увеличение числа задержек прибытия самолётов в день штормов

#### Другие реализации

Функция `base::merge()` способна выполнять все четыре типа мутации

dplyr              | merge
-------------------|-------------------------------------------
`inner_join(x, y)` | `merge(x, y)`
`left_join(x, y)`  | `merge(x, y, all.x = TRUE)`
`right_join(x, y)` | `merge(x, y, all.y = TRUE)`,
`full_join(x, y)`  | `merge(x, y, all.x = TRUE, all.y = TRUE)`

Но нагляднее видится использование в коде глаголов `dplyr`, в силу того что тип соединения не спрятан в параметре а напрямую указан в самой функции.

SQL запросы выглядят следующим образом

dplyr                        | SQL
-----------------------------|-------------------------------------------
`inner_join(x, y, by = "z")` | `SELECT * FROM x INNER JOIN y USING (z)`
`left_join(x, y, by = "z")`  | `SELECT * FROM x LEFT OUTER JOIN y USING (z)`
`right_join(x, y, by = "z")` | `SELECT * FROM x RIGHT OUTER JOIN y USING (z)`
`full_join(x, y, by = "z")`  | `SELECT * FROM x FULL OUTER JOIN y USING (z)`

### Фильтрующие соединения

Фильтрующие соединения (полусоединения) сопоставляют наблюдения но влияют не на переменные а на наблюдения. Есть два типа полусоединений:

* `semi_join(x, y)` __сохраняет__ все наблюдения в `x` для которых имеется совпадение в `y`.
* `anti_join(x, y)` __опускает__ все наблюдения в `x` для которых имеется совпадение в `y`.

Полусуоединения могут быть полезны при обратном сопоставлении отфильтрованных итоговых таблиц с исходными строками. Предположим, что мы нашли первую десятку наиболее популярных пунктов назначения

```{r}
top_dest <- flights %>%
  count(dest, sort = TRUE) %>%
  head(10)
top_dest
```

А теперь мы хотим найти все авиарейсы, совершенные в один из этих аэропортов назначения. Можно самостоятельно спроектировать фильтр:

```{r}
flights %>% 
  filter(dest %in% top_dest$dest)
```

но есть определённые сложности, когда вернуть значения нужно по нескольким переменным. Чтобы упростить себе задачу, можно использовать фильтрующее соединение

```{r}
flights %>% 
  semi_join(top_dest)
```

В графическом представлении это выглядит так:

![alt text](img/join-semi.png)

Важен сам факт наличие соответствия, не имеет значения, для какого элемента находится соответствуие. Это означает, что фильтрующее соединение никогда не дублирует строки, как это делают мутирующие соединения:

![alt text](img/join-semi-many.png)

Прямая противоположность полусоединению --- антисоединение. Она созраняет строки, для которых отсутствует соответствие.

![alt text](img/join-anti.png)

Антисоединения полезны в качестве средства диагностики несоответствий соединения. Например, при соединении таблиц `flights` `planes` является интересным количество авиарейсов, для которых не находится соответствия по самолётам:

```{r}
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(tailnum, sort = TRUE)
```

#### Упражнение 13.5.1.1

<div class="question">
What does it mean for a flight to have a missing tailnum? What do the tail numbers that don’t have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.)
</div>

Используем антисоединение для диагностики несоответсвий соединения.  Логично заключить, что нужно проверить самолёты каких авиакомпаний не имеют информации о номерах самолётов

```{r}
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(carrier, sort = TRUE)
```

И действительно --- компании Envoy Air и American Airlines Inc. не подали информации о номерах самолётов.


#### Упражнение 13.5.1.2

<div class="question">
Filter flights to only show flights with planes that have flown at least 100 flights.
</div>

Для начала отберём самолёты, которые выполнили не менее 100 полётов
```{r}
top100_planes <- flights %>%
  count(tailnum, sort = TRUE) %>%
  filter(n >= 100)
top100_planes
```


Теперь отфильтруем исходную таблицу по полученным данным о количестве полётов

```{r}
semi_join(flights, top100_planes, by = "tailnum")
```

Стоит помнить о необходимости явно указывать ключ, по которому происходит группировка.

#### Упражнение 13.5.1.3

<div class="question">
Combine `fueleconomy::vehicles` and `fueleconomy::common` to find only the records for the most common models.
</div>

```{r}
fueleconomy::vehicles %>% semi_join(fueleconomy::common, by = c("make", "model"))
```

Объединение обязательно должно происходить по производителю и названию модели. А не только по какому-то одному из параметров. Так вполне вероятно, что несколько производителей могут дать своим автомобилям одинаковые названия моделей.

```{r}
fueleconomy::common %>% 
  distinct(model, make) %>% 
  group_by(model) %>%
  filter(n() > 1) %>%
  arrange(model)
```

#### Упражнение 13.5.1.4

<div class="question">
Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns?
</div>

Для начала сгруппируем все данные по месяцу и дню (без года, так как в исходных данных наблюдения только за 2013 год). Затем посчитаем суммарное время задержки за день

```{r}
flights %>%
  group_by(month, day) %>%
  summarise(delays_24 = sum(dep_delay, na.rm = TRUE) + sum(arr_delay, na.rm = TRUE)) %>%
  arrange(desc(delays_24))
```

Но в условиях задачи, необходимо найти 48 часов, т.е. двое последующих суток. Для этого необходимо добавить суммирование с лагом

```{r}
worst_delays <- flights %>%
  group_by(month, day) %>%
  summarise(delays_24 = sum(dep_delay, na.rm = TRUE) + sum(arr_delay, na.rm = TRUE)) %>%
  mutate(delays_48 = delays_24 + lead(delays_24))  %>%
  arrange(desc(delays_48)) %>%
  head(1)
```

Наихудшими 48 часами были 22-23 июля

```{r}
flights %>%
  semi_join(worst_delays) %>%
  left_join(weather) %>%
  arrange(desc(dep_delay))

```

К сожалению, перепроверив все имеющиеся показатели погоды, мне не удалось найти явной зависимости погодных условий с задержками авиарейсов. Было не очень жарко, не очень много осадков, не самый сильный ветер, довольно хорошая видимость. [Данные](https://www.timeanddate.com/weather/usa/new-york/historic?month=7&year=2013)

```{r}
weather %>%
  group_by(month, day) %>%
  summarise(worst = mean(wind_gust, na.rm = TRUE)) %>%
  arrange(desc(worst))
```

#### Упражнение 13.5.1.5

<div class="question">
What does `anti_join(flights, airports, by = c("dest" = "faa"))` tell you? 
What does `anti_join(airports, flights, by = c("faa" = "dest"))` tell you?
</div>

Антиджоин указывает на несоответствие соединений. 

Поэтому ответ на первый вопрос --- в выдаче программы будут полёты, у которых нет соответствия в таблице аэропортов по ключу "аэропорт направления".

```{r}
anti_join(flights, airports, by = c("dest" = "faa"))
```

Аэропорты, которые есть в таблице полётов, но которых нет в таблице `airports`

```{r}
flights %>%
  anti_join(airports, by = c("dest" = "faa")) %>%
  count(dest, sort = TRUE)
```

```{r}
airports %>%
  filter(faa == "SJU")
```

Ответ на второй вопрос, соответсвенно обратный --- в выдаче будут те аэропорты, которые есть в таблице `airports`, но которые не встречаются в таблице `flights`

```{r}
anti_join(airports, flights, by = c("faa" = "dest"))
```

```{r}
flights %>%
  filter(dest == "04G")
```


#### Упражнение 13.5.1.6

<div class="question">
You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned above.
</div>

Для того чтобы проверить утверждение "между самолётами и компаниями существуют неявные отношения", нужно проверить есть ли самолёты, которые принадлежат несколким компаниям

```{r}
(not_one_carrier <- flights %>%
  filter(!is.na(tailnum)) %>%
  distinct(tailnum, carrier) %>%
  count(tailnum, sort = TRUE) %>%
  filter(n > 1))
```

Аккуратным представлением данных будет следующее

```{r}
(not_one_carrier <- flights %>%
semi_join(not_one_carrier, by = "tailnum") %>%
  select(tailnum, carrier) %>%
  distinct() %>%
  arrange(tailnum)) %>%
  count(tailnum, carrier) %>%
  left_join(airlines, by = "carrier") %>%
  select(-carrier)
```


Чуть более наглядным будет представление:
```{r}
(not_one_carrier <- flights %>%
semi_join(not_one_carrier, by = "tailnum") %>%
  select(tailnum, carrier) %>%
  distinct() %>%
  arrange(tailnum)) %>%
  count(tailnum, carrier) %>%
  left_join(airlines, by = "carrier") %>%
  select(-carrier) %>%
  spread(name, n)
```

### Проблемы соединений

Данные в этой главе были специально подготовлены для того чтоб ы при работе с ними возникало как можно меньше проблем. Реальные данные не такие.

ЧТобы при работы с реальными данными возникало как можно меньше проблем, в отношении данных необходимо предпринимать следующие меры:

1. Начинать нужно с идентификации переменных, образующих первичный ключ в каждой таблице. Это нужно делать *ПОНИМАЯ* данные, а не подбирая эмпирически уникальную комбинацию

1. Необходимо убедиться что ни одна из переменных в первичном ключе не содержит пропущенных значений. Отсутствующие значения не могут однозначно определить наблюдение.

1. Необходимо убедиться, что внешним ключам соответствуют первичные ключи в присоединяемой таблице. Обычно это проще всего проверить при помощи `anti_join`.

Конечно же важно помнимать, что простой проверки по количеству строк не достаточно при объединении.

### Операции над множествами

Последний тип двухтабличных глаголов предназначен для выполнения операция над множествами. Все эти операции работают с целыми строками, сравнивая значения каждой переменной. 

ПРиведённые ниже функции ожидают, что входные таблицы `х` и `у` имеют одни и те же переменные и обрабатывают наблюдения как множества.

* `intrsect(x, y)` --- Возвращает только наблюдения, содержащие одновременно в `х` и `у`

* `union(x, y)` --- Возвращает уникальные наблюдения, содержащие в `х` и `у`

* `setdiff(x, y)` --- Возвращает наблюдения, содержащие только в `х`, но не в `у`

Пусть имеются следующие простые данные:

```{r}
df1 <- tribble(
  ~x, ~y,
   1, 1,
   2, 1
)

df2 <- tribble(
  ~x, ~y,
   1, 1,
   1, 2
)
```

ТОгда возможны следующие четыре операции

```{r}
intersect(df1, df2)
union(df1, df2)     # Возваращает 3 наблюдения, а не 4
setdiff(df1, df2)
setdiff(df2, df1)
```


<!--chapter:end:10_relation_data.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Аккуратизация данных с помощью пакета `tidyr`

### Введение

Основное внимание в этой главе будет уделено регулярным выражениям

#### Необходимые ресурсы

```{r}
library(tidyverse)
library(stringr)
```

### Основы работы со строками

Чтобы создать строку достаточно использовать кавычки

```{r}
string1 <- "Это уже строка"
string2 <- 'Это тоже строка, но внутри неё есть "кавычки"'
```

Если в строке есть спецсимволы их нужно "экранировать" апострофом или кавычками:

```{r}
double_qoute <- "\""
single_qoute <- '\''
ap_qoute <- "\\"
```

Со строками всё очень похоже на маркдаун --- печатное отображение строки, не то же самое что сама строка. Чтобы увидеть содержание строки можно использовать функцию `writeLines()`

```{r}
x <- c("\"", "\\")
x
writeLines(x)
```

Вот ещё частоиспользуемые спец.символы

* `"\n"` перевод строки

* `"\t"` табуляция

* остальные ищутся по справке `?'"'`

Чтобы создать символьный вектор, достаточно использовать функцию `с()`

```{r}
c("one", "two", "three")
```

#### Длина строки

В пакете `stringr` интуитивно понятные названия функций, все они начинаются с префикса `str_`. Например для проверки длины строки используется функция `str_length()`

```{r}
str_length(c("Я", "обожаю", "анализ", "данных", NA))
```

#### Объединение строк

Чтобы объединить две и больше строк используется `str_c()`, по аналогии с объединением символов в вектор

```{r}
str_c("x", "y")
```

Аргумент `sep` позволяет задать разделитель 

```{r}
str_c("x", "y", sep = "____,)))))")
```

Для вывода пропущенных значений использется функция `str_replace_na()`

```{r}
x <- c("abc", NA)
str_c("|-", x, "-|")
str_c("|-", str_replace_na(x), "-|")
```

Интересное свойство --- зацикливание длинного вектора по длине короткого:

```{r}
str_c("prefix-", c("a", "b", "c"), "-suffix")
```

Объекты длинной 0 опускаются. Этой возможностью особенно удобно пользоваться в сочетании с оператором `if`

```{r}
name <- "Hadley"
time_of_day <- "morning"
birthday <- FALSE

str_c(
  "Good ", time_of_day, " ", name,
  if (birthday) " and HAPPY BIRTHDAY",
  "."
)
```

Тут можно поиграться с выдачей, задавая значения дня. Для нуля и `NA` в выдаче не будет поздравления с днём рождения. Для всего остального соответственно будет

```{r}
name <- "Hadley"
time_of_day <- "morning"
birthday <- 8

str_c(
  "Good ", time_of_day, " ", name,
  if (birthday) " and HAPPY BIRTHDAY",
  "."
)
```

Для свёртывания строк в одну используется `collapse()`

```{r}
str_c(c("x", "y", "z"), collapse = ", ")
```


#### Извлечение подстрок

Для этого используется `str_sub()`, у неё есть аргументы `start` и `end`

```{r}
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)

# отрицательным числам соответствует отсчет с конца строки
str_sub(x, -3, -1)
```

А `str_sub()` можно использовать в форме присваивания для изменения строк

```{r}
str_sub(x, 1, 1) <- str_to_lower(str_sub(x, 1, 1))
x
```

#### Локали

* `str_to_lower()` --- делает все буквы прописными. 

* `str_to_upper()` --- переводит все буквы в верхний регистр.

* `str_to_title()` --- делает первую букву каждого слова прописной.

Не всё так просто с изменением регистров. Для разных языков действуют разные правила. Будь осторожен работая с преобразованием строк в разных языках.

#### Упражнение 14.2.5.1

<div class="question">
In code that doesn’t use stringr, you’ll often see `paste()` and `paste0()`. What’s the difference between the two functions? What stringr function are they equivalent to? How do the functions differ in their handling of `NA`?
</div>

Функция `paste()` по-умолчанию имеет разделитель пробел, а функция `paste0()` по умолчанию не имеет разделителя

```{r}
paste("агф", "фыуr")
paste0("fф34", "фыу")
```

В пакете `stringr()` на базовые функции похожа `str_c()`, она соответствует функции `paste0()`

```{r}
str_c("fф34", "фыу")
```

Однако `str_c()` и функции вставки обрабатывают NA по-разному. Функция `str_c()` распространяет NA, если какой-либо аргумент является пропущенным значением, он возвращает пропущенное значение. Это соответствует тому, как работает числовой R, например, `sum()`, `mean()`, обрабатывать пропущенные значения. Однако функции вставки преобразуют NA в строку «NA», а затем обрабатывают ее как любой другой символьный вектор --- жутко неудобно.

```{r}
paste0("fф34", "фыу", NA)
```


#### Упражнение 14.2.5.2

<div class="question">
In your own words, describe the difference between the sep and collapse arguments to str_c().
</div>

```{r}
i <- c("x", "y", "z")
str_c(i, collapse = ", ")
str_c("x", "y", "z", sep = ", ")
```

* `sep` --- это строка, вставленная между аргументами функции `str_c()`. Не работает с векторами

* `collapse` --- строка, используемая для разделения любых элементов символьного вектора на символьный вектор длины один. Работает с векторами

#### Упражнение 14.2.5.3

<div class="question">
Use `str_length()` and `str_sub()` to extract the middle character from a string. What will you do if the string has an even number of characters?
</div>

Если количество элементов нечётное, то чтобы найти средний элемент, нужно к максимальной длине строки прибавить единицу и разделить результат по полам --- ответ индекс среднего элемента.

Для того чтобы изъять один элемент не с конца, нужно началом и концом изъятия сделать одно и тоже число
```{r}
(x <- "1234567")
str_sub(x, (str_length(x)+1)/2, (str_length(x)+1)/2)
```

Если количество элементов чётное, то будем брать два значения, которые делят длину строки пополам. 
```{r}
(x <- "1234567")
str_sub(x, (str_length(x)+1)/2, (str_length(x)+2)/2)
```

Если такой вариант не подходит и нужно только одно значение, то в зависимости от задачи нужно выбрать либо большее либо меньшее значение


#### Упражнение 14.2.5.4
<div class="question">
What does `str_wrap()` do? When might you want to use it?
</div>

Функция `str_wrap()` переносит текст так, чтобы он умещался в пределах определенной ширины. Это полезно для переноса длинных строк текста для набора текста.

```{r}
x <- c("one, two, tree", "foo, bar")
str_wrap(x, indent = 5)
```

#### Упражнение 14.2.5.5
<div class="question">
What does `str_trim()` do? What’s the opposite of `str_trim()`?
</div>

Функция`str_trim()` удаляет пробел из строки.

```{r}
str_trim(" abc ")
str_trim(" abc ", side = "left")
str_trim(" abc ", side = "right")
```

Противоположностью `str_trim()` является `str_pad()`, которая добавляет символы с каждой стороны.

```{r}
str_pad("abc", 5, side = "both")
str_pad("abc", 4, side = "right")
str_pad("abc", 4, side = "left")
```

#### Упражнение 14.2.5.6
<div class="question">
Write a function that turns (e.g.) a vector `c("a", "b", "c")` into the string `"a, b, and c"`. 
Think carefully about what it should do if given a vector of length 0, 1, or 2.
</div>

На этом этапе я решаю задачу без знания функции --- то есть я решу в лоб, это будет не функция. 

Я вернусь сюда, когда научусь делать функции (привет Стас из будущего)

```{r}
foo <- c("a", "b", "c")

str_c(foo[[1]], ", ", foo[[2]], ", ", "and", " ", foo[[3]])
```

Функция должна работать следующим образом

* Если функции будет передаваться нулевой вектор, она должна возвращать пустую строку

* Если функции будет передаваться вектор длинной `1`, то функция должна возвращать строку с одни этим же элементом

* Если функции будет передаваться вектор длинной `2`, то функция должна вставлять между этими двумя элементами `" and "`

* Если функции будет передаваться вектор длинной больше чем `2`, то функция должна перечислять все элементы вектора через запятую, и перед последним элементом вставить `" and "`

























### Поиск соответствия шаблонам с помощью регулярных выражений

Регулярные выражения это просто и лаконично, нужно только понять принцип. Итак начнём

#### Базовые соответствия

Простейшие шаблоны в точности соответствуют строкам.

```{r}
x <- c("apple", "banana", "pear")
str_view(x, "")  # Покажет любой первый символ
str_view(x, "a") # Покажет соответсвия
str_view(x, ".a.") # Покажет заданную букву в окружении любых символов
```

Дальше по тексту будем следовать правилу

* регулярные выражения будут записываться `\.` 

* Строки представляющие эти выражения будут записываться как `"\\."`

Экранируем символ `\` вот так `\\\\`
```{r}
x <- "a\\b"
writeLines(x)
str_view(x, "\\\\")
```

##### Упражнение 14.3.1.1.1
<div class="question">
Explain why each of these strings don’t match a `\`: `"\"`, `"\\"`, `"\\\"`.
</div>

* `"\"` --- Это будет экранировать следующий символ в строке R.

* `"\\"` --- Это разрешит \ в регулярном выражении, что будет экранировать следующий символ в регулярном выражении.

* `"\\\"` --- первые две обратные косые черты будут преобразованы в буквальную обратную косую черту в регулярном выражении, третья будет экранирована следующим символом. Таким образом, в регулярном выражении это будет экранированный символ

##### Упражнение 14.3.1.1.2
<div class="question">
How would you match the sequence `"'\`?
</div>

```{r}
x <- "\"'\\"
writeLines(x)
str_view(x, "\"'\\\\", match = TRUE)
```

Экранируем символ двойной кавычки. Экранировать одинарную кавычку не нужно. Чтобы показать одинарный слэш, нужно ввести четыры.

##### Упражнение 14.3.1.1.2
<div class="question">
What patterns will the regular expression `\..\..\..` match? 
How would you represent it as a string?
</div>

```{r}
x <- "\\..\\..\\.."
writeLines(x)
str_view(x, "\\\\\\.\\.\\\\\\.\\.\\\\\\.\\.", match = TRUE)
```


#### Якоря

Якорь --- позиционная привязка

* `^` ---  совпадает с началом строки

* `$` --- совпадает с концом строки

```{r}
x <- c("apple", "banana", "pear")
str_view(x, "^a")
str_view(x, "a$")
```

Мнемоническое првавило: ВЫсокое положение `^` в иерархии всегда приводит к деньгам `$`

Чтобы принудить регулярное выражение к совпадениям только с целой строкой необходимо использовать оба якоря 

```{r}
x <- c("apple pie", "apple", "apple cake")
str_view(x, "apple")
str_view(x, "^apple$")
```

Для нахождения совпадений на границе слов можно использовать `\b`

##### Упражнение 14.3.2.1.1
<div class="question">
How would you match the literal string `"$^$"`?
</div>

```{r}
x <- "\"$^$\""
writeLines(x)
str_view(x, "\"\\$\\^\\$\"")
```

##### Упражнение 14.3.2.1.2
<div class="question">
Given the corpus of common words in `stringr::words`, create regular expressions that find all words that:

* Start with “y”.

* End with “x”

* Are exactly three letters long. (Don’t cheat by using `str_length()`!)

* Have seven letters or more.

Since this list is long, you might want to use the match argument to `str_view()` to show only the matching or non-matching words.
</div>

* начинаются с `y`

```{r}
str_view(stringr::words, "^y", match = TRUE)
```

* оканчиваются на `x`

```{r}
str_view(stringr::words, "x$", match = TRUE)
```

* состоят ровно из трёх букв
  
```{r}
str_view(stringr::words, "^...$", match = TRUE)
```

* состоят из семи или более букв
  
```{r}
str_view(stringr::words, "^.......", match = TRUE)
```


#### Символьные классы и чередования

* `.` --- совпадает с любым символом

* `\d` --- совпадает с любой цифрой. ЧТобы экранировать нужно использовать двойной слэш `\\d`

* `\s` --- совпадает с любым пробельным символом (пробел, табуляция, перевод строки) `\\s`

* `[abc]` --- совпадает с `a`, `b` или `c`

* `[^abc]` --- совпадает с любыми символами кроме `a`, `b` или `c`

Чередование обеспечивает возможность выбора альтернативов шаблона.

```{r}
str_view(c("grey", "gray"), "gr(e|a)y")
```

##### Упражнение 14.3.3.1.1
<div class="question">
Create regular expressions to find all words that:

* Start with a vowel.

* That only contain consonants. (Hint: thinking about matching “not”-vowels.)

* End with ed, but not with eed.

* End with ing or ise.
</div>

* Начинается с гласной
```{r}
str_view(stringr::words, "^[aeiou]", match = TRUE)
```

* Сoдержат только согласные
```{r}
str_view(stringr::words, "^[^aeiou]+$", match = TRUE)
```

* Оканчивается на `ed`, но не на `eed`.
```{r}
str_view(stringr::words, "[^e]ed$", match = TRUE)
```

* Оканчивается на `ing` или `ize`.
```{r}
str_view(stringr::words, "i(ng|ze)$", match = TRUE)
```

##### Упражнение 14.3.3.1.2
<div class="question">
Empirically verify the rule “i before e except after c”.
</div>

Правило гласит --- “i” пишется перед “e” (исключение — после “c”). Сначала проверяем слова, которые удовлетворяют правилу:

```{r}
str_view(stringr::words, "(cei|[^c]ie)", match = TRUE)
```

Теперь поищем слова, которые не соответствуют правилу:
```{r}
str_view(stringr::words, "(cie|[^c]ei)", match = TRUE)
```

##### Упражнение 14.3.3.1.3
<div class="question">
Is “q” always followed by a “u”?
</div>

В представленных словах других комбинаций не найдено
```{r}
str_view(stringr::words, "q[^u]", match = TRUE)
```

##### Упражнение 14.3.3.1.4
<div class="question">
Write a regular expression that matches a word if it’s probably written in British English, not American English.
</div>

С такими упраджнениями заодно и английский подтянешь. 
В общем случае сложно выполнить это упражнение, и может потребоваться словарь. 
Немного погуглив, появилось несколько эвристических соображений, которые должны учитывать некоторые распространенные случаи. 

Британский английский имеет тенденцию использовать следующее:

* “ou” в отличае от американского “o”

* “ae” и “oe” в отличае от американского  “a” и “o”

* слова заканчиваются на `ise` в отличае от американского `ize`

* слова заканчиваются на `yse`

Учитывая это, можно получить следующее регулярное выражение `ou|ise$|ae|oe|yse$` (или или или или)

##### Упражнение 14.3.3.1.5
<div class="question">
Create a regular expression that will match telephone numbers as commonly written in your country.
</div>

В России нет четко регламентированного стандарта, но есть общие правила, которых придерживаюсь и я. Подробно о рекомендуемых правилах записи телефонных номеров рассказал дизайнер Василий Никоноров в [своей статье](http://steinebel.ru/?go=all/phone-numbers/)

![alt text](img/phone-nums-rule.png)

Для записи телефонного номера, подойдёт следующее регулярное выражение: `+`

В представленных словах других комбинаций не найдено
```{r}
x <- c("+7 987 654-32-10", "+7(987)654-32-10", "8 (987) 654-32-10")
str_view(x, "\\+\\d\\s\\d\\d\\d\\s\\d\\d\\d-\\d\\d-\\d\\d")
```

#### Повторения

Сколько раз может встречаться *предшествующий* символ или выражение, чтобы совпадение считалось достигнутым 

* `?`: 0 или 1

* `+`: 1 или больше

* `*`: 0 или больше

```{r}
x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"
str_view(x, "CC?")
str_view(x, "CC+")
str_view(x, 'C[LX]+')
```

Кроме того можно определить точное количество совпадений 

* `{n}`: точно n раз

* `{n,}`: n или больше раз

* `{,m}`: самое большее m раз

* `{n,m}`: между n и m раз

```{r}
str_view(x, "C{2}")

str_view(x, "C{2,}")

str_view(x, "C{2,3}")
```

Полезно знать, что алгоритм поиска жадный, чтобы сделать его ленивым нужно добавить в конец выражения символ `?`

##### Упражнение 14.3.3.1.1
<div class="question">
Describe the equivalents of `?`, `+`, `*` in `{m,n}` form.
</div>

* `?`: 0 или 1 `{0,1}`

* `+`: 1 или больше `{1,}`

* `*`: 0 или больше `{0,}`


##### Упражнение 14.3.3.1.2
<div class="question">
Describe in words what these regular expressions match: (read carefully to see if I’m using a regular expression or a string that defines a regular expression.)

* `^.*$`

* `"\\{.+\\}"`

* `\d{4}-\d{2}-\d{2}`

* `"\\\\{4}"`
</div>

* `^.*$` Любой символ встречается ноль или более раз, другими словами --- это регулярное выражение ищет строку любой длины. Это регулярное выражение, его нужно экранировать

```{r}
str_view(c("cat", "$3.21", "data science"), "^.*$")
```

* `"\\{.+\\}"` Любой символ в курвах который встречается один или больше раз. Это строка описывающая регулярное выражение, не нужно экранировать

```{r}
str_view(c("{cat}", "${3.21}", "data science", "{}"), "\\{.+\\}")
```

* `\d{4}-\d{2}-\d{2}` Любое 4 значное число минус двузначное минус двузначное. Это регулярное выражение, его нужно экранировать

```{r}
str_view(c("2352-34-12", "232-34-12", "2352 34 12", "22-33-1239"), "\\d{4}-\\d{2}-\\d{2}")
```

* `"\\\\{4}"` Бэкслэш который встречается 4 раза. Это строка описывающая регулярное выражение, не нужно экранировать

```{r}
str_view(c("2352-34-12", "\\\\\\\\", "2352 34 12", " "), "\\\\{4}")
```

##### Упражнение 14.3.3.1.3
<div class="question">
Create regular expressions to find all words that:

* Start with three consonants.

* Have three or more vowels in a row.

* Have two or more vowel-consonant pairs in a row.
</div>


##### Упражнение 14.3.3.1.4
<div class="question">
Solve the beginner regexp crosswords at <https://regexcrossword.com/challenges/beginner>
</div>

Продолжаем постигать науку регулярных выражений. Идет со скрипом.

Решения я выкладываю в [репозиторий](https://github.com/driapitek/regex-crossword-solver) на гитхабе


#### Группирование и обратные ссылки

Круглые скобки определяют группы, на которые можно ссылаться с помощью обратных ссылок. Это регулярное выражение находит все фрукты, которые содержат повторяющиеся пары букв.

```{r}
str_view(fruit, "(..)\\1", match = TRUE)
```

##### Упражнение 14.3.5.1.1

<div class="question">
Describe, in words, what these expressions will match:

* `(.)\1\1`

* `"(.)(.)\\2\\1"`

* `(..)\1`

* `"(.).\\1.\\1"`

* `"(.)(.)(.).*\\3\\2\\1"`
</div>

Регулярные выражения --- это целое искусство. Чтобы их освоить нужно время. Больше информации о регулярных выражениях можно найти [на хабре](https://habr.com/post/115825/)

* `(.)\1\1` --- один и тот же символ появляется три раза подряд. Только нужно экранировать запись

```{r}
str_view("fffff", "(.)\\1\\1")
```


* `"(.)(.)\\2\\1"` --- За парой символов следует одна и та же пара символов в обратном порядке.

```{r}
str_view(c("fffff", "oihoiahsodh", "arra"), "(.)(.)\\2\\1")
```

* `(..)\1` --- Два символа повторяются. Нужно экранировать

```{r}
str_view(c("fffff", "1212", "arra"), "(..)\\1")
```

* `"(.).\\1.\\1"` --- Пять символов, повторяется нечётный

```{r}
str_view(c("fffff", "2f2f2", "arra"), "(.).\\1.\\1")
```

* `"(.)(.)(.).*\\3\\2\\1"` --- Три символа, за которыми следуют ноль или более символов любого вида, за которыми следуют те же три символа, но в обратном порядке.

```{r}
str_view(c("adssda", "123 321", "are2222era"), "(.)(.)(.).*\\3\\2\\1")
```

##### Упражнение 14.3.5.1.2

<div class="question">
Construct regular expressions to match words that:

* Start and end with the same character.

* Contain a repeated pair of letters (e.g. church'' containsch’’ repeated twice.)

* Contain one letter repeated in at least three places (e.g. eleven'' contains threee’’s.)
</div>

* Начинается и заканчивается с одного и того же символа. 

```{r}
str_view(c("a", "ii;ji", "are2222era"), "^(.)((.*\\1$)|\\1?$)")
```

* СОдержит повторяющуюся пару букв

```{r}
str_view(c("a", "ii;ji", "afre2222ereaa"), "([A-Za-z][A-Za-z]).*\\1")
```

* СОдержит одну букву повторяющуюся по крайне мере в трёх местах

```{r}
str_view(c("eleven", "ii;j", "afre2222ereaa"), "([a-z]).*\\1.*\\1")
```

### Инструментарий

Разбивай сложное выражение на несколько простых

#### Обнаружение совпадений

Для обнаружения совпадений используется функция `str_detect()`
```{r}
x <- c("apple", "banana", "pear")
str_detect(x, "e")
```

Она возвращает логический вектор, благодаря этому её удобно использовать для нахождения некоторых полезных вещей. Например, количество вхождений

```{r}
# Сколько слов начинаются с буквы t?
sum(str_detect(words, "^t"))
```

Или среднее количество слов содержащих определённую комбинацию

```{r}
# Какова доля слов, оканчивающихся на гласную?
mean(str_detect(words, "[aeiou]$"))
```

Когда у вас сложные логические условия (например, соответствуют `a` или `b`, но не `c`, если не `d`), часто проще объединить несколько вызовов `str_detect()` с логическими операторами, чем пытаться создать одно регулярное выражение. Например, вот два способа найти все слова, которые не содержат гласных:

```{r}
# Найти все слова, содержащие хотя бы одну гласную и инвертировать эту операцию "!"
no_vowels_1 <- !str_detect(words, "[aeiou]")

# Найти все солова, состоящие только из согласных символов не являющихся гласными
no_vowels_2 <- str_detect(words, "^[^aeiou]+$")
identical(no_vowels_1, no_vowels_2)
```

Как говорилось ранее --- если регулярное выражение усложняется простым и логичным шагом будет такой подход: разбить на простые части, объединить простые части логическим оператором.

Есть удобная функция оболочка `str_subset()`, она используется для выбора элементов соответствующзих шаблону.

```{r}
words[str_detect(words, "x$")]
str_subset(words, "x$")
```

Однако обычно строкой будет один из столбцов фрейма данных, и вместо этого будет использоваться фильтр.

```{r}
df <- tibble(
  word = words, 
  i = seq_along(word) # используется для генерации регулярных последовательностей
)
df %>% 
  filter(str_detect(word, "x$")) # фильтрует заданный набор данных, оставляя только те слова, в которых на конце х
```

`str_count()` сообщает сколько совпадений обнаружено в строке

```{r}
x <- c("apple", "banana", "pear")
str_count(x, "a")

# сколько гласных в среднем приходится на одно слово
mean(str_count(words, "[aeiou]"))
```

`str_count()` естественно использовать с `mutate()` 

```{r}
df %>%
  mutate(
    vowels = str_count(word, "[aeiou]"),
    consonants = str_count(word, "[^aeiou]")
  )
```

Интересная особенность --- совпадения никогда не перекрываются. Сколько раз в строке `"abababa"` встречается шаблон `"aba"`? Регулярное выражение скажет что он встречается два раза, а не три

```{r}
str_count("abababa", "aba")

str_view_all("abababa", "aba")
```

Обратим внимание на последнюю функцию. В пакете `string` многие функции идут парами --- одна работает с одиночными совпадениями, другая со всеми.

##### Упражнение 14.4.1.1.1
<div class="question">
For each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple `str_detect()` calls.

* Find all words that start or end with x.

* Find all words that start with a vowel and end with a consonant.

* Are there any words that contain at least one of each different vowel?

* What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator?)
</div>

* В общем случае

```{r}
# все слова начинающиеся или заканчивающиеся на X
str_view_all(words, "^x|x$", match = TRUE)

df %>%
  filter(str_detect(words, "^x|x$")) #  Указан порядковый номер слова
```

А теперь разберём

```{r}
# Одним регулярным выражением
words[str_detect(words, "^x|x$")]

# Двумя отдельными выражениями
start_with_x <- str_detect(words, "^x")
end_with_x <- str_detect(words, "x$")
words[start_with_x | end_with_x]
```

* В общем случае. Ругелярное выражение такое --- ищи первым символом любую гласную, после этого может быть любой символ один или больше раз, а оканчиваться слово должно на любую негласную букву.

```{r}
# все слова начинающиеся на гласную, а заканчивающиеся на согласную
str_view_all(words, "^[aeiou].*[^aeiou]$", match = TRUE)

df %>%
  filter(str_detect(words, "^[aeiou].*[^aeiou]$")) #  Указан порядковый номер слова
```

А теперь разобьём

```{r}
# Одним регулярным выражением
words[str_detect(words, "^[aeiou].*[^aeiou]$")]

# Двумя отдельными выражениями
start_with_x <- str_detect(words, "^[aeiou]")
end_with_x <- str_detect(words, "[^aeiou]$")
words[start_with_x & end_with_x]
```

* В общем случае, cлова, в которых гласная содержится хотя бы один раз -- не придумал способ реализации. 

```{r}
# Сочетание нескольких регулярных выражений
words[str_detect(words, "a") &
      str_detect(words, "e") &
      str_detect(words, "i") &
      str_detect(words, "o") &
      str_detect(words, "u")]
```

* Доля гласных это отношение количества гласных букв в слове, к длине всего слова. Я предполагаю, что самым длинным будет какое-то особое слово, в котором кол-во букв, совпадает с кол-вом гласных. 

```{r}
(vowels <- str_count(words, "[aeiou]")) # Считаем кол-во гласных в слове
max(vowels) # Максимальное кол-во гласных в слове 5 штук
words[which(vowels == max(vowels))] # Берём слова, с максимальным количеством гласных
prop_vowels <- str_count(words, "[aeiou]") / str_length(words) # Считаем долю гласных букв от всего слова.
words[which(prop_vowels == max(prop_vowels))] # Берём словам, с максимальной долей гласных
```

#### Извлечение совпадений

Для извлечение фактического текста совпадегния используется функция `str_extract()`. Для демонстрации воспользуемся текстом  [Harvard senteces](https://en.wikipedia.org/wiki/Harvard_sentences).

Предложения, составляющие этот текст предоставляются пакетом `stringr::sentences`

```{r}
length(sentences)
head(sentences)
```

Предположим мы хотим найти все предложения, в которых упоминается цвет. Сначала мы создаем вектор названий цветов:

```{r}
colors <- c("red", "orange", "yellow", "green", "blue", "purple")
```

А затем превращаем его в одиночное регулярное выражение:

```{r}
(color_match <- str_c(colors, collapse = "|"))
```

После этого можно выбрать все предложения, в которых упоминается какой-либо цвет:

```{r}
has_color <- str_subset(sentences, color_match)
```

А затем извлечь каждый цвет, чтобы увидеть, что это за цвета:

```{r}
(matches <- str_extract(has_color, color_match))
```

*Функция `sub_extract()` извлекает лишь первое совпадение*. Это легче всего увидеть, если выбрать сначала все предложения, в которых имеется более одного совпадения

```{r}
more <- sentences[str_count(sentences, color_match) > 1]
str_view_all(more, color_match)
str_extract(more, color_match)
```

Это обычная схема при работе с пакетом `stringr`, поскольку одиночные структуры проще. Для получения всех совпадений используем функцию `str_extract_all()`. Но она уже возвращает список, с которым несколько затруднительнее работать.

```{r}
str_extract_all(more, color_match)
```

Если передать функции `str_extract_all()` аргумент `simplify = TRUE`, она вернёт матрицу, в которой короткие совпадения расширены до той же длины, что и самое длинное.

В разобранном выше примере это сложно понять, посколько в каждом предложение указанный цвет встречается по два раза:

```{r}
str_extract_all(more, color_match, simplify = TRUE)
```

Легче понять по искусственному примеру:

```{r}
# Вводим переменную, с кол-вом букв в каждом векторе 1,2,3 соответственно
x <- c("a", "a b", "a b c")
# Ищем совпадение любой буквы в переменной x, с расширением недостающих совпадений
str_extract_all(x, "[a-z]", simplify = TRUE)
```

##### Упражнение 14.4.3.1.1
<div class="question">
In the previous example, you might have noticed that the regular expression matched “flickered”, which is not a color. Modify the regex to fix the problem.
</div>

Выдача результата проводится при любом найденном совпадении. Для того чтобы искать только слова обозначающие цвет, а не любое найденное совпадение символов, достаточно чтобы искалось слово целиком.

```{r}
colors <- c("red", "orange", "yellow", "green", "blue", "purple")
color_match <- str_c(colors, collapse = "|")
more <- sentences[str_count(sentences, color_match) > 1]
str_view_all(more, color_match)
```

Для этого удобно использовать оператор: `\b` --- он ищет совпадение в начале или конце. Нам нужно чтобы найденные символы были началом и концом слова, иными словами чтобы это было слово целиком

```{r}
colors <- c("red", "orange", "yellow", "green", "blue", "purple")
color_match2 <- str_c("\\b(", str_c(colors, collapse = "|"), ")\\b")
more <- sentences[str_count(sentences, color_match) > 1]
str_view_all(more, color_match2)
```

##### Упражнение 14.4.3.1.2
<div class="question">
From the Harvard sentences data, extract:

* The first word from each sentence.

* All words ending in ing.

* All plurals.
</div>

* Я сразу буду пытаться упрощать и стараться не лепить огромные регулярные выражения. 
Поэтому я буду часто использовать некоторые сокращенные записи для классов символов. 
Вот их неполный перечень

| Обозначение| Описание      |
| -----------|:------------------:|
|`\w`|	Word (a-z, A-Z, 0-9, including _ (underscore))|
|`\W`|	Non-word|
|`\d`|	Digit (0-9)|
|`\D`|	Non-digit|
|`\s`|	Whitespace|
|`\S`|	Not whitespace|
|`\b`|	Match at beginning or end|
|`\B`|	Do not match at beginning or end|
|`\0`|	NULL character|
|`\n`|	New line|

Сначала я подумал, что идеально для цели "извлечь первое слово" подходит оператор `\w` --- любое слово:

```{r}
str_view(sentences, "\\w+") # найти один или более буквенный символ
```

Но у меня возникли сомнения по поводу конструкции `It's` --- это одно слово или два? Кроме того бывают слова написанные через дефис, например название города `Baden-Baden`. Поэтому я решил действовать навярняка --- я буду брать конструкцию целиком до первого пробела.

```{r}
str_view(sentences, "\\S+") # найти один или более не пробельных символов
```

тогда итоговое решение будет выглядеть следующим образом:

```{r}
str_extract(sentences, "\\S+") %>%
  head()
```

Мне показалось ошибочным моё решение, поскольку я нашёл предложение, которое начинается со слова `ii`.
```{r}
sentences[284]
```

Однако, действительно, это предложение начинается с двух гласных, первая из которых строчная.

* Как и в первом упражнении, нужно найти слово целиком, для этого нужно использовать оператор `\b`.


```{r}
str_view_all(sentences, "\\b[A-Za-z]+ing\\b", match = TRUE) # Найти слова первые один или более буквенных символов и оканчивающиеся на `ing`
```

```{r}
(ing <- str_detect(sentences, "\\b[A-Za-z]+ing\\b"))  # Содержит ли предложение слово с инг-овым окончанием
sentences[ing]                                        # предложения с инговым окончанием
str_extract_all(sentences[ing], "\\b[A-Za-z]+ing\\b") # Используем extract_all, потому что в предложении может быть несколько инг-овых слов.
```

С такой структурой полученного набора неудобно работать. Для того чтобы упростить полученный набор до вектора используем функцию `unlist()`. Учитывая структуру списка на входе, `unlist()` упрощает его для создания вектора, который содержит все атомарные компоненты, которые встречаются во входном списке.

```{r}
unlist(str_extract_all(sentences[ing], "\\b[A-Za-z]+ing\\b"))
```

С полученным вектором уже удобнее работать, к примеру можно извлечь уникальные слова оканчивающиеся на -ing, встречающиеся в исходном наборе:

```{r}
unique(
  unlist(
    str_extract_all(
      sentences[ing], "\\b[A-Za-z]+ing\\b")
    )
  )
```


* Поиск всех слов во множественном числе только регулярными выражениями будет трудной задачей, если соблюдать все правила языка. Потому что помимо добавления к слову окончания `s` есть ещё ряд условий такие как:

  * если существительное заканчивается на: -o, -ch, -sh, -ss или -x, множественное число образуется путем добавления окончания `-es`.

  * если существительное оканчивается на -y и перед -y стоит согласная буква, мы "y" меняем на "i" и добавляем `-es`.
  
  * 12 существительных оканчивающихся на - f или - fe, при образовании множественно числа "теряют" - f или - fe, но приобретают - ves.
Вот они: calf (теленок), half (половина), knife (нож), leaf (лист дерева), life (жизнь), loaf (буханка, каравай), self (сам, себя), sheaf (сноп, вязанка), shelf (полка), thief (вор), wife (жена), wolf (волк).

  * ряд существительных, у которых множественное число образуется за счет изменения гласной (а в некоторых случаях, за счет добавления окончания - en / - ren). foot (нога, ступня) - feet, tooth (зуб) - teeth, man (мужчина, человек) - men, woman (женщина) - women, mouse (мышь) - mice, goose (гусь) - geese, louse (вошь) - lice, child (ребенок) - children, ox (бык, вол) - oxen.

  *  Существительные deer (олень) и sheep (овца) имеют одинаковую форму, как для единственного, так и для множественно числа. sheep - sheep, deer - deer.

Мне кажется, проще на данном этапе решить задачу в общей форме --- искать все слова у которых не менее трёх букв перед `s`. Три для того чтобы отсечь слова наподобие `as, is, gas`. Итого имеем:

```{r}
unique(
  unlist(
    str_extract_all(sentences, "\\b[A-Za-z]{3,}s\\b")
    )
  )
```

#### Разбиение совпадений на группы

Круглые скобки можно использовать 

* для расстановки приоритетов, 

* для обеспечения возможности обратных ссылокв процессе обнаружения совпадений,

* для извлечения частей сложных совпадений

Предположим, есть необходимость извлечь существительное из предлдожений. Приближением приближенным к реальности (или эвристикой) будет поиск любого слова следующего за артиклем `a` или `the`. Определение "слова" в регулярном выражение не совсем простая штука, поэтому мы воспользуемся приближением --- слово это последовательность, состоящая по крайне мере из одного символа, не являющегося пробелом.

```{r}
noun <- "(a|the) ([^ ]+)"

has_noun <- sentences %>%
  str_subset(noun) %>%
  head(10)

has_noun %>% 
  str_extract(noun)
```

Функция `str_extract` даёт нам полное совпадение, функция `str_match` --- каждый отдельный его компонент. Вместо символьного вектора она возвразает матрицу с одним столбцом для полного совпадения, за которым следуют столбцы, по одному для каждой группы.

```{r}
has_noun %>% 
  str_match(noun)
```

*Важно!* 

Если данные содержатся в tibble-фрейме, зачастую проще использовать функцию `tidyr::extract()`. Она работает подобно `str_match()`, но требует чтобы мы именовали совпадения, которые затем помещаются в новые столбцы

```{r}
tibble(sentence = sentences) %>% 
  tidyr::extract(
    sentence, c("article", "noun"), "(a|the) ([^ ]+)", 
    remove = FALSE
  )
```


##### Упражнение 14.4.3.1.1
<div class="question">
Find all words that come after a “number” like “one”, “two”, “three” etc. Pull out both the number and the word.
</div>

Это задание очень похоже на пример разобранный в книге, с той лишь разницей, что в задаче необходимо перечислить все числительные.



```{r}
numbers <- "(one|two|three|four|five|six|seven|eight|nine|ten) +(\\S+)"

has_numbers <- sentences %>%
  str_subset(numbers) %>%    # str_subset() используется для выбора элементов, соответствующих шаблону
  head(10)

has_numbers %>%              # Выводим все совпадения в красивую матрицу
  str_match(numbers)
```

##### Упражнение 14.4.3.1.2
<div class="question">
Find all contractions. Separate out the pieces before and after the apostrophe.
</div>

Необходимо найти все сокращения.
Напомню, что в английском языке можно сокращать некоторые слова. В таких случаях ставится апостроф `'` на место пропуска букв.

```{r}
contractions <- sentences %>%
  str_subset("(\\S+)'(\\S+)")

contractions %>%
  str_match("(\\S+)'(\\S+)")
```

#### Замена совпадений

Функции `str_replace()` и `str_replace_all()` позволяют заменять совпадения новыми строками. Проще всего заменить шаблон фиксированной строкой. 

```{r}
x <- c("apple", "pear", "banana")
str_replace(x, "[aeiou]", "-")     # Заменяет первое совпадение
str_replace_all(x, "[aeiou]", "-") # Заменяет все совпадения
```

С помощью последней функции можно выполнять множественную замену, предоставляя именованный вектор.

```{r}
x <- c("1 house", "2 cars", "3 people")
str_replace_all(x, c("1" = "one", "2" = "two", "3" = "three"))
```

Вместо замены совпадений фиксированной строкой можно использовать обратные ссылки для вставки компонентов совпадений. В следующем коде мы меняем порядок следования второго и третьего слов.

```{r}
sentences %>% 
  str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") %>% 
  head(5)
```

##### Упражнение 14.4.4.1.1
<div class="question">
Replace all forward slashes in a string with backslashes.
</div>

Напоминаю, чтобы вывести обратную косую черту, необходиму её трижды экранировать.
```{r}
str_replace_all("C:/user/no_porn", "/", "\\\\")
```

##### Упражнение 14.4.4.1.2
<div class="question">
Implement a simple version of `str_to_lower()` using `replace_all()`.
</div>

Функция `str_to_lower()` делает все буквы высшего регистра в малом регистре. Т.е. фактически необходимо заменить заглавные на маленькие буквы. Я использую короткую версию, но принцип масштабируется на весь алфавит

```{r}
# Я пока что наиндусил в коде:
(lower <- str_replace_all(words, c("A"="a", "B"="b", "C"="c", "D"="d", "E"="e", "F"="f", "G"="g", "H"="h", "I"="i", "J"="j", "K"="k", "L"="l", "M"="m", "N"="n", "O"="o", "P"="p", "Q"="q", "R"="r", "S"="s", "T"="t", "U"="u", "V"="v", "W"="w", "X"="x", "Y"="y", "Z"="z")))
```

##### Упражнение 14.4.4.1.3
<div class="question">
Switch the first and last letters in words. Which of those strings are still words?
</div>

Будем действовать как в примере, разобранном в книге, когда мы меняли порядок групп. В этой задаче тоже будет три группы.

* Первая группа --- это первый буквенный символ в слове

* Вторая группа --- это любой символ, встречающийся ноль или более раз

* Третья группа --- это последний буквенный символ в слове

```{r}
swap <- str_replace_all(words, "^([A-Za-z])(.*)([a-z])$", "\\3\\2\\1")
swap
```

2. После замены символов, словами останутся:

  * слова, оканчивающиеся на одну и ту же букву (слова из одной буквы частный случай), например --- "dad"
  
  * слова, которые начинающиеся и оканчивающиеся на взаимозаменяемые буквы (палиндром частный случай), например "lead" --- "deal"

Чтобы найти такие слова, будем искать полученные в результате замены букв слова в исходной выборке. Для этого воспользуемся функцией, которую мы изучили в прошлой теме. Функция `intrsect(x, y)` возвращает только наблюдения, содержащие одновременно в `х` и `у`

```{r}
intersect(swap, words)
```

#### Разбиение строк

Функции `str_split` позволяeт разбивать строки на части. Например, можно разбить предложения на слова.

```{r}
sentences %>%
  head(5) %>%
  str_split(" ")
```

По скольку каждый компонент может состоять из разного количества частей, функция возвращает список. Если работаем со списком длинной один, то проще всего извлечь первый элемент списка.

```{r}
"a|b|c|d" %>% 
  str_split("\\|") %>% 
  .[[1]]
```

В противном случае, как и про работе с другими функциями, возвращающими список, можно использовать параметр `simplify = TRUE` который вернёт матрицу.

```{r}
sentences %>%
  head(5) %>% 
  str_split(" ", simplify = TRUE)
```

Можно запросить максимальное количество частей, котооре 

```{r}
fields <- c("Name: Hadley", "Country: NZ", "Age: 35")
fields %>% str_split(": ", n = 2, simplify = TRUE)
```

Вместо разбивки слов по шаблонам, можно разбивать по границам символов, строк, предложений или слов

```{r}
x <- "This is a sentence.  This is another sentence."
str_view_all(x, boundary("word"))
```

```{r}
str_split(x, " ")[[1]]

str_split(x, boundary("word"))[[1]]
```

Функция `boundary()` сопоставляет границы между вещами

##### Упражнение 14.4.5.1.1
<div class="question">
Split up a string like `"apples, pears, and bananas"` into individual components.
</div>

Разбивать строку будем по границам слов, сопоставляя со списком слов. 
И так как мы работаем с списком длинной один, возьмём первый элемент.

```{r}
x <- "apples, pears, and bananas"
str_split(x,  boundary("word"))[[1]]
```

##### Упражнение 14.4.5.1.2
<div class="question">
Why is it better to split up by boundary("word") than " "?
</div>

Лучше разделять предложение по границам слов, потому что при разбиении по пробелам в слово цепляются символы, в примере выше это запятые.

```{r}
x <- "apples, pears, and bananas"
str_split(x,  " ")[[1]]
```

Рассмотрим пример из [Unicode Report on word boundaries](http://www.unicode.org/reports/tr29/#Word_Boundaries)

```{r}
sentence <- "The quick (“brown”) fox can’t jump 32.3 feet, right?"
str_split(sentence,  " ")[[1]]
```

В разбиение попали слова с символами, что не совсем корректно --- показателен пример `(“brown”)`.

```{r}
str_split(sentence, boundary("word"))[[1]]
```

Так гораздо лучше.

##### Упражнение 14.4.5.1.3
<div class="question">
What does splitting with an empty string `("")` do? Experiment, and then read the documentation.
</div>

Она разобьет строку на одтельные символы

```{r}
x <- "apples, pears, and bananas"
str_split(x,  "")[[1]]
```

Документация говорит, что пустой паттерн `""` эквивалентен границе символа. An empty pattern, "", is equivalent to boundary("character").

#### Поиск совпадений

Функции `str_locate()` и `str_locate_all()` дают начальную и конечную позиции каждого совпадения. Они особенно полезны, когда ни одна из других функций не делает именно то, что нужно. МОжно использовать `str_locate()`, чтобы найти соответствующий шаблон, а затем `str_sub()`, чтобы извлечь и/или изменить их.

### Другие типы шаблонов

Когда используется шаблон, являющийся строкой, она автоматически помещается в вызов функции `regex()`

```{r}
# Обычный вызов
str_view(fruit, "nana")
# Является сокращенной записью вызова
str_view(fruit, regex("nana"))
```

Передавая функции `regex()` дополнительные аргументы, можно управлять деталями сопоставления строк с шаблоном.

* `ignore_case = TRUE` --- позволяет игнорировать регистр символов при сопоставлении с шаблоном. В первом из приведенных ниже вызовов функции `str_view()` используется текущая локаль

```{r}
bananas <- c("banana", "Banana", "BANANA")
str_view(bananas, "banana")
str_view(bananas, regex("banana", ignore_case = TRUE))
```

* `multiline = TRUE` --- разрешает специальным символам  `^` и `$` совпадать с началом и концом каждой логической строки, а не полной строки

```{r}
x <- "Line 1\nLine 2\nLine 3"
str_extract_all(x, "^Line")[[1]]
str_extract_all(x, regex("^Line", multiline = TRUE))[[1]]
```

* `comments = TRUE` --- разрешает использование комментариев и пробельных символов для повышения удобочитаемости сложных регулярных выражений. Пробелы, как и весь остальной текст после символа `#`, игнорируются. Чтобы литеральный символ пробела учитывался при сопоставлении, его необходимо экранировать `"\\"`

```{r}
phone <- regex("
  \\(?     # optional opening parens
  (\\d{3}) # area code
  [) -]?   # optional closing parens, space, or dash
  (\\d{3}) # another three numbers
  [ -]?    # optional space or dash
  (\\d{3}) # three more numbers
  ", comments = TRUE)

str_match("514-791-8141", phone)
```

* `dotall = TRUE` разрешает символу "точка" `.` совпадать с любым символом, включая `\n`

Существуют три другие функции, которые можно использовать вместо функции `regex()`

* `fixed()` --- ищет точные совпадения с указанной последовательностью байтов. Эта функция игнорирует все специальные регулярные выражения и работает на очень низком уровне, что позволяет избежать сложного экранирования символов и значительно повысить быстродействие. В соответствии с результатами приведённого ниже теста быстродействие в этом простом примере увеличилось в три раза.

```{r}
microbenchmark::microbenchmark(
  fixed = str_detect(sentences, fixed("the")),
  regex = str_detect(sentences, "the"),
  times = 20
)
```

Нужно проявлять осторожно, использую `fixed()` для работы с данными, подготовленными не на английском. Это весьма проблематично, поскольку для представления одного и того же символа существует несколько способов. Пример из книги:

символ `á` можно представить как одиночный символ или как символ `а` плюс акцент

```{r}
a1 <- "\u00e1"
a2 <- "a\u0301"
c(a1, a2)
a1 == a2
```

Визуализированные символы выглядят одинаковыми, но таковыми не являются, и функция `fixed()` не обнаруживает совпадения. Вместо этого можно использовать функцию `coll()`, которая уважает принятые среди людей правила сравнения символов.

```{r}
str_detect(a1, fixed(a2))
str_detect(a1, coll(a2))
```

* `coll()` --- сравнивает строки, используя стандартные правила сравнения. Это полезно при выполнении поиска без учета регистра букв. Этой функции можно задать параметр `locale`.

```{r}
# Это означает, что при выполнении поиска, не зависящего от
# регистра букв, нужно учитывать все отличия

i <- c("I", "İ", "i", "ı")
i

str_subset(i, coll("i", ignore_case = TRUE))

str_subset(i, coll("i", ignore_case = TRUE, locale = "tr"))
```

Функции `fixed()` и `regex()` имеют аргумент `ignore_case = TRUE`, но оги не дают возможность выбирать локаль: они всегда используют локаль, заданную по умолчанию. Можно убедится на примере следующего кода:

```{r}
stringi::stri_locale_info()
```

Слабым местом функции `coll()` является скорость работы. Поскольку правила определения эквивалентности символов чрезвычайно сложны, функция `coll()` работает медленнее по сравнению с функциями `fixed()` и `regex()`.

*  В примере с функцией `str_split()` уже знаем применение функции `boundary()` для сопоставления с границами. То же самое можно сделать и с другими функциями.

```{r}
x <- "This is a sentence."
str_view_all(x, boundary("word"))

str_extract_all(x, boundary("word"))
```

#### Упражнение 14.5.1.1
<div class="question">
How would you find all strings containing `\` with regex() vs. with fixed()?
</div>

```{r}
string <- c("a\\b", "ab")
```


* При помощи функции `regex()`

```{r}
str_subset(string, "\\\\")
```

* При помощи функции `fixed()`

```{r}
str_subset(c("a\\b", "ab"), fixed("\\"))
```

#### Упражнение 14.5.1.2
<div class="question">
What are the five most common words in sentences?
</div>

Я предположу, что чаще всего используются артикли и предлоги. Проверим это.
Для того чтобы определить какие слова используются чаще других, нужно их посчитать. Но перед этим все слова в предложении нужно разбить на слова, без использования символов. Для этого воспользуемся разбиением при помощи функции `boundary()`
```{r}
str_view_all(sentences, boundary("word"))
str_extract_all(sentences, boundary("word"))[[1]] # Беру первое измерение для примера
```

Эта функция выводит список, с которым трудно работать, для того чтобы превратить список в матрицу, я буду использовать функцию `unlist()`

```{r}
unlist(str_extract_all(sentences, boundary("word")))
```

Она преобразовала все разбитые на слова предложения в один вектор.

Далее чтобы с этим было удобнее работать, преобразуем вектор в tibble-формат, т.е. таблицу с одним столбцом.

```{r}
tibble(word = unlist(str_extract_all(sentences, boundary("word"))))
```

Как видно, есть слова начинающиеся с заглавной буквы, по этой причине слова `The` и `the` будут считаться как два разных слова. Так не годится,  нужно перевести всё в один регистр. Для этого добавим ещё один столбец, в котором при помощи функции `str_to_lower()` переведём все символы высокого регистра в низкий.

```{r}
tibble(word = unlist(str_extract_all(sentences, boundary("word")))) %>%
  mutate(to_lower = str_to_lower(word))
```

И после этого осталось только посчитать количество раз, которое встречается каждое слово. Для этого воспользуемся функцией `count()`  с параметром `sort = TRUE` для сортировки по возрастанию. По условию задачи нам нужно пять самых часто встречаемых слов, поэтому возьмём `head(5)`.

```{r}
tibble(word = unlist(str_extract_all(sentences, boundary("word")))) %>%
  mutate(to_lower = str_to_lower(word)) %>%
  count(to_lower, sort = TRUE) %>%
  head(5)
```

### Другие применения регулярных выражений

В базовый состав R входят еще две функции, которы так же используют regex

* `apropos()` --- выполняет поиск всех объектов, доступных в глобальном окружении. Эту фкнецию удобно использовать в тех случаях, когда вы не можете вспомнить точное имя какой-то функции.

```{r}
apropos("replace")
```

* `dir()`--- перечисляет все файлы, зранящиеся в каталоге. Аргемент `pattern` принимает регулярное выражение и возвращает имена лишь тех файлов, которые соответствуют шаблону. Например, можно найти все файлы R Markdown в текущем каталоге с помощью следующего кода

```{r}
head(dir(pattern = "\\.Rmd$"))
```

### Пакет `stringi`

Пакет `stringr` построени поверх пакета `stringi`. В `stringr` всего 42 функции, в `stringi` аж 234. Вызов функции различается лишь префиксом `stri_` для `stringi`

#### Упражнение 14.7.1.1
<div class="question">
Find the `stringi` functions that:

1. Count the number of words.

2. Find duplicated strings.

3. Generate random text.
</div>

1. Подсчитывает количество слов:

```{r}
apropos("stri_count")
```

Это функция --- `stri_count_words()`

2. Находит повторяющиеся строки:

```{r}
apropos("stri_repeat") # нет, не угадал
apropos("stri_duplicate")
```

Это функция --- `stri_duplicated()`

3. Генерирует случайный текст

```{r}
apropos("stri_rand")
```

Целых три функции:

  * `stri_rand_lipsum()` генерирует lorem-ipsum текст
  * `stri_rand_strings()` генерирует рандомную строку
  * `stri_rand_shuffle()` случайным образом перемешивает кодовые точки (символы) в тексте.

<!--chapter:end:11_string.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Работа с факторами с помощью пакета `forcats`

### Введение

Факторы используются для работы с категориальными переменными. Их так же можно использовать если нужно отобразить символьные векторы в порядке следования, отличающимся от алфавитного.

#### Используемые ресурсы

```{r}
library(tidyverse)
library(forcats)
library(stringr)
```

### Создание факторов

Предположим есть переменная, в которой внесены названия месяцев

```{r}
x1 <- c("Dec", "Apr", "Jan", "Mar")
```

Есть пару проблем с записью строки в эти перменные

* Возможны опечатки

```{r}
x2 <- c("Dec", "Apr", "Jam", "Mar")
```

* Список сортируется не правильно, т.е. он сортируется не по месяцам а по алфавиту.

```{r}
sort(x1)
```

Обе проблемы решаются использованием фактора. Чтобы создать фактор нужно

1. Создать список допустимых уровней.

```{r}
month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
```

1. Теперь можно создать фактор

```{r}
y1 <- factor(x1, levels = month_levels)
y1
sort(y1)
```

Любые значения не входящие в этот набор автоматически будут преобразовываться в `NA`. 

```{r}
y2 <- factor(x2, levels = month_levels)
y2
```

Можно получить сообщения об ошибках, используя функцию `readr::parse_factor()`

```{r}
y2 <- parse_factor(x2, levels = month_levels)
```

Если опустить уровни, они будут браться из данных в алфавитном порядке

```{r}
factor(x1)
```

Иногда предпочтительнее, чтобы порядок уровней совпадал с порядком первого появления в данных. Можно сделать это в процессе создания фактора путем задания уровней для функции `unique()` или уже постфактум с помощью функции `fct_inorder()`

```{r}
f1 <- factor(x1, levels = unique(x1))
f1
f2 <- x1 %>% factor() %>% fct_inorder()
f2
```

Если потребуется непосредственный доступ к набору допустимых уровней, это можно сделать с помошью функции `levels()`

```{r}
levels(f2)
```

### Опрос GSS

В оставшейся части главы работаем с `forcats::gss_cat` это данные, предоставленные General Society Survey --- общенациональный социальный опрос США

```{r}
gss_cat
```

Информация о перменных по запросу хэлпа `?gss_cat`.

Если факторы хранятся в тиббле-фрэйме, мы не сможем увидеть их, не предпринимая никаких мер. Один из способов использовать функцию `count()`. Другой --- более наглядный, использовать построение диаграмой.

```{r}
gss_cat %>% count(race)

ggplot(gss_cat, aes(race)) +
  geom_bar()
```

По умолчанию опускаются уровни, в которых не было ни одного значения, это не всегда полезно. Иногда нужно посмотреть и не встречающиеся значения. Для этого нужно принудлительно просить R показать таких перменные при помощи функции `scale_x_discrete()`

```{r}
ggplot(gss_cat, aes(race)) +
  geom_bar() +
  scale_x_discrete(drop = FALSE)
```

#### Упражнение 15.3.1.1
<div class="question">
Explore the distribution of `rincome` (reported income). What makes the default bar chart hard to understand? How could you improve the plot?
</div>

Всё потому что подписи по абсциссе смешались в кучу. 

```{r}
gss_cat %>%
  count(rincome)

rincome_plot <- ggplot(gss_cat, aes(rincome)) +
  geom_bar()
```

Первым шагом можно повернуть оси

```{r}
rincome_plot +
  coord_flip()
```

Или, как один из вариантов решения --- перевернуть подписи на 90 градусов

```{r}
rincome_plot + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Или на другой угол, при котором будут хорошо читаться подписи.

```{r}
rincome_plot + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Но мне всё же больше нравится вариант с поворотом оси.

Далее видно, что из информативного представления о количестве зарплаты, выбиваются те кто либо не знают, не могут ответить, или не захотелили отвечать. Эта информация может быть статистически полезна, но прям хочется убрать тех кто указал "неприемлемую" зарплату. Кроме этого можно сократить записи тысячей на `k`, чтобы не сбивать с толку

```{r}
gss_cat %>%
  filter(!rincome %in% c("Not applicable")) %>%
  ggplot(aes(rincome)) +
  geom_bar() +
  coord_flip() +
  scale_y_continuous("Number of Respondents", labels = function(x) paste0(x/1000, "k")) +
  scale_x_discrete("Respondent's Income")
```

Ещё хотелось бы сортировать в обратном порядке и заменить `Lt $1000` на `Less then $1000`, но об этом мы узнаем в следующей главе

#### Упражнение 15.3.1.2
<div class="question">
What is the most common `relig` in this survey? What’s the most common `partyid`?
</div>

```{r}
gss_cat %>%
  ggplot(aes(relig)) +
  geom_bar() +
  coord_flip()
```

Очевидно, что протестанты встречаются чаще других. ПОсмотрим сколько это в числовом выражении:

```{r}
gss_cat %>%
  count(relig) %>%
  arrange(desc(n)) %>%
  head(1)
```

Проделаем точно такую же операцию, но для переменной `partyid`

```{r}
gss_cat %>%
  ggplot(aes(partyid)) +
  geom_bar() +
  coord_flip()
```

А так же `Independent` встречается чаще других. И в числовом выражении

```{r}
gss_cat %>%
  count(partyid) %>%
  arrange(desc(n)) %>%
  head(1)
```


#### Упражнение 15.3.1.3
<div class="question">
Which `relig` does `denom` (denomination) apply to? How can you find out with a table? How can you find out with a visualisation?
</div>

Можно графически посмотреть вот так
```{r}
ggplot(gss_cat, aes(relig)) +
  geom_bar(aes(fill = denom), position = "fill") +
  scale_x_discrete(drop = FALSE) +
  coord_flip()
```

Графически заметно, что в основном понятие конфессии применимо к протестантам и христианам. Реже встречаются в группе "Другие". Можно добавить фильтрацию и убрать параметр `drop`, тогда графически всё станет явно.

```{r}
gss_cat %>%
  filter(!denom %in% c("Not applicable")) %>%
ggplot(aes(relig)) +
  geom_bar(aes(fill = denom), position = "fill") +
  coord_flip()
```

В числовом виде это можно представить как --- убери всё что `Not applicable` в переменной `denom` и покажи всё содержимое `relig`

```{r}
gss_cat %>%
  filter(!denom %in% c("Not applicable")) %>%
  count(relig) %>%
  arrange(desc(n))
```

#### Изменение порядка следования факторов

Часто оказывается полезным изменить порядок следования факторов в визуализации. Допустим мы хотим изучить среднее количество часов, посвящённы просмотру телевизора представителями разных религий.

```{r}
relig_summary <- gss_cat %>%
  group_by(relig) %>%
  summarise(
    age = mean(age, na.rm = TRUE),
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )

ggplot(relig_summary, aes(tvhours, relig)) + geom_point()
```

Конечно тут сложно рассмотреть закономерности, потому что точки разбросаны хаотично. Для того чтобы поменять порядок, используется знакомая мне уже функция `fct_reorder()`, она принимает три аргумента:

* `f` --- фактор, уровни которого надо поменять

* `x` --- числовой вектор, которой нужно использовать для изменения порядка следования уровней.

* `fun` --- необязательный аргумент, функция, которая используется если для кажджого значения фактора `f`, существует несколько значений числового вектора `x`. По умолчанию используется `median`

Итак изменим порядок следования в зависимости от количества часов

```{r}
ggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) +
  geom_point()
```

Так-то лучше, теперь отчётливо видно что `Не знаю`-щие чаще смотрять, чем к примеру буддисты.

Но лучше вместо `aes()` выводить перераспределение в отдельный шаг при помощим `mutate()`. Это облегчит чтение кода.

```{r}
relig_summary %>%
  mutate(relig = fct_reorder(relig, tvhours)) %>%
  ggplot(aes(tvhours, relig)) +
    geom_point()
```

А теперь посмотрим, как меняется средний возраст от заявленного уровня дохода

```{r}
rincome_summary <- gss_cat %>%
  group_by(rincome) %>%
  summarise(
    age = mean(age, na.rm = TRUE),
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )

ggplot(rincome_summary, aes(age, fct_reorder(rincome, age))) + geom_point()
```

Стало только хуже, потому что изначально перменная с доходом уже была упорядочена.

Оставьте функцию `fct_reorder()` для факторов, уровни котороых упорядочиваются произвольно.

В то же время имеет смысл переместить уровень `"Не применимо"` в начало вместе с дргими специальными уровнями.
Для этого можно использовать функцию `fct_relevel()`. В качестве аргументов она принимает фактор, и любое количество факторов которые нужно перместить в начало линии

```{r}
ggplot(rincome_summary, aes(age, fct_relevel(rincome, "Not applicable"))) +
  geom_point()
```

Столь высокое значение для уровня `"Не применимо"` вероятно связано с пенсионным возрастом.

Другой тип переупорядочивания уровней полезен в тех случаях, когда вы выделяете цветом линии на графике. Функция `fct_reorder2()`
 переупорядочивает факторы по значениям `y`, связанным с наибольшими значениями `x`. Это облегчает чтения графика, посколько цвета линий выравниваются с легендой
 
```{r}
by_age <- gss_cat %>%
  filter(!is.na(age)) %>%
  count(age, marital) %>%
  group_by(age) %>%
  mutate(prop = n / sum(n))

ggplot(by_age, aes(age, prop, colour = marital)) +
  geom_line(na.rm = TRUE)

ggplot(by_age, aes(age, prop, colour = fct_reorder2(marital, age, prop))) +
  geom_line() +
  labs(colour = "marital")
```
 
Наконец, в случае столбчатых диаграмм можно использовать `fct_infeq()` для упорядочивания уровней по возрастанию: это простейший тип переупорядочивания, посколько он не требует никаких дополнительных перменных.

```{r}
gss_cat %>%
  mutate(marital = marital %>% 
           fct_infreq()) %>%
  ggplot(aes(marital)) +
    geom_bar()
```

Можно отзеркалить упорядочивания при помощи функции `fct_rev()`

```{r}
gss_cat %>%
  mutate(marital = marital %>% 
           fct_infreq() %>%
           fct_rev()) %>%
  ggplot(aes(marital)) +
    geom_bar()
```

#### Упражнение 15.4.1.1
<div class="question">
There are some suspiciously high numbers in `tvhours`. Is the mean a good summary?
</div>

Пожалуй, просмотр телевизора 24 часа в сутки это перебор.

```{r}
gss_cat %>%
  count(tvhours) %>%
  arrange(desc(tvhours))
```

```{r}
gss_cat %>%
  ggplot(aes(tvhours)) +
  geom_histogram(binwidth = 1, na.rm = TRUE)
```

В остальном данные не выглядят такими уж необычными.

```{r}
summary(gss_cat[["tvhours"]])
```

Среднее конечно чувствительнее к отскакивающим значениям, чем медиана, но всё зависит от того, что мы хотим изучить. 

#### Упражнение 15.4.1.2
<div class="question">
For each factor in `gss_cat` identify whether the order of the levels is arbitrary or principled.
</div>

Рассмотрим категориальные перменные `marital`, `race`, `rincome`, `partyid`, `relig`, `denom`. 
И пожалуй `tvhours` тоже можно отнести к категориальной перменной потому что она обозначает время.

1. Пойдём по порядку и начнём с `marital`:

```{r}
gss_cat %>%
  ggplot(aes(x = marital)) +
  geom_bar()
```

Можно перерупорядочить значения по такой логике:

* сначала переменные, характеризующие пребывание когда-либо в отношениях
  
  * еще в отношениях
  
    - женаты
  
    - живут раздельно
  
  * уже не в отношениях
  
    - разведены
  
    - овдовели
* никогда не были женаты

* нет ответа

Другими словами, я бы отсортировал всё вот таким образом:

```{r}
ggplot(gss_cat, aes(fct_relevel(marital,"Married", "Separated", "Divorced", "Widowed", "Never married"))) +
  geom_bar() +
  labs(x = "marital")
```

2. Посмотрим на переменную `race`

```{r}
gss_cat %>%
  ggplot(aes(x = race)) +
  geom_bar()
```

В принципе всё хорошо, и можно не передвигать ничего, но можно специальную группу можно поменять местами.

```{r}
gss_cat %>%
  mutate(race = race %>% fct_infreq()) %>%
  ggplot(aes(x = race)) + 
  geom_bar()
```

3. Посмотрим на переменную `rincome`

```{r}
gss_cat %>%
  ggplot(aes(x = rincome)) +
  geom_bar() +
  coord_flip()
```

Эта перменная уже отсортирована, её не нужно сортировать дополнительно, разве что можно специальную группу передвинуть в конец

```{r}
ggplot(gss_cat, aes(fct_relevel(rincome, "Not applicable"))) +
  geom_bar() + 
  coord_flip()
```

4. Посмотрим на переменную `partyid`

```{r}
gss_cat %>%
  ggplot(aes(x = partyid)) +
  geom_bar() +
  coord_flip()
```

Ничего страшного не случится, если мы отсортируем эту переменную.

```{r}
gss_cat %>%
  mutate(partyid = partyid %>% fct_infreq() %>% fct_rev()) %>%
  ggplot(aes(x = partyid)) +
  geom_bar() +
  coord_flip()
```

5. Посмотрим на переменную `denom`

```{r}
gss_cat %>%
  ggplot(aes(x = denom)) +
  geom_bar() +
  coord_flip()
```

Можно отсотрировать.

```{r}
gss_cat %>%
  mutate(denom = denom %>% fct_infreq() %>% fct_rev()) %>%
  ggplot(aes(x = denom)) +
  geom_bar() +
  coord_flip()
```

5. Посмотрим на переменную `tvhours`

```{r}
gss_cat %>%
  ggplot(aes(x = tvhours)) +
  geom_bar()
```

В зависимости от задачи, эту переменную можно отсортировать, допустим чтобы посмотреть какое количество часов уделяют больше всего экранному времени. 
Или можно оставить неизменно, если нам нужно будет посмотреть как меняется активность час от часа.

#### Упражнение 15.4.1.3
<div class="question">
Why did moving “Not applicable” to the front of the levels move it to the bottom of the plot?
</div>

Потому что это дает уровню «Не применимо» целочисленное значение 1.

### Изменение уровней факторов

Более мощным приёмом является изменение значений уровней, а не изменение следования. 
Это позволяет сделать более понятными подписи для публикаций и свертывать уровни создавая уровни более высокго порядка для отображения. 
Для этого можно использовать инструмент `fct_recode()`. 
Она позволяет перекодировать, т.е. изменять значения каддого уровня. Возьмём например `gss_cat$partyid`

```{r}
gss_cat %>% count(partyid)
```

СОдержащаяся в названиях уровней информация сжата и непоследовательна. Давайте немного расширим их и используем параллельную конструкцию 

```{r}
gss_cat %>%
  mutate(partyid = fct_recode(partyid,
    "Republican, strong"    = "Strong republican",
    "Republican, weak"      = "Not str republican",
    "Independent, near rep" = "Ind,near rep",
    "Independent, near dem" = "Ind,near dem",
    "Democrat, weak"        = "Not str democrat",
    "Democrat, strong"      = "Strong democrat"
  )) %>%
  count(partyid)
```

Как видно из кода выше, функция оставляет нетронутыми уровни, которые не были указаны в параметрах. Функция так же предупредит, если сослаться на несуществующий уровень.

МОжно создавать группы, приписывая несколько преждних уровней одному и тому же новому уровгю

```{r}
gss_cat %>%
  mutate(partyid = fct_recode(partyid,
    "Republican, strong"    = "Strong republican",
    "Republican, weak"      = "Not str republican",
    "Independent, near rep" = "Ind,near rep",
    "Independent, near dem" = "Ind,near dem",
    "Democrat, weak"        = "Not str democrat",
    "Democrat, strong"      = "Strong democrat",
    "Other"                 = "No answer",
    "Other"                 = "Don't know",
    "Other"                 = "Other party"
  )) %>%
  count(partyid)
```

Как и при любой другой группировке, нужно быть остородным, группируя вместе категории, которые являются различными, мы будем получать результаты, которые будут вводить в заблуждение.

Если планируется свернуть значительное количество уровней, функция `fct_collapse()` --- полезное решение. Для каждой новой переменной можно предоставить вектор прежних уровней.

```{r}
gss_cat %>%
  mutate(partyid = fct_collapse(partyid,
    other = c("No answer", "Don't know", "Other party"),
    rep = c("Strong republican", "Not str republican"),
    ind = c("Ind,near rep", "Independent", "Ind,near dem"),
    dem = c("Not str democrat", "Strong democrat")
  )) %>%
  count(partyid)
```

Иногда может понадобится объединить все небольшие группы, для того чтобы упростить график или таблицу. Это работа функции `fct_lump()`

```{r}
gss_cat %>%
  mutate(relig = fct_lump(relig)) %>%
  count(relig)
```

Такое свёртование избыточно, благо поведением функции можно управлять. 

```{r}
gss_cat %>%
  mutate(relig = fct_lump(relig, n = 10)) %>%
  count(relig, sort = TRUE) %>%
  print(n = Inf)
```

#### Упражнение 15.5.1.1
<div class="question">
How have the proportions of people identifying as Democrat, Republican, and Independent changed over time?
</div>

Объединим переменную, как это делалось в главе
```{r}
gss_cat %>%
  mutate(partyid = fct_collapse(partyid,
    other = c("No answer", "Don't know", "Other party"),
    republican = c("Strong republican", "Not str republican"),
    independent = c("Ind,near rep", "Independent", "Ind,near dem"),
    democrat = c("Not str democrat", "Strong democrat")
  )) %>%
    count(year, partyid) %>%
  group_by(year) %>%
  mutate(portion = n / sum(n)) %>%
  ggplot(aes(year, portion, color = fct_reorder2(partyid, year, portion))) +
  geom_point() +
  geom_line() +
  labs(y = "count",
       color = "Party")
```

#### Упражнение 15.5.1.2
<div class="question">
How could you collapse `rincome` into a small set of categories?
</div>

```{r}
gss_cat %>%
  ggplot(aes(x = rincome)) +
  geom_bar() +
  coord_flip()
```

Мелкий доход рассмотрен по тысячам, чуть больший рассмотрен по пять тысяч. 
Я бы свернул всё что меньше пяти тысяч в одну группу. От пяти до 10 в другую. 
И ввёл одну специальную группу для обозначения всех кто не рассказал про свой доход.

```{r}
gss_cat %>%
  mutate(
    rincome =
      fct_collapse(
        rincome,
        `Unknown` = c("No answer", "Don't know", "Refused", "Not applicable"),
        `Loss then $5000` = c("Lt $1000", str_c(
          "$", c("1000", "3000", "4000"),
          " to ", c("2999", "3999", "4999")
        )),
        `$5000 - 10000` = str_c(
          "$", c("5000", "6000", "7000", "8000"),
          " to ", c("5999", "6999", "7999", "9999")
        )
      )
  ) %>%
  ggplot(aes(x = rincome)) +
  geom_bar() +
  coord_flip()
```



<!--chapter:end:12_factors.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Работа с датами и временем с помощью пакета `lubridate`

### Введение

Время не так просто как может показаться. Всему своё время, и в этой главе мы наловчимся обрабатывать время.

#### Используемые ресурсы

```{r}
library(tidyverse)
library(lubridate)
library(nycflights13)
```

### Создание перменных описывающих дату и время

Существует три типа данных ссылающихся на момент времени

* дата --- календарная дата, tibble выводит это как `<date>`

* время --- время суток, tibble выводит это как `<time>`

* дата/время --- дата время, в tibble выводится как `<dttm>`

Для получения текущей даты можно использовать

```{r}
today()
now()
```

Существует три способа создания данных в формате даты/времени.
Рассмотрим их более подробно

#### Создание значений даты/времени на основе строк

МОжно распарсить дату время при помощи средств пакета `readr`, это описано в главе 8.
МОжно встроенными инструментами пакета `lubridate`, для этошо есть семейство функций, которые по факту осуществляют парсинг входных данных и выводят данные в формате даты времени

```{r}
ymd("2017-01-31")
mdy("January 31st, 2017")
dmy("31-Jan-2017")
```

Главное в верном порядке расставить буквы, означающие год-месяц-день.
Можно так же через нижнее подчеркивание задавать время

```{r}
ymd_hms("2017-01-31 20:11:59")
mdy_hm("01/31/2017 08:01")
```

#### Создание значений даты/времени на основе отдельных компонентов

Иногда вместо отдельной строки, в распоряжении будет отдельный компонент, предоставленный в нескольких столбцах.

```{r}
flights %>% 
  select(year, month, day, hour, minute)
```

Для таких случаев есть функции `make_date()` и `make_datetime()`
```{r}
flights %>% 
  select(year, month, day, hour, minute) %>% 
  mutate(departure = make_datetime(year, month, day, hour, minute))
```

Сделаем тоже самое для таблиц `flights` связанные со временем.

```{r}
make_datetime_100 <- function(year, month, day, time) {
  make_datetime(year, month, day, time %/% 100, time %% 100)
}

flights_dt <- flights %>% 
  filter(!is.na(dep_time), !is.na(arr_time)) %>% 
  mutate(
    dep_time = make_datetime_100(year, month, day, dep_time),
    arr_time = make_datetime_100(year, month, day, arr_time),
    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),
    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)
  ) %>% 
  select(origin, dest, ends_with("delay"), ends_with("time"))

flights_dt
```

Используя эти данные мы можем визуализировать распределение времени вылета на протяжении года

```{r}
flights_dt %>% 
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day
```

Или на протяжении одного дня 

```{r}
flights_dt %>% 
  filter(dep_time < ymd(20130102)) %>% 
  ggplot(aes(dep_time)) + 
  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes
```

При построении значений даты/времени в числовом контексте, как в случае гистограммы, 1 означает одну секунду, поэтому значению параметра `binwidth` равному 86400 соответствует один день. Для дат значению 1 соответствует один день

#### Создание значений даты/времени на основе других типов

Может возникнуть необходимость в переходе между  значениями даты/времени и даты. 
Это работа функций `as_datetime()` и `as_date()`

```{r}
as_datetime(today())
as_date(now())
```


#### Упражнение 16.2.4.1
<div class="question">
What happens if you parse a string that contains invalid dates?

```{r}
print(class(ymd(c("2010-10-10", "bananas"))))
```
</div>

Функция создает NA и предупреждающее сообщение.

#### Упражнение 16.2.4.2
<div class="question">
What does the `tzone` argument to today() do? Why is it important?
</div>

Часовой пояс.
Он определяет часовой пояс даты.
Поскольку разные часовые пояса могут иметь разные даты, значение `today()` может варьироваться в зависимости от указанного часового пояса.

#### Упражнение 16.2.4.3
<div class="question">
Use the appropriate lubridate function to parse each of the following dates:

```{r}
d1 <- "January 1, 2010"
d2 <- "2015-Mar-07"
d3 <- "06-Jun-2017"
d4 <- c("August 19 (2015)", "July 1 (2015)")
d5 <- "12/30/14" # Dec 30, 2014
```
</div>

```{r}
mdy(d1)
ymd(d2)
dmy(d3)
mdy(d4)
mdy(d5)
```

### Компоненты даты/времени

В этом разделе наше внимание будет сосредоточено на функциях доступа, позволяющих получать и устанавливать значения отдельных компонентов. 

#### Получение компонентов

Для извлечения отдельных компонентов предназначены функции

`year()`, 
`month()`,
`mday()` (day of the month),
`yday()` (day of the year),
`wday()` (day of the week),
`hour()`, 
`minute()`, 
`second()`

```{r}
datetime <- ymd_hms("2016-07-08 12:34:56")

year(datetime)
month(datetime)
mday(datetime)
yday(datetime)
wday(datetime)
```

Можно передать функция аргумент `label = TRUE` чтобы получить сокращенное название месяца или дня недели. ЧТобы получить полное нзвание, задайте аргумент `abbr = FALSE`

```{r}
month(datetime, label = TRUE)
wday(datetime, label = TRUE, abbr = FALSE)
```

Мы можем использовать функцию `wday()` для того чтобы убедится, что количество вылетов на протяжении недели больше чем в выходные дни

```{r}
flights_dt %>% 
  mutate(wday = wday(dep_time, label = TRUE)) %>% 
  ggplot(aes(x = wday)) +
    geom_bar()
```

В поведении среднего времени задержки вылета в зависимости от минуты часа наблюдается любопытная закономерность.
Похоже, что для авиарейсов, вылетающих в минутные интервалы часа 20-30 и 50-60, задержки намного меньше, чем для остальных временных промежутков.

```{r}
flights_dt %>% 
  mutate(minute = minute(dep_time)) %>% 
  group_by(minute) %>% 
  summarise(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n()) %>% 
  ggplot(aes(minute, avg_delay)) +
    geom_line()
```

Интересно, что если взглянуть на время вылета по расписанию, то никакой ярко выраженной закономерности не наблюдается

```{r}
sched_dep <- flights_dt %>% 
  mutate(minute = minute(sched_dep_time)) %>% 
  group_by(minute) %>% 
  summarise(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n())

ggplot(sched_dep, aes(minute, avg_delay)) +
  geom_line()
```

Так почему же нам удается наблюдать закономерность, в фактическом времени вылета? Подобно многим другим данным, подготовленным людьми, здесь наблюдаеися отчетливое смещение в сторону авиарейсов, отправляющихся в круглое время. Работая с данными, подверженными влиянию человеческих суждений, всегда надо быть настороже!

```{r}
ggplot(sched_dep, aes(minute, n)) +
  geom_line()
```

#### Округление

Альтернативный подход к построению графиков отдельных компонент --- округление даты до ближайшей единицы времени с помощью функций 
`floor_date()`, `round_date()`, `ceiling_date()`. Каждая из этих функций принимает вектор дат, подлежащих округлению и название единицы, до которой должно выполняться округление вниз `floor`, округление вверх `ceiling`, или до ближайшего значения `round`. Это например, позволяет построить график количества авиарейсов в неделю.

```{r}
flights_dt %>% 
  count(week = floor_date(dep_time, "week")) %>% 
  ggplot(aes(week, n)) +
    geom_line()
```

Особенно полезно может быть вычсиление разницы между округленной и неокруглённой датой.

#### Задание значений компонентов

Функции доступа так же позволяет устанавливать значения компонентов даты/времени. 

```{r}
(datetime <- ymd_hms("2016-07-08 12:34:56"))

year(datetime) <- 2020
datetime

month(datetime) <- 01
datetime

hour(datetime) <- hour(datetime) + 1
datetime
```

Альтернативный вариант позволяет не изменять значения на месте, а создавать новые значения с помощью функции `update()`. Кроме того можно устанавливать одновременно несколько значений.

```{r}
update(datetime, year = 2020, month = 2, mday = 2, hour = 2)
```

Если значения слишком велики, они "закольцовываются"

```{r}
ymd("2015-02-01") %>% 
  update(mday = 30)

ymd("2015-02-01") %>% 
  update(hour = 400)
```

Функцию `update()` можно использовать для того, чтобы отобразить распределение авиарейсов на протяжении дня для каждого дня в году

```{r}
flights_dt %>% 
  mutate(dep_hour = update(dep_time, yday = 1)) %>% 
  ggplot(aes(dep_hour)) +
    geom_freqpoly(binwidth = 300)
```

Задание для более крупных компонентов даты постоянного значения --- удобная методика, позволяющая исследовать закономерности, связанные с меньшими компонентами.

#### Упражнение 16.3.4.1
<div class="question">
How does the distribution of flight times within a day change over the course of the year?
</div>

Давайте попробуем построить помесячный график.

```{r}
flights_dt %>%
  filter(!is.na(dep_time)) %>%
  mutate(dep_hour = update(dep_time, yday = 1),
         month = factor(month(dep_time))) %>% 
  ggplot(aes(dep_hour, color = month)) +
  geom_freqpoly(binwidth = 60 * 60)
```

Чтобы убрать отклонения заметные отклонения между месяцами из-за разного количества дней в месяце, нужно отнормировать построение

```{r}
flights_dt %>%
  filter(!is.na(dep_time)) %>%
  mutate(dep_hour = update(dep_time, yday = 1),
         month = factor(month(dep_time))) %>% 
  ggplot(aes(dep_hour, color = month)) +
  geom_freqpoly(aes(y = ..density..), binwidth = 60 * 60)
```

#### Упражнение 16.3.4.2
<div class="question">
Compare `dep_time`, `sched_dep_time` and `dep_delay`. Are they consistent? Explain your findings.
</div>


```{r}
flights_dt %>%
  mutate(residual = (dep_time - sched_dep_time) / 60) %>% 
  filter(residual != dep_delay) %>%
  select(residual, dep_time, sched_dep_time, dep_delay)
```

Существуют расхождения. 
Похоже, в данных есть ошибки. 
Это рейсы, в которых фактическое время отправления на следующий день относительно запланированного времени отправления. 
Мы забыли учесть это при создании даты и времени с помощью функции `make_datetime_100()` в 16.2.2 из отдельных компонентов.
Код должен был бы проверить, если время отправления меньше запланированного времени отправления плюс задержка отправления (в минутах). В качестве альтернативы, простое добавление задержки отправления к запланированному времени отправления является более надежным способом построения времени отправления, поскольку оно автоматически учитывает переход на следующий день.

#### Упражнение 16.3.4.3
<div class="question">
Compare `air_time` with the duration between the departure and arrival. 
Explain your findings. 
(Hint: consider the location of the airport.)
</div>

```{r}
flights_dt %>%
  mutate(residual = as.numeric(arr_time - dep_time),
         diff = residual - air_time) %>% 
  select(origin, dest, residual, air_time, diff, arr_time, dep_time) %>% 
  group_by(diff) %>%
  count(diff) %>%
  filter(!is.na(diff)) %>%
  ggplot(aes(diff, n)) +
  geom_jitter(alpha = 0.25, width = 0, height = 0.2) +
  scale_x_log10()
```

Большая часть точек лежит в области отклонения. Вероятно, это связано с переводом времени.


#### Упражнение 16.3.4.4
<div class="question">
How does the average delay time change over the course of a day? Should you use `dep_time` or `sched_dep_time`? Why?
</div>

Будем брать запланированное время вылета. 
Потому что это заявленная характеристика вылета, и на неё можно ореентироваться. 
КРоме того использование `dep_time` всегда смещает задержки на более поздний день. 
```{r}
flights_dt %>%
  mutate(sched_dep_hour = hour(sched_dep_time)) %>%
  group_by(sched_dep_hour) %>%
  summarise(dep_delay = mean(dep_delay)) %>% 
  ggplot(aes(y = dep_delay, x = sched_dep_hour)) +
  geom_point() +
  geom_smooth()
```

Как видно на графике,  самые большие задержки плавно возрастают в течении дня, и за пару часов до полуночи, немного спадают. При этом пик образуется в районе 19 часов.

#### Упражнение 16.3.4.5
<div class="question">
On what day of the week should you leave if you want to minimise the chance of a delay?
</div>

Чтобы ответить на этот вопрос, нужно посчитать среднее время задержки в каждом дне недели


```{r}
flights_dt %>% 
  mutate(wday = wday(sched_dep_time, label = TRUE)) %>%
  group_by(wday) %>%
  summarise(mean_wday_arr_delay = mean(arr_delay, na.rm = TRUE),
            mean_wday_dep_delay = mean(dep_delay, na.rm = TRUE)) %>%
  ggplot(aes(mean_wday_dep_delay, mean_wday_arr_delay)) +
    geom_point() +
    geom_text(aes(label = wday), vjust = 1.2, hjust = 1.2, check_overlap = TRUE) +
  labs(x = "Среднее время задержки вылета, минут",
       y = "Среднее время задержки прилёта, минут")
```

Очевидно, я бы выбрал для полёта субботу

#### Упражнение 16.3.4.6
<div class="question">
What makes the distribution of `diamonds$carat` and `flights$sched_dep_time` similar?
</div>

```{r}
ggplot(diamonds, aes(x = carat %% 1 * 100)) +
  geom_histogram(binwidth = 1)
```


```{r}
ggplot(flights_dt, aes(x = minute(sched_dep_time))) +
  geom_histogram(binwidth = 1)
```

И в `diamonds$carat`, и в `flights$sched_dep_time` есть аномально большие значения, которые находятся под хорошими «человеческими» числами. 
В `flights$sched_dep_time` это минуты 00 и 30 минут и кратные 0 и 5 минутам.

В `diamonds$carat` это в 0, 1/3, 1/2, 2/3.


#### Упражнение 16.3.4.7
<div class="question">
Confirm my hypothesis that the early departures of flights in minutes 20-30 and 50-60 are caused by scheduled flights that leave early. 
Hint: create a binary variable that tells you whether or not a flight was delayed
</div>


```{r}
flights_dt %>% 
  mutate(minute = minute(dep_time)) %>% 
  group_by(minute) %>% 
  summarise(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    n = n()) %>% 
  ggplot(aes(minute, avg_delay)) +
    geom_line()
```

На минутном уровне ничего не появляется:

```{r}
flights_dt %>%
  mutate(
    early = dep_delay < 0,
    minute = minute(sched_dep_time)
  ) %>% 
  group_by(minute) %>%
  summarise(early = mean(early)) %>% 
  ggplot(aes(x = minute, y = early)) +
  geom_point()
```

Но если сгруппировать с 10-минутными интервалами, то в эти минуты будет больше доля ранних рейсов.

```{r}
flights_dt %>%
  mutate(
    early = dep_delay < 0,
    minute = minute(sched_dep_time) %% 10
  ) %>%
  group_by(minute) %>%
  summarise(early = mean(early)) %>% 
  ggplot(aes(x = minute, y = early)) +
  geom_point()
```

### Временные промежутки

* длительности --- количество секунд

* периоды --- представляют промежутки времени, используемые людьми, такие как недели или месяцы

* интервалы --- начальный и конечный моменты времени

#### Длительности

При вычитании двух дат в `R` получется объект `difftime`

```{r}
h_age <- today() - ymd(19921020)
h_age
```

Объект класса `difftime` записывает временные промежутки, выраженные в секундах, минутах, часах, днях или неделях. Эта неоднозначность может несколько затруднить работсу с объектами `difftime`, поэтому пакет `lubridate` предоставляет альтернативу --- длительности `duration`, которая всегда выржается в секундах.

```{r}
as.duration(h_age)
```

Для длительностей предусмотрен целый ряд удобных конструкторов

```{r}
dseconds(15)

dminutes(10)

dhours(c(12, 24))

ddays(0:5)

dweeks(3)

dyears(1)
```

Длительности всегда выражают временные промежутки в секундах. Длительность можно умножать и складывать.

```{r}
2 * dyears(1)

dyears(1) + dweeks(3) + dhours(15)
```

Длительности могут участвовать в операциях сложения и вычитания совместно с днями.

```{r}
tomorrow <- today() + ddays(1)
last_year <- today() - dyears(1)
```

Вместе с тем, поскольку длительности предоставляют точное количество секунд, можно получить неожиданные результаты.

```{r}
one_pm <- ymd_hms(
  "2016-03-12 13:00:00",
  tz = "America/New_York"
)

one_pm

one_pm + ddays(1)
```

Почему момент времени спустя сутки после 13:00 12 марта получился равным 14:00 13 марта. Это всё потому что произошло изменение часового пояса. ВВиду перехода на летнее время 12 марта содержит лишь 23 часа, но после добавления полных суток, выраженных в секундах, мы получаем доугой результат.

#### Периоды

Для разрешения этой проблемы пакет `lubridate` предоставляет *периоды*.
Это временные промежуткт, но оги не работают с фиксированной длительностью, выраженной в секундах. а используют такие единицы, используемые людьми, как дни и месяцы, благодаря чему работюь более интуитивным образом.

```{r}
one_pm

one_pm + days(1)
```

Подобно длительностям, периоды можно создавать с помощью целого ряда собственных функций конструкторов.

```{r}
seconds(15)

minutes(10)

hours(c(12, 24))

days(7)

months(1:6)

weeks(3)

years(1)
```

Периоды можно складывать и умножать на числа

```{r}
10 * (months(6) + days(1))

days(50) + hours(25) + minutes(2)
```

Периоды можно так же складывать с датами. В отличае от длительностей, работая с периодами вы будете полчать резльтаты в соответствии со своими ожиданиями.

```{r}
# Високосный год
ymd("2016-01-01") + dyears(1)

ymd("2016-01-01") + years(1)


# Переход на летнее время
one_pm + ddays(1)

one_pm + days(1)
```

Давайте используем периоды для устранения кажущихся странностей, связанных с датами авиарейсов. Некоторые самолёты, если верить данным, прилетают в пункт назначения еще до того, как вылетели из Нью-Йорка!

```{r}
flights_dt %>%
  filter(arr_time < dep_time)
```

Это авиарейсы, в которых при переходе через полночь самолет находится в воздухе. Мы использовали одну и ту же информацию о дате, как для времени вылета, так и для времени прилета, но эти ночные авиарейсы прибывают в аэропорт назначения на следуюзий день. Мы можем это учесть, добавив `days(1)` ко времени прибытия каждого ночного авиарейса. 

```{r}
flights_dt <- flights_dt %>%
  mutate(
    overnight = arr_time < dep_time,
    arr_time = arr_time + days(overnight * 1),
    # Бинарная переменная умножается на единицу --- FALSE * 1 = 0
    sched_arr_time = sched_arr_time + days(overnight * 1)
  )
```

Теперь все авирейсы подчиняются законам физики.

```{r}
flights_dt %>%
  filter(overnight, arr_time < dep_time)
```

#### Интервалы

Результат деления `dyears(1) / ddays(365)` результат очевиден --- 1. Поскольку длительности всегда представляются количеством секунд, а длительность года определяется как кол-во секунд в 365 днях.

А какой результат будет при делении `years(1) / days(1)`. Если имеется в виду 2015 год, то 365, а если 2016 то 366.

В данном случае пакет `lubridate` не располагает достаточной информацией для того чтобы дать однозначный ответ. Вместо этого он даст лишь оценку рещультата, сопроводив её предупреждающим сообщением.

```{r}
years(1) / days(1)
```

Для точности, нужно использовать интервал. Интервал --- это длительность, для которой указан начальный момент времени, что позволяет точно определить, сколько времени она занимает.

```{r}
next_year <- today() - years(1)
(today() %--% next_year) / ddays(1)
```

Чтобы выяснить сколько периодов приходится на интервал, необходимо использовать целочисленное деление.

```{r}
(today() %--% next_year) %/% days(1)
```

#### Резюме

Как обычно, всегда выбирайте самую простую структуру, которая позволяет решить вашу задачу. 

* Если вас интересует лишь физическое время --- длительность

* Если нужно выразить время в терминах --- период

* Если нужно выразить длительность временного промежутка --- интервал

* Вставка рисунка --- ![alt text](img/datetimes-arithmetic.png)

#### Упражнение 16.4.5.1

<div class="question">
Why is there `months()` but no `dmonths()`?
</div>

Потому что месяц это непостоянная величина.

* 31 день: январь, март, май, июль, август, октябрь

* 30 дней: апрель, июнь, сентябрь, ноябрь, декабрь

* 28 или 29 дней: февраль

Месяц --- это не продолжительность времени, определяемая независимо от того, когда он происходит, а специальный интервал между двумя датами.

#### Упражнение 16.4.5.2
<div class="question">
Explain `days(overnight * 1)` to someone who has just started learning R. How does it work?
</div>

Всё очень просто. `overnight = arr_time < dep_time` это бинарная переменная, которая принимает значения либо `TRUE` если время прибытия меньше времени отправления, либо `FALSE`, если наоборот. 
По правилу умножения бинарных операторов в `R` мы получим 0 если будем умножать на `FALSE` и 1 если будем умножать на `TRUE`.
Такой манёвр в функции `arr_time = arr_time + days(overnight * 1)` позволяет добавлять один день `days(1)` к дням, у которых время прибытия на день раньше, и не прибавлять ничего `days(0)`, в случае если прибытие было в день отправления.

#### Упражнение 16.4.5.3
<div class="question">
Create a vector of dates giving the first day of every month in 2015. Create a vector of dates giving the first day of every month in the current year.
</div>

```{r}
# Сначала я подумал, что нумерация месяцев идёт от первого месяца
ymd("2015-01-01") + months(1:12)

# Но это не так, первый месяц начинается с нуля
ymd("2015-01-01") + months(0:11)

```

Чтобы узнать первый месяц текущего года, снача возьмём текущую дату.
Округлим её до года, а затем добавим месяцы, как это делалось выше.

```{r}
floor_date(today(), unit = "year") + months(0:11)
```

#### Упражнение 16.4.5.4
<div class="question">
Write a function that given your birthday (as a date), returns how old you are in years.
</div>

```{r}
my_age <- function(birth) {
  (ymd(birth) %--% today()) %/% years(1)
}
my_age("1992-10-20")
```


#### Упражнение 16.4.5.5
<div class="question">
Why can’t `(today() %--% (today() + years(1)) / months(1)` work?
</div>

В коде нету скобки. Но даже если исправить выражение, и проставить в нужном месте скобочку, он работает не совсем так как ожидается. Потому что делим на период, а не на интервал или длительность.


```{r}
(today() %--% (today() + years(1))) / months(1)
```

Числитель выражения `(today ()% -% (today () + years (1))` представляет собой интервал, который представляет длительность времени вместе с начальной точкой. Интервал имеет точное количество секунд. 
Знаменатель выражения, `months(1)`, представляет собой период, который имеет значение для человека, но не определен в терминах точного количества секунд. 
Месяцы могут составлять 28, 29, 30 или 31 день, поэтому неясно на какие `months(1)` делится? 
Код не выдает предупреждающее сообщение, но не всегда дает правильный результат.


### Часовые пояса

Есть несколько трудностей, с котороми возможно предстоит столкнуться.

* Используемые названия часовых поясов бывают неоднозначны. Но в R для отображения часового пояса используется формат `"<континент>/<город>"`
Чтобы узнать свой текущий часовой пояс достаточно вызвать функцию `Sys.timezone()`

```{r}
Sys.timezone()
```

```{r}
# View(OlsonNames())
```

В `R` часовой пояс это атрибут даты/времени, которы лишь управляет выводом на печать. Например, следующие три объекта представляют один и тот же момент времени.

```{r}
(x1 <- ymd_hms("2015-06-01 12:00:00", tz = "America/New_York"))

(x2 <- ymd_hms("2015-06-01 18:00:00", tz = "Europe/Copenhagen"))

(x3 <- ymd_hms("2015-06-02 04:00:00", tz = "Pacific/Auckland"))
```

Можно проверить это путём вычитания

```{r}
x1 - x2
x2 - x3
```

Если не указано иное, пакет `lubridate` всегда использует UTC. Это стандартный часовой пояс, используемый научным сообществом, который примерно эквивалентен своему предшественнику GMT. В нём отсутствует переход на летнее время, что удобно для выполнения вычислений. В операциях, объединяющих дату и время наподобие `c()` часовой пояс часто опускается. В этом случае дата и время будут отображаться с текущим часовым поясом

```{r}
(x4 <- c(x1, x2, x3))
```

Часовой пояс можно изменить двумя способами.

* Можно оставить тоже время, но изменить его отображение. Используйте этот метод, если хотите отобразить время в более естественном формате. 

```{r}
(x4a <- with_tz(x4, tzone = "Australia/Lord_Howe"))
```

Этот пример иллюстрирует ещё одну проблему --- разница между часовыми поясами не всегда выражается целым числом часов.

* МОжно изменить само время. Используйте этот метод, если время было выведено с некорректно указанным часовым поясом и вы хотите исправить это

```{r}
(x4b <- force_tz(x4, tzone = "Australia/Lord_Howe"))

x4b - x4
```


<!--chapter:end:13_lubridate.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Программирование
## Введение
Запомни --- код это средство коммуникации.
Коммуницируем мы с компьютером и человеком.
Поэтому он должен быть понятен и тому и другому.

## Узнайте больше

Две книги, которые предстоит изучить

* Первая это [Hands on Programming with R](https://www.amazon.com/dp/1449359019/ref=cm_sw_su_dp) by Garrett Grolemund.

* Вторая это [Advanced R](http://adv-r.had.co.nz) by Hadley Wickham

## Работа с каналами с помощью пакета `magrittr`

### Введение

Каналы мощный инструмент. В этой главе познакомимся как с ними работать, когда следует и когда не следует использовать.

#### Необходимые ресурсы

```{r}
library(magrittr)
```

### Альтернативы каналам

Смысл использования каналов -- помочь писать код, который легко читать и понимать. Рассмотрим на шуточном примере:

<div class="question">
Little bunny Foo Foo
Went hopping through the forest
Scooping up the field mice
And bopping them on the head
</div>

```{r}
# foo_foo <- little_bunny()
```


#### Промежуточные объекты

Простейший подход --- итеративно заменять каждый шаг.

```{r}
# foo_foo_1 <- hop(foo_foo, through = forest)
# foo_foo_2 <- scoop(foo_foo_1, up = field_mice)
# foo_foo_3 <- bop(foo_foo_2, on = head)
```

Минусы --- нужно запоминать и тщательно следить за нумерацией функций, повышается вероятность ошибок.
Но вариант имеет право на жизнь.

#### Замена исходного объекта

```{r}
# foo_foo <- hop(foo_foo, through = forest)
# foo_foo <- scoop(foo_foo, up = field_mice)
# foo_foo <- bop(foo_foo, on = head)
```

Здесь повышается читабельность, однако

* ослажняется отладка --- если допустить ошибку, то придется выполнять заново весь канал

* повторение преобразуемого объекта затрудняет понимание смысла изменений в каждой строке

#### Композиция функций

```{r}
# bop(
#  scoop(
#     hop(foo_foo, through = forest),
#     up = field_mice
#   ), 
#   on = head
# )
```

Минус --- код приходится читать снизу вверх и слева направо, а аргументы и соответствующие им функции оказываются разнесёнными.
Такой код воспринимать человеку очень непросто.

#### Использование канала

```{r}
# foo_foo %>%
#   hop(through = forest) %>%
#   scoop(up = field_mice) %>%
#   bop(on = head)
```

Использование канала проще для понимания --- поскольку он фокусирует внимание на глаголах а не на существительных.

Канал работает, выполняя "лексическое преобразование": `magrittr` за кулисами переассемблирует код в канале, преобразуя его в форму, которая работает путём замены промежуточного объекта. Когда вы выполняете канал наподобие предыдущего, `magrittr` делает примерно следующее

```{r}
# y_pipe <- function(.) {
#   . <- hop(., through = forest)
#   . <- scoop(., up = field_mice)
#   bop(., on = head)
# }
# my_pipe(foo_foo)
```

Отсюда следует, что канал не работает для следующих двух классов функций

* Функции использующие текущее окружение. Например функции `load()`, `get()`, `assign()`

```{r}
assign("x", c(10, 20, 30))

y <- c(10, 20, 30)
```

* Функции использующие ленивые вычисления. `try()`, `suppressMessages()`, `suppressWarnings()` и многие другие.

### Когда канал не следует использовать

* Длина канала превышает 10 шагов. Это облегчит отладку.

* Имеется несколько входных или выходных значений. Если преобразуемых объектов не один, а два или более и все они взаимосвязаны, не используйте канал.

* Вы начинаете задумываться об использовании направленного графа со сложной структурой зависимостей. Каналу в силу своей природы линейны, и выражение сложных отношений с их помощью обычно приводит к запутанному коду

### Другие инструменты

Все пакеты `tidyverse` автоматически делают доступным оператор `%>%`, однако понадобится явно указать пакет `magrittr` если возникнет одна из следующих ситуаций

* В процессе работы с более сложными каналами иногда удобно вызывть функцию ради её побочных эффектов. Во многих случаях такие функции ничего не возвращают, фактически закрывая канал. 

В качестве обходного пути, можно использовать Т-канал. Оператор `%T>%` работает подобно `%>%`, за исключением того, что возвращает не правую, а левую часть.

```{r}
rnorm(100) %>%
  matrix(ncol = 2) %>%
  plot() %>%
  str()
```

```{r}
rnorm(100) %>%
  matrix(ncol = 2) %T>%
  plot() %>%
  str()
```

* Если вы работаете с функциями, не имеющими программного интерфейса, для работы с фреймами данных, то есть передаете им индивидуальные векторы, а не фрейм данных и вычисляемые в его контексте выражения, вам может быть полезен оператор `%$%`. Он вырывает переменные из фрейма данных, чтобы на них можно было явно ссылаться. Это может пригодиться, при работе со многими функциями, входящими в базовый комплект R

```{r}
mtcars %$%
  cor(disp, mpg)
```

* Оператор присваивания `%<>%`.

```{r}
mtcars <- mtcars %>% 
  transform(cyl = cyl * 2)

mtcars %<>% transform(cyl = cyl * 2)
```

Но операция присваивания на столько специфичная, что для большей читаемости кода рекомендуется делать всё же так `mtcars <- mtcars`



<!--chapter:end:14_magrittr.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Функции

### Введение

Написание хороших функций --- это путешествие длинною в жизнь, и да начнётся оно сейчас.

#### Используемые ресурсы

Здесь работаем с базовым функционалом, дополнительные пакеты, не потребуются

```{r}
library(lubridate)
library(magrittr)
library(stringr)
library(ggplot2)
```


### Когда следует писать функции

Когда есть необходимость повторять фрагмент кода более чем два раза.

```{r}
df <- tibble::tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df$a <- (df$a - min(df$a, na.rm = TRUE)) / 
  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))
df$b <- (df$b - min(df$b, na.rm = TRUE)) / 
  (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE))
df$c <- (df$c - min(df$c, na.rm = TRUE)) / 
  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))
df$d <- (df$d - min(df$d, na.rm = TRUE)) / 
  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))
df
```

Код выше масштабирует значения в каждом столбцу таким образом, чтобы они изменялись в пределах от 0 до 1. Но если присмотреться к выводу `df$b` можно увидеть значения больше единицы. Почему так произошло? Потому что в коде ошибка --- `(max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE)` в минимуме вместо `df$b`, стоит `df$a`. 

Не так-то просто обнаружить ошибку в коде, среди однообразных выводов. Внесение повторяющегося кода в функцию --- неплохая идея, поскольку это избавит от ошибок подобного кода.

Чтобы написать фукнцию, нужно сначала проанализировать код. Сколько в нём имеется входных переменных.

В этом коде:

```{r}
(df$a - min(df$a, na.rm = TRUE)) /
  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))
```

Есть лишь одна входная переменная `df$a`. Чтобы облегчить понимание кода вынесем повторяющийся числовой вектор во временную переменную с простым именем

```{r}
x <- df$a
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
```

Теперь можно заметить, что и тут код дублируется --- диапазон данных вычислется три раза. Хотя это можно сделать только один раз. В этом нам поможет базовая функция `range()`. 

```{r}
rng <- range(x, na.rm = TRUE)
(x - rng[1]) / (rng[2] - rng[1])
```

На сколько проще и читабельнее стал код. Но и это ещё не всё. Теперь на авансцену выходит --- создание функции

```{r}
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}
rescale01(c(0, 5, 10))
```

Итак, как видно из кода выше, создание новой функции включает три ключевых момента

1. Необходимо выбрать *имя* функции. Здесь мы используем имя `rescale01`, поскольку функция масштабирует вектор таким образом, чтобы его значения изменялись в пределах от 0 до 1.

2. Необходимо перечислить входные значения, или *аргументы* функции, после ключевого слова `function`, заключив их в круглые скобки. В данном случае имеется всего один аргумент --- это `(x)`, но если бы их было больше, вызов функции выглядел примерно так `function(x, y, z)`.

3. Разработанный код помещается в тело *функции* --- заключенный в фигурные скобки блок кода, следующий непосредственно за названием функции со списком аргументов.

Если взглянуть на ситуацию в целом, то мы сначала создали простой код, а затем превратили её в функцию. Так следует поступать и в остальных ситуациях. 

На этой стадии целесообразно проверить как работает функция с разными значениями

```{r}
rescale01(c(1, 2, 3, NA, 0.2))
```

Со временем --- очень захочется превратить эти неформальные интерактивные проверки в формальные автоматизированные тесты. Этот процесс называют блочным тестированием. 

Об этом можно узнать больше по адресу <http://r-pkgs.had.co.nz/tests.html>.

Теперь, когда у нас есть функция, мы можем заменить исходный пример.

```{r}
df$a <- rescale01(df$a)
df$b <- rescale01(df$b)
df$c <- rescale01(df$c)
df$d <- rescale01(df$d)
```

И для сравнения, рядом первоначальный код

```{r}
df$a <- (df$a - min(df$a, na.rm = TRUE)) / 
  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))
df$b <- (df$b - min(df$b, na.rm = TRUE)) / 
  (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE))
df$c <- (df$c - min(df$c, na.rm = TRUE)) / 
  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))
df$d <- (df$d - min(df$d, na.rm = TRUE)) / 
  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))
df
```

Тут есть ещё над чем работать, например очень хочется избавиться от дублирования и сделать это всё "одной строкой", но об этом мы узнаем чуть позже. 

Большим преимуществом функций, является то, что при изменении требований коду изменение нужно вносить в одном месте. Например, можно обнаружить, что некоторые значения приводят к аварийной работе функции.

```{r}
x <- c(1:10, Inf)
rescale01(x)
```

Поскольку мы внесли код в функцию, правку нужно врести в одном месте

```{r}
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}
rescale01(x)
```

Это важная составляющая принципа --- НЕ ПОВТОРЯЙСЯ ("Do not repeat yourself", DRY). Чем больше повторений, тем сложнее держать в голове все места, которые будут нуждаться в обновлении.


#### Упражнение 19.2.1.1
<div class="question">
Why is `TRUE` not a parameter to `rescale01()`? What would happen if `x` contained a single missing value, and `na.rm` was `FALSE`?
</div>


Напомню функцию `rescale01()`

```{r}
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}
```

`TRUE` не является параметром функции, поскольку он не указан в круглых скобках после слова тэга `function`

Если `x` содержит единственное пропущенное значение и `na.rm = FALSE`, то эта функция по-прежнему возвращает не пропущенное значение.

```{r}
rescale01_alt <- function(x, na.rm = FALSE) {
  rng <- range(x, na.rm = na.rm, finite = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}
rescale01_alt(c(NA, 1:5), na.rm = FALSE)

rescale01_alt(c(NA, 1:5), na.rm = TRUE)
```

Опция `finite = TRUE` у параметра `range()` удалит все неконечные элементы, а NA - неконечный элемент.

Однако, если и `finite = FALSE` и `na.rm = FALSE`, то эта функция будет возвращать вектор значений `NA`. 
Напомним, арифметические операции со значениями NA возвращают NA.

```{r}
rescale01_alt2 <- function(x, na.rm = FALSE, finite = FALSE) {
  rng <- range(x, na.rm = na.rm, finite = finite)
  (x - rng[1]) / (rng[2] - rng[1])
}
rescale01_alt2(c(NA, 1:5), na.rm = FALSE, finite = FALSE)
```

#### Упражнение 19.2.1.2
<div class="question">
In the second variant of `rescale01()`, infinite values are left unchanged. Rewrite `rescale01()` so that `-Inf` is mapped to 0, and `Inf` is mapped to 1.
</div>

Для решения хочется использовать конструкцию если `y == -Inf`, то верни 0, если `y == Inf` то верни 1.
Но так как с работой с условиями я ещё не знаком, то внесу эти в явном виде.

```{r}
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  y <- (x - rng[1]) / (rng[2] - rng[1])
  y[y == -Inf] <- 0
  y[y == Inf] <- 1
  y
}

rescale01(c(0:3, -Inf, Inf, NA))
```

#### Упражнение 19.2.1.3
<div class="question">
Practice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need? Can you rewrite it to be more expressive or less duplicative?
</div>

```{r}
x <- c(0:10)

mean(is.na(x))

x / sum(x, na.rm = TRUE)

sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
```


1. Эта функция подсчитывает делит количество пропущенных значений на общее количество значений. 
Другими словами --- функция возвращает долю пропущенных значений.

```{r}
t <- c(NA, NA, NA, NA, 1:6)
i <- c(NA, NA, NA, 1:7)

is.na(x)
mean(is.na(x))
```

Я бы назвал эту функцию missing_value_rate, или ещё лучше --- `NA_rate`

```{r}
NA_rate <- function(x) {
  mean(is.na(x))
}

NA_rate(t)
NA_rate(i)
```

2. Эта функция нормирует выборку относительно единицы или другими словами возвращает вес каждого значения в векторе, при этом пропущенные значения не берутся в расчёт.

```{r}
x <- c(2, 10000)
x
x / sum(x, na.rm = TRUE)
```

Я бы назвал эту функцию `weight_to_one` поскольку она показывает вес каждого значения относительно единицы

```{r}
weight_to_one <- function(x) {
  x / sum(x, na.rm = TRUE)
}

weight_to_one(x)
```

Будет выглядеть хорошо, ну по крайне мере однообразно с базовыми функциями, если вынести `na.rm` (по аналогии с `mean` и `median`) со значением по умолчанию `FALSE` как параметр функции. То есть указать его в круглых скобочках после слова `function()`

```{r}
weight_to_one <- function(x, na.rm = FALSE) {
  x / sum(x)
}

weight_to_one(x)
```

3. Стандартное отклонение делённое на среднеарифметическое --- это [коэффициент вариации](http://statistica.ru/glossary/general/koeffitsient-variatsii/). 
Поэтому я назову эту функцию `coefficient_of_variation`.

```{r}
gti <- c(1:1000)

coefficient_of_variation <- function(x) {
  sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
}

coefficient_of_variation(gti)
```

Будет ещё лучше, если я, как в предыдущем примере, вынесу `na.rm = FALSE` в параметр функции. Тогда можно будет управлять выводом функции, не изменяя её код.

```{r}
coefficient_of_variation <- function(x, na.rm = FALSE) {
  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)
}
```

#### Упражнение 19.2.1.4
<div class="question">
Follow <http://nicercode.github.io/intro/writing-functions.html> to write your own functions to compute the variance and skew of a numeric vector.
</div>

Первая функция, которую многие люди, похоже, должны написать, --- это вычислить стандартную ошибку среднего для некоторой переменной, потому что, как ни странно, эта функция не поставляется с базовым пакетом R. Она вычисляется следующим образом $\sqrt{\mathrm{var}(x)/n}$

```{r}
x <- c(1:169)

var(x)
```

`var` --- подсчитывает дисперсию (`variance`). Это то что нам нужно написать самим. 

Но для начала мы напишем функцию для определения стандартной ошибки:

```{r}
standart.error <- function(x) {
  sqrt(var(x)/length(x))
}
```

Но вот таким образом, на самом деле она выглядит "некрасиво" и слабочитаемо. Понятнее будет, если каждую опцию внести в отдельную внутреннюю переменную

```{r}
standart.error <- function(x) {
  v <- var(x)
  n <- length(x)
  sqrt(v/n)
}
```

Правда же так гораздо приятнее? Теперь возьмёмся за функцию дисперсии

По определению, дисперсия --- это среднеквадратическое отклонение от среднего или 
$$
D = \frac{1}{n - 1} \sum_{i=1}^n (x_i - \bar{x}) ^2 \text{,}
$$
Отлично. Теперь переведём это в функцию. $n$ в формуле это длина вектора или `length(x)`. $\bar{x}$ --- это математическое ожидание или среднее `mean(x)`. Тогда вся формула будет иметь вид

```{r}
variance <- function(x, na.rm = FALSE) {
    n <- length(x)
    m <- mean(x, na.rm = na.rm)
    sum((x - m)^2) * (1/(n - 1))
}
```

И теперь проверим нашу функцию

```{r}
x <- c(1:169)

var(x)
variance(x)
```

Отлично!

Возьмёмся за коэффициент асимметрии числового вектора. 
Неформально говоря, коэффициент асимметрии положителен, если правый хвост распределения длиннее левого, и отрицателен в противном случае.
Если распределение симметрично относительно математического ожидания, то его коэффициент асимметрии равен нулю.

![alt text](img/skew.png)

Этот коэффициент считается следующим образом

$$
\gamma_1 = \frac{\frac{1}{n - 2}\left(\sum_{i=1}^{n}(x_{i} - \bar x)^3\right)}{D^{3 / 2}}
$$

Или переводя в функцию, получим
```{r}
skewness <- function(x, na.rm = FALSE) {
  v <- var(x, na.rm = na.rm)
  n <- length(x)
  m <- mean(x, na.rm = na.rm)
  (sum(x - m)^3 / (n - 2)) / v^(3 / 2)
}
```

#### Упражнение 19.2.1.5
<div class="question">
Write `both_na()`, a function that takes two vectors of the same length and returns the number of positions that have an NA in both vectors.
</div>

Сначала разберёмся, как нам считать пропуски.
Чтобы определить пропущенное значение воспользуемся функцией `is.na()`

```{r}
t <- c(1, 2, NA)
y <- c(NA, NA, NA)
is.na(t)
```

А количество значений `TRUE` в векторе, нам поможет посчитать функция `sum()`

```{r}
sum(is.na(t))
sum(is.na(y))
```

Итак, теперь нам надо посмотреть в скольких местах в обоих векторах встречаются пропуски.
В нашем случае это один раз

Такое выражение не верно, оно даёт сумму всех пропущенных значений в обоих векторах
```{r}
sum(is.na(t)) + sum(is.na(y))

```


Такое выражение тоже не подходит, поскольку это логическое `ИЛИ` и оно сравнивает оба вектора и считает за единицу, случай если хотя бы в одном векторе был пропуск.
```{r}
sum(is.na(t) | is.na(y))
```

Тогда наше решение --- это логический оператор `И`. Функция ниже возвращает сумму случаев когда оба значения вектора есть пропущенные значения
```{r}
sum(is.na(t) & is.na(y))
```

Теперь определим это в функцию

```{r}
both_na <- function(x, y) {
  sum(is.na(x) & is.na(y))
}
both_na(t, y)
```

Вуаля

#### Упражнение 19.2.1.6
<div class="question">
What do the following functions do? Why are they useful even though they are so short?

```{r}
is_directory <- function(x) file.info(x)$isdir
is_readable <- function(x) file.access(x, 4) == 0
```
</div>

Функция `is_directory()` проверяет, является ли путь в `x` каталогом. 
Функция `is_readable()` проверяет, является ли путь в `x` доступный для чтения. 
Что означает, что файл существует и у пользователя есть разрешение на его открытие. 
Эти функции полезны даже при том, что они короткие, потому что их имена значительно упрощают работу кода.


#### Упражнение 19.2.1.6
<div class="question">
Read the complete lyrics to “Little Bunny Foo Foo”. There’s a lot of duplication in this song. Extend the initial piping example to recreate the complete song, and use functions to reduce the duplication.
</div>

Пожалуй я скипну это упражнение и вернусь к нему однажды


### Функции создаются для компьютеров и людей

Делай читабельные функции с внятным названием

Будь последовательным --- используй один стиль именования функций.

Семейство аналогичных функций называй согласованно.

Избегай перекрывания имен функций и переменных.

Комментируй свой код отвечая на вопрос `зачем?`. Избегай комментов отвечающих на вопрос `что?` и `как?`

Делай понятный код.

Подумай о добавлении промежуточных переменных.


#### Упражнение 19.3.1.1
<div class="question">
Read the source code for each of the following three functions, puzzle out what they do, and then brainstorm better names.
</div>

1. Пойдём по порядку. 

```{r}
f1 <- function(string, prefix) {
  substr(string, 1, nchar(prefix)) == prefix
}
```


В `f1` используются следующие функции:
  
  `substr()` извлекает подстроки в символьном векторе с заданными параметрами начала извлечения и конца
  
```{r}
substr(c("abc77777", "abd77777", "qwe77777"), 1, 5)
```
  
  `nchar()` считает количество символов в каждом члене символьного вектора
  
```{r}
x <- c("abc77777", "abd77777", "qwe77777")
y <- "ab"

# Всё вместе это работает так
substr(x, 1, nchar(y)) == y
```

```{r}
f1(c("resdfj", "rejsdj-", "eradsf,", "resdfj"), "re")
```
  
  Теперь как работает эта функция. `substr()` принимает первым значением параметр `string` (это на самом деле немного путает вначале, потому что `string` не название функции, а название параметра).
  
  Дальше указана единица --- т.е. из вектора будут извлекаться значения с первой позиции. 
  
  Далее следует функция `nchar(prefix)` --- которая считает количество символов во втором заданном в функцию векторе. Полученное число будет третьим параметром для функции `substr()`, т.е. он задаёт конечное значение извлекаемого вектора. 
  
  Таким образом выражение `substr(string, 1, nchar(prefix))` всегда будет брать из заданных символьных векторов количество символов с первого по длинну префикса.
  
  И наконец операция `== prefix` сравнивает извлечённые символы с заданным префиксом. И возвращает булево значение `TRUE` если вектор содержит префикс и `FALSE`
  
  Исходя из выше описанного я бы назвал функцию `f1` `имеет_префикс()` или по-английски `has_prefix()`
  
```{r}
has_prefix <- function(string, prefix) {
  substr(string, 1, nchar(prefix)) == prefix
}
```

2. Функция `f2` отбрасывает последний элемент вектора `x`

```{r}
f2 <- function(x) {
  if (length(x) <= 1) return(NULL)
  x[-length(x)]
}
```

Но тут добавлено условие --- если длинна заданного вектора равна или меньше единице, то возвращается `NULL`. И это логично, потому что отбросить последнее значение от единичного вектора всё равно что взять ноль.
```{r}
f2(1)
```

Я бы назваль эту функцию `пни последнего` или `kick_last`

```{r}
kick_last <- function(x) {
  if (length(x) <= 1) return(NULL)
  x[-length(x)]
}
```

3. В функции `f3` 

```{r}
f3 <- function(x, y) {
  rep(y, length.out = length(x))
}
```
 
  используется функция `rep()` --- она копирует  значения в `x` с заданным параметром `length.out` который указывает желаемую длинy выходного вектора, т.е. длине вектора `x`. Другие входные данные будут приведены к двойному вектору, и первый элемент будет взят. Игнорируется, если NA или недействительным.


```{r}
x <- c("ab", "c77", "c777", "abd77777", "qwe77777")
length(x)
y <- c(1:2)
f3(x, y)

rep(1:4, length.out = 9)
```

Получается, функция `f3` берёт параметр `y` и повторяет его столько раз, какая длина у `x`.

```{r}
f3(c(1:4), "cv")
```

Эту функцию можно назвать `расширение()` или `recycle()`

#### Упражнение 19.3.1.2
<div class="question">
Take a function that you’ve written recently and spend 5 minutes brainstorming a better name for it and its arguments.
</div>

Вернусь сюда когда начну писать свои функции

#### Упражнение 19.3.1.3
<div class="question">
Compare and contrast `rnorm()` and `MASS::mvrnorm()`. How could you make them more consistent?
</div>

```{r}
#?rnorm
```


`rnorm()` производит выборки из одномерного нормального распределения, а `MASS::mvrnorm` - из многомерного нормального распределения. 
Основными аргументами в `rnorm()` являются

* `n` --- кол-во наблюдений

* `mean` --- мат.ожидание

* `sd` --- стандартное отклонение.

Основными аргументами `MASS::mvrnorm` являются 

* `n`  --- необходимое кол-во образцов

* `mu` --- вектор, дающий средние значения переменных.

* `Sigma` --- положительно определенная симметричная матрица, определяющая ковариационную матрицу переменных.

Чтобы быть последовательными, они должны иметь одинаковые имена. Однако это сложно. В общем случае лучше соответствовать более широко используемым функциям, например, `rmvnorm()` должен следовать соглашениям `rnorm()`. Однако, хотя среднее значение является правильным в многомерном случае, `sd` не имеет смысла в многомерном случае. Однако обе функции внутренне согласованы. Не было бы хорошей практикой иметь в качестве аргументов аргументы `mu` и `sd`, а в качестве аргументов - Sigma.


#### Упражнение 19.3.1.4
<div class="question">
Make a case for why `norm_r()`, `norm_d()` etc would be better than `rnorm()`, `dnorm()`. Make a case for the opposite.
</div>


Если функции названы `norm_r()` и `norm_d()`, группы соглашений об именах функционируют по их распределению.

Если они названы `rnorm()` и `dnorm()`, соглашение об именовании группирует функции по действию, которое они выполняют.

* Функции r * всегда выбирают из распределений: например, `rnorm()`, `rbinom()`, `runif()` и `rexp()`.

* Функции d * вычисляют плотность вероятности или массу распределения: например, `dnorm()`, `dbinom()`, `dunif()` и `dexp()`.

В дистрибутивах `R` используется это последнее соглашение об именах.

### Условное выполнение

Инструкция `if` позволяет организовать условное выполнение кода. Она имеет следующий синтаксис

```{r}
#if (условие) {
  # код выполняемый если условие TRUE
#} else {
  # код выполняемый если условие FALSE
#}
```

Чтобы получить справку нужно заключить инструкцию в апострофы `?`if``

Рассмотрим пример простой функции, которая возвращает логический вектор, указывающий на то, именован или не именован каждый из элементов вектора

```{r}
has_name <- function(x) {
  nms <- names(x)
  if (is.null(nms)) {
    rep(FALSE, length(x))
  } else {
    !is.na(nms) & nms != ""
  }
}
```

Стандартное для функций правило --- функция возвращает последнее вычисленное значение. В случае функции выше, это может быть результат вычисления любой из двух ветвей оператора `if`

#### Условия

Результатом вычисления условия должно быть логическое значение --- либо `TRUE` либо `FALSE`.

Если это вектор --- будет предупреждение.

Если `NA` --- будет ошибка.

Несколько условий можно объединять при помощи логических векторов `||` (ИЛИ) `&&` (И). 
Они используют короткий цикл вычислений --- как только для оператора обнаруживается, что первое условие равно `TRUE`, остальные условия не обрабатываются.
Аналогично для `&&` --- Если первое условие `FALSE`, остальные не обрабатываются.

Важно --- никогда не использовать операторы `|` `&` в инструкции `if` потому что эти операции векторизованы и применяются к нескольким значениям. Если имеется логический вектор, можно свернуть его в одиночное значение с помощью функции `any()` или `all()`.

Будь внимателен при проверке на равенство. Оператор `==` векторизован, это означает что может быть получено более чем одно выходное значение. В током случае можно проверить, что длина переменной уже равна 1, свернуть вектор с помощью функции `any()` или `all()` или использовать не векторизованную функцию `identical()`.

Функция `identical()` строгая --- она всегда возвращает одиночное значение `TRUE`, либо одиночное значение `FALSE` и не выполняет прпиведение типов. Это означает, что нужно быть аккуратным при сравнении целых чисел с числами двойной точности.

```{r}
identical(0L, 0)
```

Так же будь осторожен при проверке вещественных чисел.

```{r}
x <- sqrt(2) ^ 2
x
x == 2
x - 2
```

вместо этого используй для сравнения функцию `dplyr::near()`

И ещё --- не сравнивай `x == NA`, оно не принесет никакой пользы.

#### Множественные условия

Несколько инструкций можно объединить в цепочки

```{r}
#if (this) {
  # сделай это
#} else if (that) {
  # сделай ещё что-то
#} else {
  # 
#}
```

Если цепочка получается длинной, подумай как её переписать. Одна полезная методика предпологает использование функции `switch()`. Эта функция позволяет выбирать ветвь кода на основании заданной позиции или имени.

```{r}
foo <- function(x, y, op) {
 switch(op,
  plus = x + y,
  minus = x - y,
  times = x * y,
  divide = x / y,
  stop("Unknown op!")
)
}
```

Работает она таким образом --- в аргументах функции указываем тег триггер. В теле `switch`-а указываем условия наступления триггера.

вызывается триггер вот таким образом:

```{r}
# foo(2, 5, "plus")
# foo(2, 5, "divide")
# foo(2, 5, "plва")
```

Ещё есть функция `cut()`. Разберём её работу в упражнениях

#### Стиль кода

За инструкцией `if` должны следовать курвы `{}`. Содержимое внутри скобочек должно отделяться двумя пробелами.
Так легче отслеживать иерархию в коде, скользя взглядом вдоль левого края.

Открывающаяся скобка не должна стоять на отдельной строке.

За ней всегда должен следовать переход на новую строка.

Закрывающаяюся курва всегда должна распологаться на отдельной строке, если за ней не следует блок `else`.

Код в фигурных скобках следует всегда отделять пробелами.

```{r}
# Good
if (y < 0 && debug) {
  message("Y is negative")
}

if (y == 0) {
  log(x)
} else {
  y ^ x
}
```

В случае коротких конструкций, умещающихся в одной строке, фигурные скобки можно опустить.

```{r}
y <- 10
x <- if (y < 20) "Too low" else "Too high"
```

Но так лучше не делать, лучше повысить чтение кода курвами

```{r}
if (y < 20) {
  x <- "Too low" 
} else {
  x <- "Too high"
}
```

#### Упражнение 19.4.4.1
<div class="question">
What’s the difference between `if` and `ifelse()`? 
Carefully read the help and construct three examples that illustrate the key differences.
</div>

У `ifelse()` следующие аргументы `ifelse(test, yes, no)`. 

`test` --- логическая проверка. Объект.

`yes`	--- return values for true elements of `test`.

`no`	--- return values for false elements of `test`.

```{r}
x <- c(6:-4)

sqrt(ifelse(x >= 0, x, NA))
if(x >= 0) sqrt(x)
```

Ключевое слово `if` проверяет одно условие, тогда как `ifelse()` проверяет каждый элемент.

```{r}
y <- 10
if (y < 20) {
  "Too low" 
}

if (y < 0) {
  "Too low" 
}
```

В то время как `ifelse()`

```{r}
ifelse(y < 20, "Too high", "Too low")
ifelse(y < 0, "Too high", "Too low")
```

#### Упражнение 19.4.4.2
<div class="question">
Write a greeting function that says “good morning”, “good afternoon”, or “good evening”, depending on the time of day. (Hint: use a time argument that defaults to `lubridate::now()`. That will make it easier to test your function.)
</div>

Итак функция должна работать следующим образом.
Если текущее время меньше либо равно 12:00 --- то выведи «good morning»,
Если текущее время меньше либо равно 18:00 --- то выведи «good afternoon»,
Для всего оставшегося времени выведи «good evening».


```{r}
greeting <- function(time = now()) {
  hour <- hour(time)
  if (hour <= 12) {
    print("good morning")
  } else if (hour <= 18) {
    print("good afternoon")
  } else {
    print("good evening")
  }
}

greeting(now())

hour(ymd_h("2017-01-08:05"))

greeting((ymd_h("2017-01-08:05")))
```

#### Упражнение 19.4.4.3
<div class="question">
Implement a `fizzbuzz` function. It takes a single number as input. If the number is divisible by three, it returns “fizz”. If it’s divisible by five it returns “buzz”. If it’s divisible by three and five, it returns “fizzbuzz”. Otherwise, it returns the number. Make sure you first write working code before you create the function.
</div>

Если остаток от деления на 3 равен нулю и остаток от деления на 5 равен нулю верни «fizzbuzz»,
Если остаток от деления на 3 равен нулю, то верни «fizz»,
Если остаток от деления на 5 равен нулю, то верни «buzz»,
В любом другом случае верни само число

```{r}
fizzbuzz <- function(x) {
  if (x %% 3 == 0 && x %% 5 == 0) {
    print("fizzbuzz")
  } else if (x %% 3 == 0) {
    print("fizz")
  } else if (x %% 5 == 0) {
    print("buzz")
  } else {
    print(x)
  }
}
```

```{r}
fizzbuzz(6)
fizzbuzz(5)
fizzbuzz(15)
fizzbuzz(4)
```

#### Упражнение 19.4.4.4
<div class="question">
How could you use `cut()` to simplify this set of nested if-else statements?

How would you change the call to `cut()` if I’d used `<` instead of `<=`? What is the other chief advantage of `cut()` for this problem? (Hint: what happens if you have many values in temp?)
</div>

```{r}
temp <- seq(-20, 40, by = 5)
temp
```

```{r}
if (temp <= 0) {
  "freezing"
} else if (temp <= 10) {
  "cold"
} else if (temp <= 20) {
  "cool"
} else if (temp <= 30) {
  "warm"
} else {
  "hot"
}
```

Функция `cut()` делит диапазон `x` на интервалы и кодирует значения в `x` в зависимости от того, на какой интервал они попадают. Крайний левый интервал соответствует первому уровню, следующий левый - второму уровню и так далее.

У функции есть аргумент `breaks` --- числовой вектор из двух или более уникальных точек разреза, либо одно число (больше или равное 2), дающее число интервалов, на которые должен быть вырезан x. Число интервалов 

У функции есть логический аргумент `right`, по умолчанию заданный `right = TRUE` указывающий, должны ли интервалы быть закрыты справа (и открыты слева) или наоборот.

```{r}
Z <- stats::rnorm(10000)
table(cut(Z, breaks = -6:6))
```

```{r}
aaa <- c(1,2,3,4,5,2,3,4,5,6,7)
table(cut(aaa, 11))
```

Если посмотреть на скобочки, когда параметр `right = TRUE`, то они являются включающим множеством т.е. неравенством `<=` что подходит для первого условия нашей задачи. Тогда для оптимизации функции нужно проделать следующее:

1. Указать диапазоны --- от минус бесконечности, 0, 10, 20, 30, до плюс бесконечности.

2. Указать параметр --- `right = TRUE`,

3. Указать подписи --- "freezing", "cold", "cool", "warm", "hot" в параметре `labels()`

Итого получаем:

```{r}
temp
table(cut(temp, c(-Inf, 0, 10, 20, 30, Inf),
  right = TRUE,
  labels = c("freezing", "cold", "cool", "warm", "hot")
))
```

Если неравенство станет строгим, то есть сменится `<=` на `<`, тогда нам нужно будет поменять параметр на противоположное значение `right = FALSE`

```{r}
table(cut(temp, c(-Inf, 0, 10, 20, 30, Inf),
  right = FALSE,
  labels = c("freezing", "cold", "cool", "warm", "hot")
))
```

Двумя преимуществами использования `cut()` является:

1. `cut()` работает с векторами, тогда как, `if` работает только с одним значением, 

1. для изменения условия сравнения нужно было только изменить аргумент `right`, в то время как в инструкции `if`  пришлось бы изменить четыре оператора.

#### Упражнение 19.4.4.5
<div class="question">
What happens if you use `switch()` with numeric values?
</div>

В `switch(n, ...)`, если `n` является числовым, он вернет `n`-й аргумент из `...`. Это означает, что если `n = 1`, `switch()` вернет первый аргумент в `...`, если `n = 2`, второй и тд. Например,

```{r}
switch(1, "cat", "dog", "cow")

switch(3, "cat", "dog", "cow")

# При нуле и меньше функция работает вхолостую
switch(0, "cat", "dog", "cow")

switch(-1, "cat", "dog", "cow")

# Если чесло нецело, то игнорируется нецелая часть.
# Не округляется, а именно отсекается
switch(1.5, "cat", "dog", "cow")

switch(3.2, "cat", "dog", "cow")
```

#### Упражнение 19.4.4.6
<div class="question">
What does this switch() call do? What happens if x is “e”?

```{r}
#switch(x, 
#  a = ,
#  b = "ab",
#  c = ,
#  d = "cd"
#)
```

Experiment, then carefully read the documentation.
</div>

```{r}
foo1 <- function(x) {
 switch(x, 
  a = ,
  b = "ab",
  c = ,
  d = "cd"
)
}
```

```{r}
foo1("a")
foo1("b")
foo1("c")
foo1("d")
foo1("e")
foo1("f")
```

Если есть совпадение, то этот элемент оценивается, если только он не отсутствует, и в этом случае следующий не пропущенный элемент оценивается, поэтому, например, `switch("cc", a = 1, cc =, cd =, d = 2)` оценивается как 2. Если найдено более одного совпадения, используется первый соответствующий элемент. В случае отсутствия совпадения, если есть неназванный элемент ... возвращается его значение. (Если существует более одного такого аргумента, сообщается об ошибке.)

### Аргументы функций

Аргументы, можно разделить на две категории:

* ПРедоставляют данные

* ПРедоставляют параметеры, управляющие деталями вычислений

Аргументы с данными указываются в начале.
Аргументы с параметрами указываются в конце. И правилом хорошего тона будет указать значение по умолчанию

```{r}
# Вычисление доверительного интервала вокруг среднего,
# С использованием нормального распределения
mean_ci <- function(x, conf = 0.95) {
  se <- sd(x) / sqrt(length(x))
  alpha <- 1 - conf
  mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))
}

x <- runif(105)
x
mean_ci(x)
```

Функция предоставляет рандомное отклонение со следующими параметрами `runif(n, min = 0, max = 1)`

Значение по умолчанию --- наиболее часто используемое значение.
Исключение --- безопасность. Например --- `na.rm = FALSE` использовать значение `TRUE`, даже если чаще всего пропущенные значения и игнорируются, делать это по умолчанию плохая затея. 
Тут просматривается паттернализм --- если делается выбор, по умолчанию то максимально безопасный. Чтобы изменить его, нужно сделать это осознанно.

Если перекрываешь значение по умолчанию аргумента, управляющего вычислениями, то нужно использовать полное имя

```{r}
# Good
mean(1:10, na.rm = TRUE)

# Bad
# mean(x = 1:10, , FALSE)
# mean(, TRUE, x = c(1:10, NA))
```

Используй пробелы, это упростит чтение кода

```{r}
# Good
# average <- mean(feet / 12 + inches, na.rm = TRUE)

# Bad
# average<-mean(feet/12+inches,na.rm=TRUE)
```

#### Выбор имени

Имя аргументов очень важная штука. Имена нужны для упрощения восприятия твоего кода читателем, а не программой.

Существуют часто употребимые названия аргументов, их следует запомнить

* x, y, z: vectors.

* w: a vector of weights.

* df: a data frame.

* i, j: numeric indices (typically rows and columns).

* n: length, or number of rows.

* p: number of columns.

Во всех остальных случаях операйся на уже существующие имена. Например используй имя `na.rm` для аргумента который опускает пропущенные значения.

#### Проверка значений

Часто бывает полезно сделать ограничения явными. ПРедположим, мы написали функции для вычисления взвешенных итоговых статистик

```{r}
wt_mean <- function(x, w) {
  sum(x * w) / sum(w)
}
wt_var <- function(x, w) {
  mu <- wt_mean(x, w)
  sum(w * (x - mu) ^ 2) / sum(w)
}
wt_sd <- function(x, w) {
  sqrt(wt_var(x, w))
}
```

Что произойдёт, если `x` и `w` имеют разную длинну.

```{r}
wt_mean(1:6, 1:3)
```

Хорошая практика заключается в проверке важных предусловий и генерирования ошибки, если они не выполняются

```{r}
wt_mean <- function(x, w) {
  if (length(x) != length(w)) {
    stop("`x` and `w` must be the same length", call = FALSE)
  }
  sum(x * w) / sum(x)
}
```

Робастная --- устойчивая к ошибкам. С этим нужно не перестараться.

Например, если бы мы добавили в функцию аргумент `na.rm`, то мы вероятно, не проверяли бы его слишком тщательно

```{r}
wt_mean <- function(x, w, na.rm = FALSE) {
  # Проверка на то, логический ли параметр
  if (!is.logical(na.rm)) {
    stop("`na.rm` must be logical")
  }
  # Проверка на совпадение длины
  if (length(na.rm) != 1) {
    stop("`na.rm` must be length 1")
  }
  if (length(x) != length(w)) {
    stop("`x` and `w` must be the same length", call. = FALSE)
  }
  if (na.rm) {
    miss <- is.na(x) | is.na(w)
    x <- x[!miss]
    w <- w[!miss]
  }
  sum(w * x) / sum(w)
}
```

```{r}
# wt_mean(1:3, 2:4, na.rm = 0)
# `na.rm` must be logical
```

Для получения столь небольшого выигрыша нам пришлось проделать много дополнительной работ.
ПОлезным компромиссом является использование встроенной функции `stopifnot()`, которая выполняет проверку того, что каждый аргумент равен `TRUE`, и генерирует типовое сообщение об ошибке, если это не так.

```{r}
wt_mean <- function(x, w, na.rm = FALSE) {
  stopifnot(is.logical(na.rm), length(na.rm) == 1)
  stopifnot(length(x) == length(w))
  
  if (na.rm) {
    miss <- is.na(x) | is.na(w)
    x <- x[!miss]
    w <- w[!miss]
  }
  sum(w * x) / sum(w)
}
```

```{r}
#wt_mean(1:6, 6:1, na.rm = "foo")
```

Заметим, что когда мы используем функцию `stopifnot()`, мы утверждаем что именно должно быть истинным, а не проверяете что может быть неправильным.

#### Точка-точка-точка (...)

В R многие функции принимают произвольное количество входных параметров со значениями.

```{r}
sum(1, 2, 3, 4, 5)
```

Как они это делают? При помощи сабжа --- `...` (многоточие). Этот аргумент захватывает любое количество аргументов, которым не назначено явных имен.

Такой подход очень удобен, посколько далее можно передать эти точки другой функции. Это особенно полезно, если функция в основном используется в качестве оболочки другой функции. 
Например обычно мы создаем следующие вспомогательные функции-оболочки для функции `str_c()`

```{r}
commas <- function(...) stringr::str_c(..., collapse = ", ")
commas(letters[1:10])

rule <- function(..., pad = "-") {
  title <- paste0(...)
  width <- getOption("width") - nchar(title) - 5
  cat(title, " ", stringr::str_dup(pad, width), "\n", sep = "")
}
rule("Important output")
```

В данном случае многоточия позволяют передать функции `str_c()` любые аргументы, не нуждающиеся в обработке. 

Любые неправильно записанные аргументы не будут генерировать ошибку.
Из-за этого опечатки могут легко пройти незамеыченными.

```{r}
x <- c(1, 2)
sum(x, na.mr = TRUE)
sum(x, na.rm = TRUE)
```

#### Ленивые вычисления

Аргументы обрабатываются в соответствии с концепцией ленивых *отложенных* вычислений.

Вычисление аргументов откладывается до тех пор, пока в этом не возникнет необходимости.

Отсюда следует, что те аргументы, которые не используются в функции, никогда не вычисляются.

#### Упражнение 19.5.5.1
<div class="question">
What does `commas(letters, collapse = "-")` do? Why?
</div>

Для начала напомню функцию которую мы прописали в параграфе "многоточие"

```{r}
commas <- function(...) stringr::str_c(..., collapse = ", ")
commas(letters[1:10])
```


```{r}
# commas(letters, collapse = "-")
```

Когда функция `commas()` свертывание задается способом указанном выше, она выдает ошибку.

Это связано с тем, что когда аргумент `collapse` передается `commas()`, он передается в `str_c()` как часть `...`. Другими словами, предыдущий код эквивалентен

```{r}
# str_c(letters, collapse = "-", collapse = ", ")
```

Тем не менее, ошибочно давать один и тот же именованный аргумент функции дважды.
Почитай хэлп к `?stringr::str_c` --- `collapse` аргумент для `str_c`.

Один из способов разрешить пользователю переопределять разделитель в  `commas()` --- это добавить аргумент свертывания в функцию.

```{r}
commas <- function(..., collapse = ", ") {
  stringr::str_c(..., collapse = collapse)
}
commas(letters, collapse = "-")
```

Это может запутать. Поэтому имеет смысл назвать аргумент `collapse` в `commas()` как-нибудь по-другому например `furl`, или ещё каким-нибудь словом синонимом.

```{r}
commas <- function(..., furl = ", ") {
  stringr::str_c(..., collapse = furl)
}
commas(letters, furl = "-")
```

#### Упражнение 19.5.5.2
<div class="question">
It’d be nice if you could supply multiple characters to the `pad` argument, e.g. `rule("Title", pad = "-+")`. 
Why doesn’t this currently work? 
How could you fix it?
</div>

Функция `rule` добивает до конца консоли заданные в `pad` символы. По умолчанию мы задали один символ `-`

```{r}
rule <- function(..., pad = "-") {
  title <- paste0(...)
  width <- getOption("width") - nchar(title) - 5
  cat(title, " ", stringr::str_dup(pad, width), "\n", sep = "")
}
rule("Important output")
```

Разберём всё по порядку.

Функция `getOption("width")` --- возвращает текущую длину консоли

```{r}
getOption("width")
```

Отсюда получается, что выражение `getOption("width") - nchar(title) - 5` возвращает длинну текущего окна консоли минус длинну передаваемого заголовка и минус 5

Функция `cat()` --- это конкатенация.

```{r}
cat("1", 2, "doggy")
```

Функция `stringr::str_dup()` повторяет вектор строк заданное количество раз.


```{r}
fruit <- c("apple", "pear", "banana")
stringr::str_dup(fruit, 2)
```


Итого функция `rule()` дублирует `pad` количество раз, равное желаемой ширине, минус длина `title` и пять дополнительных символов. Это подразумевает, что `pad` --- это всего лишь один символ. Если бы `pad` был двухсимвольным, результат будет почти вдвое длиннее.

```{r}
rule("Important output", pad = "+-")
rule("Important output", pad = "+-Ж")
rule("Important output", pad = "+-01")
```

Чтобы функция работала с несколькими символами в `pad`, одним из подходов можно укоротить количество выводимых символов.

```{r}
rule <- function(..., pad = "-") {
  title <- paste0(...)
  width <- getOption("width") - nchar(title) - 5
  gap <- stringr::str_dup(
    pad,
    ceiling(width / stringr::str_length(title))
  )
  cat(title, " ", gap, "\n", sep = "")
}

rule("Valuable output", pad = "-+38")
```

Это решение в пределе не совершенно, поскольку при увеличении количества символов, разделитель будет переходить на другую строку. Этого можно избежать усекая строку. Но это уже отладка функции. Вернусь к этой проблеме немного попозже.

#### Упражнение 19.5.5.3
<div class="question">
What does the `trim` argument to `mean()` do? 
When might you use it?
</div>

`trim` --- это доля (от 0 до 0,5) наблюдений, которая будет обрезана с каждого конца `x` до вычисления среднего значения. Значения дифферента за пределами этого диапазона принимаются в качестве ближайшей конечной точки.

Это может пригодится, когда известны выбросы в данных, и понятно, что их можно отбросить.
Это полезно для расчета показателя центральной тенденции, который устойчив к выбросам.

```{r}
x <- (1:10)
y <- c(100, 1, 1, 1, 1, 1, 1, 1, 1, 100)

matrix <- as_tibble(cbind(x, y))

ggplot(data = matrix, aes(x,y)) +
  geom_point()

mean(y)
mean(y, trim = 0.2)
```

#### Упражнение 19.5.5.4
<div class="question">
The default value for the method argument to `cor()` is `c("pearson", "kendall", "spearman")`. 
What does that mean? 
What value is used by default?
</div>

```{r}
# ?cor
```

В описании говорится:

`method` --- это строка символов, указывающая, какой коэффициент корреляции должен быть вычислен. Один из «pearson» (по умолчанию), «kendall» или «spearman».

Это означает, что аргумент метода может принимать одно из этих трех значений. Первое значение, «pearson», используется по умолчанию.

### Возвращаемые значения

При организации возврата следует помнить две вещи:

* Облегчит ли чтение текста функции преждевременный возврат

* Нельзя ли сделать функцию пригодной для включения в цепочки канала

#### Явные команды возврата

Обычно возврат значения является последней инструкцией функции, однако можно организовать преждевременный при помощи `return()`

```{r}
complicated_function <- function(x, y, z) {
  if (length(x) == 0 || length(y) == 0) {
    return(0)
  }
    
  # Complicated code here
}
```

Другой ситуацией является инструкция `if` с одним сложным и одним простым блоками. Например

```{r}
f <- function() {
  if (x) {
    # Do 
    # something
    # that
    # takes
    # many
    # lines
    # to
    # express
  } else {
    # return something short
  }
}
```

Но если первый блок ичень длинный то к тому времени, когда дойдём до `else` можно забыть об условии. Один из способов устранить это недоразумение --- использовать ранний возврат

```{r}
f <- function() {
  if (!x) {
    return(something_short)
  }

  # Do 
  # something
  # that
  # takes
  # many
  # lines
  # to
  # express
}
```

В этом случае на ранний возврат обращаешь внимание сразу, не просматривая весь длинный код.

#### Написание функций, пригодных для включения в канал

Функции способные работать в канале можно разбить на два типа:

* преобразования

* побочные

Преобразующие --- имеется четко определённый первичный объект, который передается в качестве первого аргумента, и его модифицированная версия возвращается функцией.
Например для `dplyr` и `tidyr` --- ключевыми объектами являются фреймы данных.

Функции с побочным эффектом вызываются в первую очередь для какого-либо действия, например для рисования графика или созхранения файла, а не для преобразования объекта. Эти функции должны возвращать первый аргумент "невидимо", поэтому по умолчанию они ничего не выводят, но могут быть использованы в канале. Напримео, следующая функцию выводит кол-во отсутствующих значений во фрейме данных.

```{r}
show_missings <- function(df) {
  n <- sum(is.na(df))
  cat("Missing values: ", n, "\n", sep = "")
  
  invisible(df)
}
```

Если мы вызываем её интерактивно, то вызыво `invisible()` означает, что входной объект `df` не выводится.

```{r}
show_missings(mtcars)
```

Но он есть, просто по умолчанию не выводится.

```{r}
x <- show_missings(mtcars) 

class(x)

dim(x)
```

И мы всё ещё можем использовать функцию в канале.

```{r}
mtcars %>% 
  show_missings() %>% 
  mutate(mpg = ifelse(mpg < 20, NA, mpg)) %>% 
  show_missings()
```

### Окружение

Окружение функции в значительной мере определяют как работают функции. Окружение управляет тем, как R находит значение, связанное с именем. Возьмем, например,

```{r}
f <- function(x) {
  x + y
}
```

Во многих языках программирования этот код будет ошибочным --- потому что отсутствует определение переменной `y`.
Но в данном случае это нормальный код, так как в R для определения значений переменных используется *лексическая область видимости*. Поскольку переменная `y` не определена в функции, R будет искать её в *окружении*, содержащим определение функции.

```{r}
y <- 100
f(10)

y <- 1000
f(10)
```

R сила --- благодаря своей гибкости можно переопределять базовые функции. И ещё много чего, о чём можно узнать из книги *Advanced R* <http://adv-r.had.co.nz>

<!--chapter:end:15_function.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Векторы

### Введение

Векторы в R --- наше всё. Надо быть готовыми к работе с ними.

#### Используемые ресурсы

Нам понадятся ряд функций из пакета `purrr`

```{r}
library(tidyverse)
library(pryr)
```

### Основные сведения о векторах

Есть два основных типа векторов: атомарные вектора и списки

1. *Атомарные векторы* :

  - логический (`logical`)
  
  - целочисленный (`integer`)
  
  - вещественный (`double`)
  
  - символьный (`character`)
  
  - комплексный (`complex`)
  
  - двоичные ("сырые") данные (`raw`)
  
2. *Списки*, их иногда называют рекурсивными векторами --- потому что они могут содержать другие списки.

Главное различие между атомарными векторами и списками заключается в том, что первые однородны, тогда как вторые могут быть неоднородными, т.е. могут содержать элементы разных типов.
Существует еще один родственный им объект `NULL` --- его часто используют для представления отсутствия вектора (в отличае от значения `NA`, используемого для представления отсутствия значения в векторе!).

Обычно `NULL` ведёт себя как вектор нулевой длины. Взаимосвязь различных векторов показана на рисунке

![alt text](img/vectors.png)

Каждый вектор зарактеризуется двумя основными свойствами.

* *Тип* Для определениея типа вектора служит функция `typeof()`

```{r}
typeof("letters")

typeof(1:10)
```

* *Длина* Для определения длины вектора служит функция `length()`

```{r}
x <- list("a", "b", 1:10)
length(x)
```

Кроме того, векторы могут содержать произвольные дополнительные метаданные в форме атрибутов, которые используются для создания *расширенных* векторово, обладающих дополнительными аспектами поведения. Существуют четыре важных типа расширенных векторов:

* *факторы* --- строятся поверх целочисленных векторов

* векторы *даты* и *даты/времени* --- строятся поверх числовых векторов

* *фрейм данные* и *tibble-фреймы* --- строятся поверх списков

### Важные типы атомарных векторов

#### Логический тип

Простейший тип, могут содержать только три возможных значения `FALSE`, `TRUE`, и `NA`

```{r}
c(TRUE, TRUE, FALSE, NA)
```

#### Числовой тип

Целочисленные и вещественные векторы совокупно называются числовыми. Число обозначается как целое следующей за ним большой буквой `L`

```{r}
typeof(1)

typeof(1L)

```

В R числа являются вещественными по умолчанию, за исключением следующих случаев

* Вещественные числа являются приближенными. Это значения, представляющие числа с плавающей точкой.
Например,

```{r}
x <- sqrt(2) ^ 2
x

x - 2
```

Поэтому вещественные числа лучше сравнивать при помощи `dplyr::near()`. Это безопасный способ сравнения, если два вектора чисел с плавающей запятой (попарно) равны. Это безопаснее, чем использовать `==`, потому что он имеет встроенный допуск

1.  Целые числа включают одно специальное значение --- `NA`, тогда как среди вещественных чисел таких щначений четыре: `NA`, `NaN`, `Inf` и`-Inf`. Все огни могу появится при делении чисел

```{r}
c(-1, 0, 1) / 0
```

  Избегай использования оператора `==` для тестирования указанных специальных значений. Вместо этого используй вспомогательные функции
`is.finite()`, `is.infinite()` и `is.nan()`

    
    |                  |  0  | Inf | NA  | NaN |
    |------------------|-----|-----|-----|-----|
    | `is.finite()`    |  x  |     |     |     |
    | `is.infinite()`  |     |  x  |     |     |
    | `is.na()`        |     |     |  x  |  x  |
    | `is.nan()`       |     |     |     |  x  |

#### Символьный тип

Самый сложный, поскольку каждый элемент --- строка, а строка может содержать произвольное количество данных.

R использует глобальный пул строк --- каждая уникальная строка сохраняется в памяти всего один раз. И всякий раз когда оа используется, фактически используется указательна представление строка.
Это позволяет снизить расход памяти при дублировании строк, в чем можно непосредственно убедиться с помощью функции `pryr::object_size()`

```{r}
x <- "This is a reasonably long string."
pryr::object_size(x)

y <- rep(x, 1000)
pryr::object_size(y)
```

Переменная `y` не занимает в 1000 раз больше памяти по сравнению с `x`, поскольку каждый элемент `y` всего лишь указатель на одну и ту же строчку. Указатель занимает 8 байт, поэтому для 1000 указателей на строку, занимающую 136 байт, требуется память объёмом 8 * 1000 + 136 = 8,13 Кбайт.

#### Отсутствующие значения

Для каждого типа атомарных векторов предусмотрено своё отсутствующее значение.

```{r}
NA            # logical

NA_integer_   # integer

NA_real_      # double

NA_character_ # character
```

#### Упражнение 20.3.5.1
<div class="question">
Describe the difference between `is.finite(x)` and `!is.infinite(x)`.
</div>

```{r}
x <- c(0, 1, NA, NaN, Inf, -Inf)
is.finite(x)

!is.infinite(x)
```

Функция `is.finite()` считает, что не пропущенные числовые `(0, 1)` значения являются конечными, а пропущенные `(NA)`, не число `(NaN)` и положительная-отрицательная бесконечность `(Inf, -Inf)` не являются конечными. 
Функция `is.infinite()` ведет себя немного по-другому. Она считает, что `Inf` и `-Inf` бесконечны, а все остальное, включая не пропущенные числа, `NA` и `NaN`, не бесконечно.

#### Упражнение 20.3.5.2
<div class="question">
Read the source code for `dplyr::near()` (Hint: to see the source code, drop the ()). How does it work?
</div>

```{r}
dplyr::near
```

Вместо проверки на точное равенство, функция `dplyr::near()` проверяет, что два числа находятся в пределах определенного допуска, `tol`. По умолчанию для допуска установлен квадратный корень из `.Machine$double.eps`, который является наименьшим числом с плавающей запятой, которое может представить компьютер.

```{r}
.Machine$double.eps
```

#### Упражнение 20.3.5.3
<div class="question">
A logical vector can take 3 possible values. How many possible values can an integer vector take? How many possible values can a double take? Use google to do some research.
</div>

Для целочисленных векторов, R использует a 32-битное представление. Это означает что вектор может быть представлен $2^{32}$ различными значениями с целыми числами. Одно из этих значений отложено для `NA_integer_`. Из справки для целых чисел.

> Note that current implementations of R use 32-bit integers for integer vectors,
> so the range of representable integers is restricted to about +/-2*10^9: doubles
> can hold much larger integers exactly.

Диапазон значений целых чисел, которые R может представлять в целочисленном векторе, равен $\pm 2^{31} - 1$,

```{r}
.Machine$integer.max
```

Самое большое целое число это $2^{31} - 1$ меньше чем $2^{32}$ потому что 1 bit используется для записи ($+$, $-$) и одно значение используется для записи `NA_integer_`.

Если вы попытаетесь представить целое число больше этого значения, R вернет значения `NA`.

```{r warning}
.Machine$integer.max + 1L
```

Тем не менее, вы можете представить это значение (точно) с помощью числового вектора, затратив примерно в два раза больше памяти.

```{r}
as.numeric(.Machine$integer.max) + 1
```

Тоже самое верно для самого большого отрицательного числа

```{r}
-.Machine$integer.max - 1L
```

Для вещественных векторов R использует 64-битное представление. Это означает, что они могут держать
до $2^{64}$ значений точно. Однако некоторые из этих значений присваиваются специальным значениям.
такие как `-Inf`,` Inf`, `NA_real_` и` NaN`. Из справки для `double`:

> All R platforms are required to work with values conforming to the IEC 60559
> (also known as IEEE 754) standard. This basically works with a precision of
> 53 bits, and represents to that precision a range of absolute values from
> about 2e-308 to 2e+308. It also has special values `NaN` (many of them),
> plus and minus infinity
> and plus and minus zero (although R acts as if these are the same). There are
> also denormal(ized) (or subnormal) numbers with absolute values above or below
> the range given above but represented to less precision.

Детали представления с плавающей точкой и арифметики сложны, выходят за рамки этого вопроса и лучше обсуждаются в ссылках, представленных ниже.
Вещественное число может представлять числа в диапазоне около $\pm 2 \times 10 ^ {308} $, что
предоставляется в

```{r}
.Machine$double.xmax
```

Многие другие подробности реализации двойных векторов приведены в переменной `.Machine` (и ее документации).

```{r}
.Machine$double.base
```

количество бит, используемых для значимого (мантисса),

```{r}
.Machine$double.digits
```

количество битов, использованных в показателе степени,

```{r}
.Machine$double.exponent
```

и самые маленькие положительные и отрицательные числа не равные нулю,

```{r}
.Machine$double.eps
.Machine$double.neg.eps
```

-   Computerphile, "[Floating Point Numbers](https://www.youtube.com/watch?v=PZRI1IfStY0)"
-   <https://en.wikipedia.org/wiki/IEEE_754>
-   <https://en.wikipedia.org/wiki/Double-precision_floating-point_format>
-   "[Floating Point Numbers: Why floating-point numbers are needed](https://floating-point-gui.de/formats/fp/)"
-   Fabien Sanglard, "[Floating Point Numbers: Visually Explained](http://fabiensanglard.net/floating_point_visually_explained/)"
-   James Howard, "[How Many Floating Point Numbers are There?](https://jameshoward.us/2015/09/09/how-many-floating-point-numbers-are-there/)"
-   GeeksforGeeks, "[Floating Point Representation Basics](https://www.geeksforgeeks.org/floating-point-representation-basics/)"
-   Chris Hecker, "[Lets Go to the (Floating) Point](http://chrishecker.com/images/f/fb/Gdmfp.pdf)", *Game Developer*
-   Chua Hock-Chuan, [A Tutorial on Data Representation Integers, Floating-point Numbers, and Characters](http://www.ntu.edu.sg/home/ehchua/programming/java/datarepresentation.html)
-   John D. Cook, "[Anatomy of a floating point number](https://www.johndcook.com/blog/2009/04/06/anatomy-of-a-floating-point-number/)"
-   John D. Cook, "[Five Tips for Floating Point Programming](https://www.codeproject.com/Articles/29637/Five-Tips-for-Floating-Point-Programming)"


#### Упражнение 20.3.5.4
<div class="question">
Brainstorm at least four functions that allow you to convert a double to an integer. How do they differ? Be precise.
</div>

Для тестирования функций округления будем использовать тестовый набор:

```{r}
test <- seq(-3, 3, by = 0.5)
test
```

Стандарт [IEEE 754-2008](https://ru.wikipedia.org/wiki/IEEE_754-2008#Правила_округления) определяет пять правил округления. Первые два правила округляют к ближайшему значению, другие называются направленными округлениями.

* Округление к ближайшему (привязка к четному). Если два ближайших числа с плавающей точкой одинаково близки, то должно быть получено число с     чётной самой младшей цифрой. Это вариант по умолчанию для двоичной плавающей запятой и рекомендованный вариант по умолчанию для десятичного     числа.

* Округление к ближайшему (привязка к бесконечности). Если два ближайших числа с плавающей точкой одинаково близки, то должно быть получено       число с большим модулем.

* Округление к 0 --- направленное округление к нулю (также известное как усечение).

* Округление к $+\infty$ --- направленное округление к положительной бесконечности (также известное как округление вверх или потолок).

* Округление к $-\infty$ --- направленное округление к отрицательной бесконечности (также известное как округление вниз или пол).


| methods        | 0.5  | -0.5  | 1.5  | -1.5  |
| -------------- | ---- | ----- | ---- | ----- |
| к нулю         | 0    | 0     | 1    | -1    |
| от нуля        | 1    | -1    | 2    | -2    |
| к $+\infty$    | 1    | 0     | 2    | -1    |
| к $-\infty$    | 0    | -1    | 1    | -2    |
| чётное         | 0    | 0     | 2    | -2    |
| нечётное       | 1    | -1    | 1    | -1    |


Для округления, в R как и во многих других языках программирования используется стандарт IEEE. Это «округление до ближайшего, с привязкой к четному».

```{r}
round2 <- function(x, to_even = TRUE) {
  q <- x %/% 1    # Деление нацело
  r <- x %% 1     # Остаток отделения
  q + (r >= 0.5)  # Если r больше 0.5, то `TRUE` и соответственно прибавление единицы
}
test
round2(test)
round2(test, to_even = FALSE)
```

#### Упражнение 20.3.5.5
<div class="question">
What functions from the readr package allow you to turn a string into logical, integer, and double vector?
</div>

1. Функция `parse_logical()` анализирует логические значения, которые могут отображаться как варианты `ИСТИНА/ЛОЖЬ` или `1/0`.

```{r}
parse_logical(c("TRUE", "FALSE", "1", "0", "true", "t", "NA", "false", "f"))
```

2. Функция `parse_integer()` анализирует целочисленные значения

```{r}
parse_integer(c("1234", "000845", "NA", "345"))
```

Однако если в строке есть нечисловые символы, функция вызовет ошибку

```{r}
parse_integer(c("1000", "$1,000", "10.00"))
```

В таких случаях выручит функция `parse_number`

```{r}
parse_number(c("1.0", "3.5", "$1,000.00", "NA"))
```

3. И для анализа вещественных значений в векторе используется функция `parse_double()`

```{r}
parse_double(c("1.23", "23.646"))
```


### Использование атомарных векторов

#### Приведение типов

Существует два типа преобразования или __приведения__ одного вектора в другой

* Явное приведение --- при помощи функций `as.logical()`, `as.integer()`, `as.double()`, или `as.character()`

* Неявное преобразование происходит когда вектор используется в контексте, ожидающем вектор определённого типа. Например когда используется логический вектор с функцией суммирования.

`TRUE` конвертируется в `1` и соответственно `FALSE` в `0`. Это означает что суммирование логического вектора даёт количество истинных значений, а среднее логического вектора даёт долю таких значений.

```{r}
x <- sample(20, 100, replace = TRUE)
x
y <- x > 10
sum(y) 

mean(y)
```

Бывает и обратное использование --- от целочисленного типа к логическому.

```{r}
if (length(x)) {
  # do something
}
```

В данном случае 0 преобращуется в `FALSE`, а все остальные значения преобразуются в `TRUE`.
Такой подход усложняет чтение кода, лучше так не делать. 
Вместо этого лучше в явном виде выразить намерения `length(x) > 0`

Важно понимать что происходит, когда вектор создаётся при помощи функции `с()`.
Верх одерживает наиболее сложный тип.

```{r}
typeof(c(TRUE, 1L))

typeof(c(1L, 1.5))

typeof(c(1.5, "a"))
```

Атомарный вектор не может содержать смесь типов --- тип это семейство вектора в целом, а не его отдельных элементов.

#### Функции проверки типов

Для проверки типов вектора лучше использовать семейство векторов, которое приведено в таблице ниже

|                  | lgl | int | dbl | chr | list |
|------------------|-----|-----|-----|-----|------|
| `is_logical()`   |  x  |     |     |     |      |
| `is_integer()`   |     |  x  |     |     |      |
| `is_double()`    |     |     |  x  |     |      |
| `is_numeric()`   |     |  x  |  x  |     |      |
| `is_character()` |     |     |     |  x  |      |
| `is_atomic()`    |  x  |  x  |  x  |  x  |      |
| `is_list()`      |     |     |     |     |  x   |
| `is_vector()`    |  x  |  x  |  x  |  x  |  x   |

#### Скаляры и правила зацикливания

Более короткий вектор повторяется, или зацикливается, для достижения той же длины, что и более длинный.

В R основные математические операции работают с векторами.
Это означает, что при формировании простых математических вычислений никогда не придётся итерировать по элементам.

```{r}
sample(10) + 100
runif(10) > 0.5
```

В случае сложения векторов разной длинны, R расширяет, или как говорят __зацикливает__ --- многократно повторяет короткий вектор для достижения длинны более длинного.

```{r}
1:10 + 1:2
```

Этот процесс будет происходить без вывода дополнительных сообщений, за исключением случаев, когда короткий вектор не кратен длинному.

```{r}
1:10 + 1:3
```

НА самом деле это может привести к ошибке, поэтому в `tidyverse` для того чтобы зациклить, нужно указать это в явном виде

```{r, error = TRUE}
# tibble(x = 1:4, y = 1:2)

tibble(x = 1:4, y = rep(1:2, 2))

tibble(x = 1:4, y = rep(1:2, each = 2))
```

#### Именование векторов

Векторам можно присваивать имена.

Можно в процессе создания вектора

```{r}
c(x = 1, y = 2, z = 4)
```

Можно постфактум при помощи `purrr::set_names()`:

```{r}
set_names(1:3, c("a", "b", "c"))
```

Именованные векторы удобнее всего использовать для извлечения элементов векторов

#### Извлечение элементов

До сих пор, для фильтрации строк мы использовали функцию `dplyr::filter()`.
Она работает только с tibble-фреймами, поэтому для векторов необходимо использовать новый инструмент.
Этим инструментом является `[]`, которая вызывается примерно так `x[a]`.
Для управления извлечением жлементов можно использовать одну из четырех структур

* Числовой вектор, содержащий только целые числа. Целые числа должны быть либо все положительны, либо все отрицательны, либо нулём.
Извлекаются элементы вектора, соответствующие указанным позициям

```{r}
x <- c("one", "two", "three", "four", "five")
x[c(3, 2, 5)]
```


В действительности, повторяя некоторые позиции, можно получить выходной вектор большей длины, чем входной.

```{r}
x[c(1, 1, 5, 5, 5, 2)]
```

Отрицательные значения отбрасывают соответствующие элементы

```{r}
x[c(-1, -3, -5)]
```

Смешивать плюс с минусом не можно

```{r}
# x[c(-1, 1)]
```

Только нули могут смешиваться с отрицательльными значениями --- но нуль ничего не возвращает

```{r}
x[0]
```


* При извлечениии элементов с помощью логического вектора сохраняются все значения, соответствующие `TRUE`

```{r}
x <- c(10, 3, NA, 5, 8, 1, NA)

# Все кроме отсутствующих
x[!is.na(x)]

# Все четные или отсутствующие
x[x %% 2 == 0]

```

* Элементы именнованного вектора можно извлекать при помощи символьного вектора

```{r}
x <- c(abc = 1, def = 2, xyz = 5)
x[c("xyz", "def")]
```

Как и в случае целых чисел, символьный вектор так же позволяет дублировать отдельные элементы

```{r}
x[c("xyz", "def", "xyz")]
```


* Простейшей из структур, управля.щих извлечением элементов векторов является пустая структура `x[]`, которая возвращает целый вектор `x`. 
В случае векторов она бесполезна, но ее можно с успехом использовать для извлечения элементов матриц (и других высокоразмерных структур), поскольку например, с ее помощью можно выбрать все строки или все столбцы, оставляя соответствующий индекс пустым.

К примеру, если `x` --- двумерная матрица, то `x[1, ]` выбирает все столбцы первой строки, а  `x[, -1]` все строки за исключением первой.

ПОдробнее об этом нужно будет обязательно прочитать в [Advanced R](http://adv-r.had.co.nz) 

Существует важное видоизменение функции `[]` это `[[]]` Эта функция возвращает лишь один элемент и всегда отбрасывает имена. Она отлично подходит для тех случаев, когда мы хотим ясно указать что извлекаем одиночный элемент, как например в цикле `for`.
Различие моежду `[]` и `[[]]` играет очень важную роль в списках. Мы их разберём после упражнений


![Шпаргалка-напоминание](img/elements.PNG)

#### Упражнение 20.4.6.1

<div class="question">
What does `mean(is.na(x))` tell you about a vector `x`? 
What about `sum(!is.finite(x))`?
</div>

Функция `mean(is.na(x))` показывает долю пропущенных значений в векторе. А функция `sum(!is.finite(x))` показывает количество не бесконечных значений

```{r}
y <- c(abc = NA, def = Inf, xyz = 5)
mean(is.na(y))
sum(!is.finite(y))
```

#### Упражнение 20.4.6.2

<div class="question">
Carefully read the documentation of `is.vector()`. 
What does it actually test for? 
Why does `is.atomic()` not agree with the definition of atomic vectors above?
</div>

Функция `is.vector()` только проверяет, не имеет ли объект каких-нибудь атрибутов, кроме имен. 
Таким образом, список является вектором:

```{r}
x <- 1:10
attr(x, "woops") <- TRUE
is.vector(x)
```

Идея заключается в том, что объектно-ориентированные классы будут включать атрибуты, в том числе, но не ограничиваясь этим, «класс».

Функция `is.atomic()` явно проверяет, является ли объект одним из атомарных типов («логический», «целочисленный», «числовой», «сложный», «символьный» и «необработанный») или `NULL`.

```{r}
is.atomic(1:10)

is.atomic(list(a = 1))
```

Функция `is.atomic()` будет считать объекты атомарными, даже если они имеют дополнительные атрибуты.

```{r}
is.atomic(x)
```

#### Упражнение 20.4.6.3

<div class="question">
Compare and contrast `setNames()` with `purrr::set_names()`.
</div>


Функция `setNames()` принимает два аргумента: вектор для именования и вектор имен для применения к своим элементам.

```{r}
setNames(1:4, c("a", "b", "c", "d"))
```

Если использовать аргумент `nm` можно использовать значения вектора в качестве имени. 

```{r}
setNames(nm = c("a", "b", "c", "d"))
```

Функция `set_names()` имеет больше способов установить имена, чем `setNames()`. 
Имена могут быть указаны так же, как `setNames()`.

```{r}
purrr::set_names(1:4, c("a", "b", "c", "d"))
```

Имена могут так же быть присвоены как безымянные аргументы.

```{r}
purrr::set_names(1:4, "a", "b", "c", "d")
```


Функция `set_names()` будет называть объект самим собой, если не указан аргумент `nm` (противоположно поведению `setNames()`).


```{r}
purrr::set_names(c("a", "b", "c", "d"))
```

Самое большое различие между `set_names()` и `setNames()` состоит в том, что `set_names()` позволяет использовать функцию или формулу для преобразования существующих имен.

```{r}
purrr::set_names(c(a = 1, b = 2, c = 3), toupper)

purrr::set_names(c(a = 1, b = 2, c = 3), ~ toupper(.))
```

Функция `set_names()` также проверяет, что длина аргумента `names` имеет ту же длину, что и именуемый вектор, и выдает ошибку, если это не так.

```{r}
# purrr::set_names(1:4, c("a", "b"))
```

Функция `setNames()` позволит именам быть короче, чем именуемый вектор, и установит отсутствующие имена в `NA`.

```{r}
setNames(1:4, c("a", "b"))
```

#### Упражнение 20.4.6.4

<div class="question">
Create functions that take a vector as input and returns:

1. The last value. Should you use `[` or `[[`?

2. The elements at even numbered positions.

3. Every element except the last value.

4. Only even numbers (and no missing values).
</div>

1. Возвращаем последнее значение в векторе. Это просто --- достаточно использовать конструкцию `[]`

```{r}
last_value <- function(x) {
  x[length(x)]
}
```

2. Элементы на чётных позициях

```{r}
even_indices <- function(x) {
  if (length(x)) {
    x[seq_along(x) %% 2 == 0]
  } else {
    x
  }
}
```


3. Все элементы, кроме последнего значения

```{r}
without_last_value <- function(x) {
  x[-length(x)]
}
without_last_value(x)
```


4. Только чётные числа

```{r}
even_numbers <- function(x) {
  x[x %% 2 == 0]
}
even_numbers(x)
```

#### Упражнение 20.4.6.5

<div class="question">
Why is `x[-which(x > 0)]` not the same as `x[x <= 0]`?
</div>


```{r}
x <- c(-5:5, NA, Inf, -Inf, NaN)
x[-which(x > 0)]
x[x <= 0]
```

Как нетрудно заметить, в случае нечсилого значения выражение `x[x <= 0]` возвращает `NA`.

Любая реляционная операция, которая включает в себя `NA`, возвращает `NA`. `NA <= 0`? Мы не знаем, потому что это зависит от неизвестного значения `NA`, поэтому ответ - `NA`. Этот же аргумент применим к `NaN`. Спрашивать, `NaN <= 0` не имеет никакого смысла, потому что нельзя сравнить число с «Не числом».

Это упражнение напоминаниеи, что всегда нужно проверять ваш код. 
Несмотря на то, что эти два выражения выглядят эквивалентными, на практике они разные. 
И когда вы делаете тестовый код, учитывайте как он работает с типичными значениями, так и со специальными значениями и крайними случаями, такими как вектор со значениями `NA` или `NaN` или `Inf`, или пустой вектор. 
Руководствуемся правилом --- если имеет место неожиданное поведение, вероятнее всего, оно произойдет.

#### Упражнение 20.4.6.6

<div class="question">
What happens when you subset with a positive integer that’s bigger than the length of the vector? 
What happens when you subset with a name that doesn’t exist?
</div>

Давайте проверим

```{r}
x <- c(a = 10, b = 20)
```


```{r}
x[7]
x[4:6]
x[1:5]
x["c"]
x[c("c", "d", "e")]
x[c("a", "d", "b")]
```

### Рекурсивные векторы (списки)

Списки, следуюший по сложности тип, после атомарных векторов.

Списки могут содержать другие списки.

Списки можно создавать с помощью `list()`

```{r}
x <- list(1, 2, 3, 4)
x
```

Весьма удобным инструментом для работы со списками, является функция `str()`, которая фокусируется на структуре, а не на содержимом

```{r}
str(x)

x_named <- list(a = 1, b = 2, c = 3)
str(x_named)
```

Списики могут содержать смесь объектов.

```{r}
y <- list(a = "c,", b = 2, c = TRUE)
str(y)
```

Как говорилось выше --- списки могут содержать другие списки

```{r}
z <- list(list(1, 2), list(3, 4))
str(z)

zz <- list(1, 2, list(3, 4))
str(zz)
```

#### Визуализация списков

```{r}
x1 <- list(c(1, 2), c(3, 4))
x2 <- list(list(1, 2), list(3, 4))
x3 <- list(1, list(2, list(3)))
```

Списки, созданные выше можно визуализировать следующим образом

![Демонстрация вложенности списков](img/list.png)

Это представление интерпритируется в соответствии со следующими правилами

* Спискам соответствуют прямоугольники со скругленными углами. В прямоугольниках соответствующим атомарным векторам, углы не скруглены

* Дочерние элементы отображаются в родительских и имеют несколько более тёмный фон, подчеркивающий структурную иерархию.

* Ориентация дочерних элементов (то есть строк и столбцов) не имеет значения, поэтому мы выбираем её такой, чтобы либо сэкономить место на рисунке, либо наилучшим образом проиллюстрировать важное свойство.

#### Извлечение списков

Есть три способа извлечения элементов списка, которые мы проиллюстрируем на примере списка `a`

```{r}
a <- list(f = 1:3, e = "a string", c = pi, d = list(-1, -5))
```

1. `[]` --- извлекает подчинённый список. Результат всегда является списком.

```{r}
str(a[1:2])
str(a[4])
```

Как и в случае векторов, извлечение элементов списка может осуществляться с помощью логического, целочисленного или символьного вектора.

2. `[[]]` --- извлекает одиночный компонент списка. Эта функция удаляет один уровень иерархии списка.

```{r}
str(a[[1]])

str(a[[4]])
```

3. `$` --- сокращение для извлечения именованных элементов списка. Работает аналогично функции `[[]]`, но не требует использования кавычек

```{r}
a$f

a[["f"]]
```

В случае списков различие между функциями `[[]]` и `[]` играет важную роль.
ПОскольку `[[]]` проникает в список, тогда как `[]` возвращает новый список меньшего размера.
Предыдущий код и его вывод показаны на рисунке ниже

![alt text](img/exercise_of_list.png)

#### Список специй

Список `x` --- перечница

![alt text](img/pepper1.png)

`x[1]` --- это перечница содержащая один пакетик перца. Элемент `x[2]` выглядит точно так же, но будет содержать второй пакет. Выражение `x[1:2]` будет представлять перечницу содержащую два пакета.

![alt text](img/pepper2.png)

`x[[1]]` --- это

![alt text](img/pepper3.png)

Если нужно получить содержимое пакета, то мне нужен элемент `x[[1]][[1]]`

![alt text](img/pepper4.png)

#### Упражнение 20.5.4.1

<div class="question">
Draw the following lists as nested sets:

1. `list(a, b, list(c, d), list(e, f))`

2. `list(list(list(list(list(list(a))))))`
</div>

1. Ответ 

![alt text](img/exercise_list.png)


1. Ответ 

![alt text](img/recursion_list.png)

#### Упражнение 20.5.4.2

<div class="question">
What happens if you subset a tibble as if you’re subsetting a list?
What are the key differences between a list and a tibble?
</div>

Подмножество `tibble` работает так же, как список; фрейм данных можно рассматривать как список столбцов. Основное различие между списком и таблицей заключается в том, что все элементы (столбцы) таблицы должны иметь одинаковую длину (количество строк). 
Списки в свою очередь могут иметь векторы различной длины в качестве элементов.

### Атрибуты

Любой вектор может содержать произвольные дополнительные __метаданные__, которые хранятся в атрибутах
```{r}
x <- 1:10
attr(x, "greeting")

attr(x, "greeting") <- "Hi!"
attr(x, "farewell") <- "Bye!"
attributes(x)
```

При помощи функции `attr()` можно устанавоивать или получать значения отдельных атрибутов. 
`attributes()` помогает просматривать все сразу.

СУществует три важных атрибута, которые используются для реализации фундаментальных понятий R

* *имена* используются для именования элементов вектора

* *размерности* обеспечивают поведение вектора как матрицы или массива

* *классы* используются для реализации объектно-ориентированной системы S3

Классы управляют работой обобщённых функций.
Обобщенные функции служат ключом к пониманию объектно-ориентированного программирования в R.
Обобщенные функции обеспечивают различное поведение для различных классов входных данных.
Обобщённые функции подробно разобраны в книге Advanced R <http://adv-r.had.co.nz/OO-essentials.html#s3>

Обобщённая функция выглядит так

```{r}
as.Date
```

`UseMethod` означает что это обобщённая функция и что она будет использовать определённый метод, т.е. функцию в зависимости от класса первоначального аргумента.

Все методы являются функциями, но не все функции являются методами.
Все террористы мусульмане, но не все мусульмане террористы. 
Подмножество во множестве.

Список всех методов обобщённой функции можно получить с помощью функции `methods()`

```{r}
methods("as.Date")
```

Если `x` --- символьный вектор, то `as.Date` вызовет функцию `as.Date.character()`, а если это фактор то вызовет `as.Date.factor()`

### Расширенные векторы

Атомарные векторы и списки --- это строительные кирпичи, для факторов и дат. Вот их особенности

#### Факторы

Факторы представляют категориальные или номинативные переменные. То есть факторы могут принимать ряд фиксированных значений возможных значений.
Факторы создаются поверх целых чисел и имеют атрибут `levels`

```{r}
x <- factor(c("ab", "cd", "ab"), levels = c("ab", "cd", "ef"))
typeof(x)

attributes(x)
```

#### Дата и дата-время

В R дата --- это числовые векторы, которы представляют количество дней истекших с 1 января 1970 года.

```{r}
x <- as.Date("1971-01-01")
unclass(x)


typeof(x)

attributes(x)
```

Дата-время --- это числовые векторы с классом `POSIXct`. Календарное время соответствующее стандарту POSIX

```{r}
x <- lubridate::ymd_hm("1970-01-01 01:00")
unclass(x)

typeof(x)

attributes(x)
```

Атрибут `tzone` --- необязательный. Он управляет способом вывода времени на печать, а не абсолютным временем, на что указывает его название.

```{r}
attr(x, "tzone") <- "US/Pacific"
x

attr(x, "tzone") <- "US/Eastern"
x
```

Существует другой тип объектов даты-времени который называется POSIXlt.
Эти объекты создаются на основе именованных списков.
Но их лучше преобразовывать в POSIXсt при помощи `lubridate::as_date_time()`
.
```{r}
y <- as.POSIXlt(x)
typeof(y)

attributes(y)
```

#### Tibble-фреймы

Tibble-фреймы --- это расширенные списки. 
Они имеют три класса 

* `tbl_df`

* `tbl` 

* `data.frame`, 

А так же два атрибута 

* `names` (имена столбцов) 

* `row.names` (имена строк)

```{r}
tb <- tibble::tibble(x = 1:5, y = 5:1)
typeof(tb)

attributes(tb)
```

Традиционный тип `data.frame` имеет аналогичную структуру.

```{r}
df <- data.frame(x = 1:5, y = 5:1)
typeof(df)

attributes(df)
```

Основным отличием является класс. Класс tibble-фреймов включает `data-frame`, а это означает, что tibble-фреймы наследуют поведение обычных фреймов по умолчанию.

Различие между тиббл-фреймом или фреймом данных и списком заключается в том, что все элементы тиббл-фрейма или фрейма данных должны быть векторами одинаковой длинны.

#### Упражнение 20.7.4.1

<div class="question">
1. What does `hms::hms(3600)` return? 

2. How does it print? 

3. What primitive type is the augmented vector built on top of? 

4. What attributes does it use?
</div>

1. Функция возвращает продолжительность времени равную одному часу.

```{r}
t <- hms::hms(3600)
```

2. На печать выводится в формате `%H:%M:%S`

```{r}
t
```

3. Расширенный вектор строится поверх класса `double`

```{r}
typeof(t)
```

4. Расширенный вектор использует атрибуты `class` и `units`

```{r}
attributes(t)
```

#### Упражнение 20.7.4.2

<div class="question">
Try and make a tibble that has columns with different lengths. 
What happens?
</div>

Если задавать векторы разной длинны, то произойдёт ошибка
```{r}
# tibble::tibble(x = 1:5, y = 4:1)
# Ошибка: Tibble columns must have consistent lengths, only values of length one are recycled:
# * Length 4: Column `y`
# * Length 5: Column `x`
# Call `rlang::last_error()` to see a backtrace
```

Однако если задать один из параметров числом, или вектором единичной длинны, то столбец автозаполняется этим числом

```{r}
1:1
tibble::tibble(x = 1:5, y = 2:2)
```

#### Упражнение 20.7.4.3

<div class="question">
Based on the definition above, is it OK to have a list as a column of a tibble?
</div>

Оказывается, что может быть. А значит может быть и разной длинны

```{r}
tibble::tibble(x = 3:5, y = list("a", 0, list(6:8)))[[2]]
```


<!--chapter:end:16_vectors.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Итерирование с помощью пакета `purrr`

### Введение

Снижение дублирования кода обеспечивает три основных преимущества

* Проследить намерения автора кода гораздо проще. Потому что внимание концентрируется на содержательной части кода, а не на повторяющихся участках

* Вносить исправления в код гораздо проще. Потому что нужно внести изменение в одном месте, а не бегать по всему коду и менять в соответствующих участках.

* Это облегчает устранение ошибок. Потому что опять-таки исправлять нужно в одном месте, а не в нескольких участках программы.

В этой главе мы познакомимся с двумя важными парадигмами итерирования:

* императивное программирование
  
  В императивном программировании имеются инструменты как циклы `for` или `while`. Эти циклы нужно описывать достаточно подробно

* функциональное программирование
  
  Функциональное программирование предлагает средства изолирования повторяющегося кода. Так что каждый шаблон цикла получает собственную функцию.

Как только научимся фигачить в функциональное программирование, будет легче решать многие итерационные задачи  

#### Используемые ресурсы

Тут понадобятся `purrr`, который входит в библиотеку `tidyverse`

```{r}
library(tidyverse)
```


### Циклы `for`

Пример. Есть такой фрейм.

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)
```

Вычислим медиану для каждого столбца

```{r}
output <- vector("double", ncol(df))  # 1. вывод
for (i in seq_along(df)) {            # 2. последовательность
  output[[i]] <- median(df[[i]])      # 3. тело
}
output
```

Итак. каждый цикл `for` содержит три компонента

* *вывод* --- `output <- vector("double", ncol(df))`
  
  Прежде чем выполнить цикл, всегда необходимо выделить достаточно места для хранения выходных результатов. 
  Это очень важно для обеспечения эффективности вычислений --- если наращивать выходные результаты при помощи например вызовов `с()`, то цикл будет работать очень медленно.
  Общий способ создания пустого вектора заданной длины предлагает функция `vector()`. Она имеет два аргумента: тип вектора(логически, целочисленный, вещественный, символьный) и длина вектора

* *последовательность* --- `i in seq_along(df)`
  
  Этот компонент определяет по какой переменной выполняется итерирование.
  На каждй итерации цикла переменной `i` будет присваиваться другое значение, берущееся из последовательности `seq_along(df)`
  
  Отныне лучше всегда использовать именно `seq_along(df)` вместо `1:length(x)`. Вот почему
```{r}
y <- vector("double", 0)
seq_along(y) # это же вектор нулевой длины, всё верно
1:length(y)  # это же должен быть вектор нулевой длины, почему тут два числа???
```

* *тело цикла* --- `output[[i]] <- median(df[[i]])`
  
  Этот код делает всю работу. Он выполняется многократно,  каждый раз с последующим значением `i`. 
  На первой итерации будет выполненяться инструкция `output[[1]] <- median(df[[1]])`, на второй `output[[2]] <- median(df[[2]])` и так далее
  
#### Упражнение 21.2.1.1

<div class="question">
Write for loops to:

1. Compute the mean of every column in mtcars.

2. Determine the type of each column in `nycflights13::flights`.

3. Compute the number of unique values in each column of iris.

4. Generate 10 random normals for each of  $\mu = -10, 0, 10, 100$

Think about the output, sequence, and body before you start writing the loop.
</div>
  
  
1. Если решать циклом, можно переделать задачу из упражнения:

```{r}
output <- vector("double", ncol(mtcars))
names(output) <- names(mtcars)
for (i in seq_along(mtcars)) {
  output[[i]] <- mean(mtcars[[i]])
}
output
```

2. Тип вектора определяет функция `class()`

```{r}
output <- vector("list", ncol(nycflights13::flights))
names(output) <- names(nycflights13::flights)
for (i in seq_along(nycflights13::flights)) {
  output[[i]] <- class(nycflights13::flights[[i]])
}
output

ncol(nycflights13::flights)

class(nycflights13::flights[[1]])
```

3. Тут тоже не сложно

```{r}
iris
length(unique(iris$Sepal.Length))

length(unique(iris[[2]]))


output <- vector("double", ncol(iris))
names(output) <- names(iris)
for (i in seq_along(iris)) {
  output[[i]] <- length(unique(iris[[i]]))
}
output
```

4. 

```{r}
rnorm(10, mean = -10)

mu <- c(-10, 10, 0, 100)
output <- vector("list", length(mu))
for (i in seq_along(mu)) {
  output[[i]] <- rnorm(10, mean = i)
}
output
```

#### Упражнение 21.2.1.2

<div class="question">
Eliminate the for loop in each of the following examples by taking advantage of an existing function that works with vectors:
</div>

1. Цикл `for` в данном примере объединяет все элементы вектора `letters`. Функция `str_c()` содержит внутри себя аргумент `collapse`, который выполняет эту же функцию. 

```{r}
out <- ""
for (x in letters) {
  out <- stringr::str_c(out, x)
}
out

str_c(letters, collapse = "")
```

2. Этот цикл считает стандартное отклонение $sd = \frac{\sum{(x_i - \bar{x}})^2}{n-1}$. 
Но ведь для этого есть функция `sd()`

```{r}
x <- sample(100)
sd <- 0
for (i in seq_along(x)) {
  sd <- sd + (x[i] - mean(x)) ^ 2
}
sd <- sqrt(sd / (length(x) - 1))

sd(x)
```

3. Эта функция считает скользящую (или кумулятивную) сумму --- считает сумму для каждого последующего элемента.
Для этих целей есть внутренняя функция `cumsum()`

```{r}
x <- runif(100)
out <- vector("numeric", length(x))
out[1] <- x[1]
for (i in 2:length(x)) {
  out[i] <- out[i - 1] + x[i]
}

cumsum(x)
```

#### Упражнение 21.2.1.3

<div class="question">
Combine your function writing and for loop skills:

Write a for loop that `prints()` the lyrics to the children’s song “Alice the camel”.

Convert the nursery rhyme “ten in the bed” to a function. Generalise it to any number of people in any sleeping structure.

Convert the song “99 bottles of beer on the wall” to a function. Generalise to any number of any vessel containing any liquid on any surface.
</div>

* Задание 1 --- песенка доступна по адресу <http://www.metrolyrics.com/alice-the-camel-lyrics-children.html>

Смысл такой, что по очереди от числа 5 до нуля у верблюда исчезают горбы и когда горбов нет, верблюд превращается в лошадь.

Реализовать можно и без команды `print()`. Я подошёл лениво к реализации --- моё решение не учитывает общий случай (когда горбов больше чем 5), но где вы видели верблюда с таким количеством горбов?
Но зато решение учитывает правила орфографии для единственного числа.

```{r}
count <- c("five", "four", "three", "two", "one", "no")

for (i in seq_along(count)) {
  if (i <= 4) {
    cat(str_c("Alice the camel has ", rep(count[i], 3), " humps.",
    collapse = "\n"
  ), "\nSo go, Alice, go.\n", "\n")
  }
  if (i == 5) {
    cat(str_c("Alice the camel has ", rep(count[i], 3), " hump.",
    collapse = "\n"
  ), "\nSo go, Alice, go.\n", "\n")
  }
  if (i == 6) {
   cat(str_c("Alice the camel has ", rep(count[i], 3), " humps.",
    collapse = "\n"
  ), "\nNow Alice is a horse.", "\n") 
  }
}
```

* Задание 2 --- песенка доступна по адресу <https://www.kididdles.com/lyrics/t003.html>

От заданного числа до нуля происходит счёт

There were ten in a bed\n
And the little one said\n
"Roll over, roll over"\n
So they all rolled over\n
And one fell out\n

на последнем элементе текст меняется на

There was one in a bed\n
And the little one said\n
"Good night!"\n

Для создания функции т.е. общего случая нужно иметь вектор всех названий числительных. 
Либо заменить числительные на число. Я в этой реализации опять сделаю ленивую версию в которой просто отработаю навык создания цикла `for`

```{r}
numbers <- c(
  "ten", "nine", "eight", "seven", "six", "five",
  "four", "three", "two", "one"
)

for (i in seq_along(numbers)) {
  if(length(numbers) - i == 0 ) {
    cat("There were", numbers[i], "in a bed", "\nAnd the little one said
\"Good night!\"\n
\n")
  } else {
  cat("There were", numbers[i], "in a bed", "\nAnd the little one said
\"Roll over, roll over\"
So they all rolled over
And one fell out
\n")
  } 
}
```

* Задание 3 --- песенка доступна по адресу <https://en.wikipedia.org/wiki/99_Bottles_of_Beer>

```{r}
# Сначала я реализую функцию считалку, которая будет сокращать количество бутылок.
bottles <- function(i) {
  if (i > 2) {
    bottles <- str_c(i - 1, " bottles")
  } else if (i == 2) {
    bottles <- "1 bottle"
  } else {
    bottles <- "no more bottles"
  }
  bottles
}

# Теперь можно и песенку сделать. Введём параметры по умолчанию --- если ничего не указать, кроме числа, будет стандартная песенка, но параметры можно менять. Задавать жижку, и поверхность.

song <- function(i, liquid = "beer", surface = "wall") {
for (i in seq(i, 1, -1)) {
  cat(bottles(i)," of ", liquid, " on the ", surface, ", ", bottles(i), " o f", liquid,".\n
Take one down, pass it around, ", bottles(i), " of ", liquid, " on the ", surface, ".\n", sep = "")
}  
}

song(10, "wine", "table")
```

#### Упражнение 21.2.1.4

<div class="question">

It’s common to see for loops that don’t preallocate the output and instead increase the length of a vector at each step:
How does this affect performance? Design and execute an experiment.
</div>

При помощи пакета 
```{r}
library(microbenchmark)
```

который мы уже использовали в курсе по обучению программированию, мы проверим, на сколько изменяется производительность

```{r}
add_to_vector <- function(n) {
  output <- vector("integer", 0)
  for (i in seq_len(n)) {
    output <- c(output, i)
  }
  output
}

microbenchmark(add_to_vector(10000), times = 3)

?microbenchmark()
```


```{r}
dd_to_vector_2 <- function(n) {
  output <- vector("integer", n)
  for (i in seq_len(n)) {
    output[[i]] <- i
  }
  output
}
microbenchmark(dd_to_vector_2(10000), times = 3)
```

Предварительно выделенный вектор примерно в 10 раз быстрее! Вы можете получить разные ответы, но чем длиннее вектор и чем больше объекты, тем больше предварительное выделение превзойдет добавление.

### Варианты цикла `for`

Существуют 4 следующих вариации на тему цикла `for`

#### Изменение существующего объекта вместо создания нового

Иногда возникает необходимость в использовании цикла для изменения существующего объекта.
Например, вспомним задачу

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

df
```

Вновь обратимся к трем компонентам цикла `for`

*Вывод* --- у нас уже есть выходной объект --- этот тот же объект, что и входной.

*Последовательность* --- фрейм данных можно представлять как список столбцов, поэтому мы можем итерировать, по столбцам с помощью функции `seq_along(df)`

*Тело цикла* --- примените функцию `rescale01()`

В результате получаем следующий код

```{r}
for (i in seq_along(df)) {
  df[[i]] <- rescale01(df[[i]])
}

df
```

Как правило, именно эту разновидность цикла, я буду применять для изменения списка или фрейма данных --- поэтому надо использовать двойные квадратные скобки `[[]]`. Да и вообще, лучше в циклах чаще использовать именно двойные скобки, для того чтобы отчетливо указать --- мы рабаотем, с одиночным элементом.

#### Шаблоны формирования циклов

Существуют три способа организации цикла для вектора

* по числовым индексам `for (i in seq_along(xs))` и извлечение выражения с помощью `x[[i]]`

* циклический перебор по элементам  `for (x in xs)`. Эта форма наиболее полезна, когда нужно лишь выводить на печать, или сохранять в файл.

* циклический перебор по именам `for (nm in names(xs))`. В результате, получаем имя которое можно использовать для доступа к значению с помощью выражения `x[[nm]]`. Это полезно, когда нужно использовать имя в качестве названия графика или имени файла.
При этом создавая именованные выходные данных, присваивать имя результирующему вектору нужно так

```{r}
results <- vector("list", length(x))
names(results) <- names(x)
```

Однако итерирования по числовым индксам это наиболее общая форма. Зная позицию элемента, можно вытащить и имя и значение

#### Выходные данные неизвестной длинны

Иногда длина выходных данных неизвестна заранее. 

Предположим нужно имитировать набор случайных векторов со случайной длинной.

Есть соблазн решить задачу постепенного наращивания

```{r}
means <- c(0, 1, 2)

output <- double()
for (i in seq_along(means)) {
  n <- sample(100, 1)
  output <- c(output, rnorm(n, means[[i]]))
}
str(output)
```

Но это неэффективно, поскольку на каждой итерации приходится копировать все данные из предыдущих итераций. Это квадратичная сложность $O(n^2)$. А это охначает что цикл, обрабатывающий в три раза больше элементов, будет работать в три раза дольше.

Лучшее решении заключается в сохранении результатов в виде списка, а затем объединение в один вектор, по завершении цикла

```{r}
out <- vector("list", length(means))
for (i in seq_along(means)) {
  n <- sample(100, 1)
  out[[i]] <- rnorm(n, means[[i]])
}
str(out)

str(unlist(out))
```

В данном случае был использован `unlist()` для сведения в один вектор. 
Более строгий подход --- использовать `purrr::flatten_dbl()`, в случае если входные данные не являются списком вещественных чисел, она выдаст ошибку.

Такой шаблон так же встречается в ещё двух ситуациях

1. Вы генерируете длинную строку. Вместо объединения результатов каждой итерации с предыдущими с помощью функции `paste()` сохраните выходные данные в символьном векторе, а затем объедините в одну строку при помощи `paste(output, collapse = "")`

2. Вы генерируете большой фрейм данных. Вместо последовательного объединения строк или столбцов на каждой итерации с помощью `rbind()` сохраните данные в виде списка, а затем используйте вызов `dplyr::bind_rows(output)` для объединения в один фрейм.

Всякий раз, когда встречается этот шаблон --- переходи к более сложному объекту результата, а по завершении объедини выходные данные за один приём. Так эффективнее.

#### Последовательность на входе неизвестной длинны

Это обычная ситуация, при выполнении различных имитаций. Предположим, нужно чтобы цикл выполнялся до тех пор, пока три раза не выподет орёл. 

Для таких целей нужен цикл `while`. Он более общий --- поскольку каждый цикл фор можно переписать как цикл вайл, однако не каждый цикл вайл можно сделать при помощи цикла фор.

```{r}
flip <- function() sample(c("T", "H"), 1)

flips <- 0
nheads <- 0

while (nheads < 3) {
  if (flip() == "H") {
    nheads <- nheads + 1
  } else {
    nheads <- 0
  }
  flips <- flips + 1
}
flips

```

#### Упражнение 21.3.5.1

<div class="question">
Imagine you have a directory full of CSV files that you want to read in. You have their paths in a vector, `files <- dir("data/", pattern = "\\.csv$", full.names = TRUE)`, and now want to read each one with `read_csv()`. Write the for loop that will load them into a single data frame.
</div>

Сначала я предварительно распределяю список. 
Затем я считываю каждый файл во фрейм данных и назначаю его элементу в этом списке. 
Результатом является список фреймов данных. 
Затем я использую `bind_rows()`, чтобы объединить список фреймов данных в один фрейм данных.

```{r}
files <- dir("data/", pattern = "\\.csv$", full.names = TRUE)
df <- vector("list", length(files))
for (i in seq_along(files)) {
  df[[i]] <- read_csv(files[[i]])
}
df <- bind_rows(df)
```

#### Упражнение 21.3.5.3

<div class="question">
What happens if you use `for (nm in names(x))` and `x` has no names? 
What if only some of the elements are named? 
What if the names are not unique?
</div>

1. не содержит имён

```{r}
x <- 1:3
print(names(x))

for (nm in names(x)) {
  print(nm)
  print(x[[nm]])
}
# То есть ничего не произошло. Потому что нет имён
# Стоит помнить что
length(NULL)
```

2. Некоторые элементы содержат имена. Тогда генерируется ошибка

```{r}
# x <- c(a = 1, 2, c = 3)
#names(x)
#
#for (nm in names(x)) {
#  print(nm)
#  print(x[[nm]])
#}
```


3. Есть неуникальные имена. Так как есть неуникальные имена, нет возможности обратиться доступ к элементам с повторяющимися именами

```{r}
x <- c(a = 1, a = 2, c = 3)
names(x)

for (nm in names(x)) {
  print(nm)
  print(x[[nm]])
}
```

#### Упражнение 21.3.5.3

<div class="question">
Write a function that prints the mean of each numeric column in a data frame, along with its name. For example, show_mean(iris) would print:

```{r}
#show_mean(iris)
# > Sepal.Length: 5.84
# > Sepal.Width:  3.06
# > Petal.Length: 3.76
# > Petal.Width:  1.20
```

Extra challenge: what function did I use to make sure that the numbers lined up nicely, even though the variable names had different lengths?
</div>


```{r}
show_mean <- function(df, digits = 2) {
  # Получаем максимальную длину названия столбца
  maxstr <- max(str_length(names(df)))
  for (nm in names(df)) {
    # Задаём условие --- считаем среднее только для числовых столбцов
    if (is.numeric(df[[nm]])) {
      # Объединяем в красивый вывод
      cat(
        str_c(str_pad(str_c(nm, ":"), maxstr + 1L, side = "right"),
          format(mean(df[[nm]]), digits = digits, nsmall = digits),
          sep = " "
        ),
        # Выносим каждый вывод функции в отдельную строку
        "\n"
      )
    }
  }
}
show_mean(iris)
show_mean(df)

```


#### Упражнение 21.3.5.4

<div class="question">
What does this code do? How does it work?
</div>

```{r}
trans <- list( 
  disp = function(x) x * 0.0163871,            # Эта функция умножает х на константу
  am = function(x) {
    factor(x, labels = c("auto", "manual"))    # Эта функция делает из переменной фактор, с понятными названиями уровней
  }
)
for (var in names(trans)) {
  mtcars[[var]] <- trans[[var]](mtcars[[var]]) # Теперь мы заменяем в исходном фрейме данных две переменные на видоизменённые
}
```

Код работает зацикливанием на именованный список функций. 
Он вызывает именованную функцию в списке столбца `mtcars` с тем же именем и заменяет значения этого столбца.

Это функция.

`trans[["disp"]]`

Это применяет функцию к столбцу `mtcars` с тем же именем

`trans[["disp"]](mtcars[["disp"]])`


### Циклы `for` и функционалы

Есть мощная штука --- выносить функции в функции. Пример

```{r}
col_summary <- function(df, fun) {
  out <- vector("double", length(df))
  for (i in seq_along(df)) {
    out[[i]] <- fun(df[[i]])
  }
  out
}

col_summary(df, mean)
col_summary(df, sd)
col_summary(df, median)
```

#### Упражнение 21.3.6.1

<div class="question">
Read the documentation for `apply()`. 
In the 2nd case, what two for-loops does it generalize.
</div>

С функциями этого семейства мы уже знакомы

Для объекта с двумя измерениями, такого как матрица или фрейм данных, метод `apply()` заменяет зацикливание строк или столбцов матрицы или фрейма данных. Функция `apply()` используется аналогично `apply(X, MARGIN, FUN, ...)`, где `X` - это матрица или массив, `FUN` - это функция, которую нужно применить, и `...` дополнительные аргументы, передаваемые в `FUN`.

Когда `MARGIN = 1`, функция применяется к каждой строке. Например, в следующем примере вычисляется среднее значение строки матрицы.

```{r}
X <- matrix(rnorm(15), nrow = 5)
apply(X, 1, mean)
```

Это эквивалентно циклу:

```{r}
X_row_means <- vector("numeric", length = nrow(X))
for (i in seq_len(nrow(X))) {
  X_row_means[[i]] <- mean(X[i, ])
}
X_row_means
```

Когда `MARGIN = 2`, `apply()` эквивалентно циклу `for` для столбцов.

```{r}
X <- matrix(rnorm(15), nrow = 5)
X
apply(X, 2, mean)
```

```{r}
X_col_means <- vector("numeric", length = ncol(X))
for (i in seq_len(ncol(X))) {
  X_col_means[[i]] <- mean(X[i, ])
}
X_col_means
```


#### Упражнение 21.3.6.1

<div class="question">
Adapt `col_summary()` so that it only applies to numeric columns. You might want to start with an `is_numeric()` function that returns a logical vector that has a `TRUE` corresponding to each numeric column.
</div>

Напомню функцию

```{r}
col_summary <- function(df, fun) {
  out <- vector("double", length(df))
  for (i in seq_along(df)) {
    out[i] <- fun(df[[i]])
  }
  out
}
```

Теперь переделаем

```{r}
col_summary2 <- function(df, fun) {
  # создаём пустой вектор, который будет хранить каждый числовой столбец
  numeric_cols <- vector("logical", length(df))
  # проверяем, является ли каждый столбец числовым
  for (i in seq_along(df)) {
    numeric_cols[[i]] <- is.numeric(df[[i]])
  }
  # находим индексы числовых столбцов
  idxs <- which(numeric_cols)
  # находим количество числовых столбцов
  n <- sum(numeric_cols)
  # создаем вектор для хранения результатов
  out <- vector("double", n)
  # применять функцию только к числовым векторам
  for (i in seq_along(idxs)) {
    out[[i]] <- fun(df[[idxs[[i]]]])
  }
  # даём имена векторам
  names(out) <- names(df)[idxs]
  out
}

df <- tibble(
  X1 = c(1, 2, 3),
  X2 = c("A", "B", "C"),
  X3 = c(0, -1, 5),
  X4 = c(TRUE, FALSE, TRUE)
)
df

col_summary2(df, mean)

```

### Функции семейства `map`

Конечно не стоит отказываться от циклов совсем --- главное решить задачу. А уж потом работать над тем, как бы ускорить работу, или сделать код более удобочитаемым.

Для повышения удобочитаемости в пакете `purrr` есть семейство функций `map`, которые создают

* `map()` --- list.

* `map_lgl()` --- logical vector.

* `map_int()` --- integer vector.

* `map_dbl()` --- double vector.

* `map_chr()` --- character vector.

вот например как они работают

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

map_dbl(df, mean)

map_dbl(df, median)

# map_dbl(df, sd)
```

Это семейство помогает сфокусироваться на выполнении операции, а не на вспомогатеольных действиях по обслуживанию цикла и сохранению результата. Это ещё более понятно при использовании каналов-конвееров `%>%`

```{r}
df %>% map_dbl(mean)

df %>% map_dbl(median)

# df %>% map_dbl(sd)
```

Что нужно о них знать

1. Реализованы на языке С

2. Второй аргумент `.f` может быть функцией, формулой, символьным или целочисленным значением

3. Для передачи особых настроек есть аргумент многоточие `...`

4. Они отображают имена

```{r}
z <- list(x = 1:3, y = 4:5)

map_int(z, length)
```

#### Сокращения

Ниже представлен пример, разбивающий набор данных на три части, и применяющий одну и ту же модель к каждой из них

```{r, eval=FALSE}
models <- mtcars %>% 
  split(.$cyl) %>% 
  map(function(df) lm(mpg ~ wt, data = df))

# еще короче
models <- mtcars %>% 
  split(.$cyl) %>% 
  map(~lm(mpg ~ wt, data = .))
```

Но самый топчик, это извлечение именнованных компонентов 
```{r, eval=FALSE}
models %>% 
  map(summary) %>% 
  map_dbl(~.$r.squared)

# еще короче
models %>% 
  map(summary) %>% 
  map_dbl("r.squared")
```

#### Базовые возможности

Они есть, их можно будет поискать. Но пока не придумал зачем, если есть более понятные и простые альтернативы

#### Упражнение 21.5.3.1

<div class="question">
Write code that uses one of the map functions to:

1. Compute the mean of every column in mtcars.

2. Determine the type of each column in nycflights13::flights.

3. Compute the number of unique values in each column of iris.

4. Generate 10 random normals for each of $\mu = -10, 0, 10, 100$
</div>

1. Это проще простого
```{r}
map_dbl(mtcars, mean)
```

Проверим:
```{r}
mtcars %>%
  summarise(mean_mpg = mean(.$mpg))
```

2. Тип данных вектора

```{r}
map_chr(nycflights13::flights, typeof)
```

3. Уникальные столбцы

```{r}
# для начала посмотрим как это делается для одного столбца
length(unique(iris$Species))

# Теперь встроим функцию в map
map_int(iris, function(x) length(unique(x)))
```

4. Сгенерировать случайные значения

```{r, eval=FALSE}
mu <- c(-10, 10, 0, 100)

# Если нужен список, то можно просто вот так
map(mu, ~ rnorm(n = 10, mean = .))

# Но можно завернуть в красивую матрицу
matrix(unlist(
  map(mu, ~ rnorm(n = 10, mean = .))
  ), 
       ncol = 10, 
       byrow = TRUE, 
       dimnames = list(mu, 1:10))
```


#### Упражнение 21.5.3.2

<div class="question">
How can you create a single vector that for each column in a data frame indicates whether or not it’s a factor?
</div>

Несколько упражнений назад, мы преобразовали во фрейме данных `mtcars` один из параметров в фактор

```{r}
is.factor(mtcars$am)
```

Теперь применим знания о `map`, собственно это и будет решением

```{r}
map_lgl(mtcars, is.factor)
```

#### Упражнение 21.5.3.3

<div class="question">
What happens when you use the map functions on vectors that aren’t lists? 
What does `map(1:5, runif)` do? 
Why?
</div>

Функции `map` работают с любыми векторами, а не только со списками. 
Как и в случае списков, функции `map` будут применять функцию к каждому элементу вектора.
В следующих примерах входные данные для `map` представляют собой атомарные векторы (логические, символьные, числовые).

```{r, eval=FALSE}
map(c(TRUE, FALSE, TRUE), ~ !.)

map(c("Hello", "World"), str_to_upper)

map(1:5, ~ rnorm(.))

map(c(-0.5, 0, 1), ~ rnorm(1, mean = .))
```


Важно помнить, что хотя входом `map()` может быть любой вектор, выводом всегда является список.

```{r}
# map(1:5, runif) # runif создаёт случайное число указанное количество раз. По умолчанию между 0 и 1
```

Функция `map()` перебирает числа от 1 до 5. Для каждого значения она вызывает `runif()` с этим номером в качестве первого аргумента, который является номером выборки для рисования. В результате получается список длиной пять с числовыми векторами размеров от одного до пяти, каждый со случайными выборками из равномерного распределения. Обращаю внимание, что хотя `input` для `map()` был целочисленным вектором, возвращаемое значение было списком.


#### Упражнение 21.5.3.4

<div class="question">
What does `map(-2:2, rnorm, n = 5)` do? Why?

What does `map_dbl(-2:2, rnorm, n = 5)` do? Why?
</div>

Не очень понятно, при заданных параметрах, что за что отвечает, потому что `n = 5` и количество значений от -2 до 2 = 5.
```{r, eval=FALSE}
 map(-2:2, rnorm, n = 10)
```

`n`  --- это передаваемый через `...` параметр `rnorm`, который отвечает за количество наблюдений. 

`-2:2` --- определяет среднее вокруг которого будет считаться `rnorm`.

Исходное выражение берет выборки размера пять из пяти нормальных распределений со средними значениями (-2, -1, 0, 1 и 2), но с тем же стандартным отклонением (1). Возвращает список с каждым элементом числовые векторы длиной 5.

Однако, если вместо этого мы используем `map_dbl()`, выражение вызывает ошибку.

Это потому, что функция `map_dbl()` требует, чтобы функция, которую она применяет к каждому элементу, возвращала числовой вектор длины один. Если функция возвращает не числовой вектор или числовой вектор длиной более единицы, `map_dbl()` вызовет ошибку. Причиной такой строгости является то, что `map_dbl()` гарантирует, что он вернет числовой вектор такой же длины, что и его входной вектор.

Эта концепция применяется к другим функциям `map_*()`: 

* `map_chr()` требует, чтобы функция всегда возвращала символьный вектор длины один; 

* `map_int()` требует, чтобы функция всегда возвращала целочисленный вектор длины один; 

* `map_lglg()` требует, чтобы функция всегда возвращала логический вектор длины один. 

* Используйте функцию `map()`, если функция будет возвращать значения различных типов или длин.

#### Упражнение 21.5.3.5

<div class="question">
Rewrite `map(x, function(df) lm(mpg ~ wt, data = df))` to eliminate the anonymous function.
</div>

```{r, eval=FALSE}
x <- split(mtcars, mtcars$cyl) # разделить набор данных на список по параметру cyl
map(x, function(df) lm(mpg ~ wt, data = df))

# Теперь применим синтаксис сокращения, и перепишем без анонимной функции
map(x, ~ lm(mpg ~ wt, data = .))
```

### Обработка ошибок

Когда `map` завершается ошибкой, можно исправить ситуацию функцией `safely()`.

Она возвращает список из двух элементов 

* `result` --- оригинальный результат. В случае ошибки будет `NULL`

* `error` --- объект ошибки. В случае успешного завершения операции будет `NULL`

```{r, eval=FALSE}
 safe_log <- safely(log)
 str(safe_log(10))
 str(safe_log("a"))
```

```{r, eval=FALSE}
x <- list(1, 10, "a")
y <- x %>% map(safely(log))
str(y)
```

Можно получить два списка --- один для всех ошибок, другой --- для всех выходных результатов.

```{r, eval=FALSE}
y <- y %>% transpose()
str(y)
```

Обработка ошибок полностью зависит от нас --- в типичных случаях надо либо просматривать значения `x`, для которых `y` содержит ошибку, либо работать с нормальными `y`

```{r, eval=FALSE}
is_ok <- y$error %>% map_lgl(is_null)
x[!is_ok]

 y$result[is_ok] %>% flatten_dbl()
```

Есть ещё два полезных наречия

* `possibily()`. С помощью неё можно указать, что будет в случае ошибки

```{r, eval=FALSE}
x <- list(1, 10, "a")
x %>% map_dbl(possibly(log, NA_real_))
```


* `quietly()` перехватывает выводимые результаты, сообщения, предупреждения

```{r, eval=FALSE}
x <- list(1, -1)
x %>% map(quietly(log)) %>% str()
```

### Функции семейства `map` с несоколькими входными переменными

Если нужно выполнять итерации параллельно по нескольким входным перменным, то можно использовать `map2` и `pmap`.
Предположим, нужно имитировать нормальные распределения с разными средними значениями.

```{r, eval=FALSE}
mu <- list(5, 10, -3)
mu %>% 
  map(rnorm, n = 5) %>% 
  str()
```

А если нужно варьировать ещё и стандартное отклонение?
Итерировать по индексам и индексировать вектора средних значений и стандартных отклонений

```{r, eval=FALSE}
sigma <- list(1, 5, 10)
seq_along(mu) %>% 
  map(~rnorm(5, mu[[.]], sigma[[.]])) %>% 
  str()
```

Это затрудняет понимание кода. Вместо этого используем `map2` для итерирования по двум векторам

```{r, eval=FALSE}
map2(mu, sigma, rnorm, n = 5) %>% str()
```

`map2` итерирует следующую последовательность вызовов функций

![итерации](img/iteration.png)

Как и `map()` функция `map2()` это оболочка вокруг цикла `for`

```{r, eval=FALSE}
map2 <- function(x, y, f, ...) {
  out <- vector("list", length(x))
  for (i in seq_along(x)) {
    out[[i]] <- f(x[[i]], y[[i]], ...)
  }
  out
}
```

А теперь черёд `pmap` --- она принимает список аргументов. Её можно испольховать если нужно например варьировать среднее значение, стандартное отклонение и количество выборок

```{r, eval=FALSE}
n <- list(1, 3, 5)
args1 <- list(n, mu, sigma)
args1 %>%
  pmap(rnorm) %>% 
  str()
```

Это выглядит примерно так

![итерации](img/iteration2.png)

Если элементы не поименованы, функция будет использвать при выо=зове позиционное соответствие.
Это затрудняет чтение кода, так что лучше всё-таки именовать

```{r, eval=FALSE}
args2 <- list(mean = mu, sd = sigma, n = n)
args2 %>% 
  pmap(rnorm) %>% 
  str()
```

![итерации](img/iteration3.png)

Можно работть и со фреймом данных --- это вообще отвал башки

```{r}
params <- tribble(
  ~mean, ~sd, ~n,
    5,     1,  1,
   10,     5,  3,
   -3,    10,  5
)
params %>% 
  pmap(rnorm)
```

Как только код усложняется, имеет смысл использовать фрейм данных.

#### Вызов различных функций

Можно варьировать саму функцию

```{r}
f <- c("runif", "rnorm", "rpois")
param <- list(
  list(min = -1, max = 1), 
  list(sd = 5), 
  list(lambda = 10)
)
```

Для обработки подобных случаев можно использовать `invoke_map()`

```{r}
invoke_map(f, param, n = 5) %>% str()
```

Первый аргумент --- список функций, или символьный вектор имён функций.

Второй аргумент --- список списков, предоставляющий аргументы разные, для разных функций. 

Последующие аргументы передаются всем функция.

И вновь, чтобы упростить, можно использовать `tribble()`

```{r}
sim <- tribble(
  ~f,      ~params,
  "runif", list(min = -1, max = 1),
  "rnorm", list(sd = 5),
  "rpois", list(lambda = 10)
)
sim %>% 
  mutate(sim = invoke_map(f, params, n = 10))
```

![итерации](img/iteration4.png)


### Функции семейства `walk`

Функции семейства `walk` это альтернатива `map`. 

Используется с целью получения побочных эффектов, например когда нужно отобразить вывод на экране или сохранить файлы на диск.

Посмотри [здесь](https://r4ds.had.co.nz/iteration.html#exercises-58) чтобы вспомнить об этом побольше.

### Другие шаблоны циклов `for`

Есть ещё ряд функций абстракций. Понадобятся, когда вдруг столкнусь с такой проблемой

#### Функции-предикаты

Ряд функций работает с функциями-предикатами, которые возвращают одиночное значение `TRUE` или `FALSE`.

Функции `keep()` и `discard()` удерживают те элементы входного объекта, для которых предикатом является соответственно значени `TRUE` или `FALSE`.

```{r}
iris %>% 
  keep(is.factor) %>% 
  str()


iris %>% 
  discard(is.factor) %>% 
  str()
```

Функции `some()` и `every()` определяют, являются ли предикат истинным для некоторых или для всех элементов

```{r}
x <- list(1:5, letters, list(10))
str(x)

x %>% 
  some(is_character)


x %>% 
  every(is_character)
```

функция `detect()` находит первый элемент с истинным предикатом, а функция `detect_index()` возвращает позицию этого элемента

```{r}
x <- sample(10)
x


x %>% 
  detect(~ . > 5)

x %>% 
  detect_index(~ . > 5)
```

Функции `head_while()` и `tail_while()` принимают элементы с начала или с конца вектора, до тех пор, пока предикат имеет истинное значение

```{r}
x %>% 
  head_while(~ . > 5)

x %>% 
  tail_while(~ . > 5)
```

#### Функции `reduce` и `accumulate`

В случае сложного списка, иногда возникает потребность в сведении его к более простому, путём повторного применения функции, преобразующей пару в синглтон (объект-одиночку). Это может быть полезным, если вы хотите применить двухтабличный глагол к нескольким таблицам.

Например, может быть список фреймов данных, и вы хотите свести его к одиночному фрейму, объеденив все элементы

```{r}
dfs <- list(
  age = tibble(name = "John", age = 30),
  sex = tibble(name = c("John", "Mary"), sex = c("M", "F")),
  trt = tibble(name = "Mary", treatment = "A")
)

dfs %>% reduce(full_join)
```

Другим примером, может быть список векторов, для которого вы хотите найти пересечение. Какие значения есть во всех векторах? ответ:

```{r}
vs <- list(
  c(1, 3, 5, 6, 10),
  c(1, 2, 3, 7, 8, 10),
  c(1, 2, 3, 4, 8, 9, 10)
)

vs %>% reduce(intersect)
```

Функция `reduce` принимает бинарную функцию --- функцию с двумя основными входными переменными --- и повторно применяет её к списку до тех пор, пока остаётся хотя бы один элемент.

Функция `accumulate` аналогична предыдущей, но удерживает все промежуточные результаты. Вы можете использовать её для реализации кумулятивного суммирования

```{r}
x <- sample(10)
x

x %>% accumulate(`+`)

```

#### Упражнение 21.9.3.1

<div class="question">
Implement your own version of `every()` using a for loop. Compare it with `purrr::every()`. 
What does purrr’s version do that your version doesn’t?
</div>

Подглядим как работает функция `every()`

```{r}
every
```

Ага, мы для каждого элемента проверяем является ли истиной результат применения функции к этому элементу.
Если результат не_ложь, то возвращаем истину, если результат не_истина возвращаем ложь.

Если есть ЛОЖЬ, мы знаем, что не все из них были ИСТИННЫМИ
если ничего не было ЛОЖЬ, то ИСТИНА

```{r}
y <- list(0:10, 5.5)
x <- 1:10
every(y, is.numeric)
every(y, is.integer)
every(x, is.integer)

is.numeric(1)
is.numeric(2)

every1 <- function(value, fun, ...){
  for (i in value) {
    if(!fun(i, ...)){
      return(FALSE)
    }
  }
  return(TRUE)
}

every1(x, is.numeric)
```

Функция `purrr::every()` делает причудливые вещи с аргументом функции предиката `fun`, например, берет логический вектор вместо функции или может проверить часть строки, если элементы `fun` являются списками.


#### Упражнение 21.9.3.2

<div class="question">
Create an enhanced `col_summary()` that applies a summary function to every numeric column in a data frame.
</div>

```{r}
col_sum2 <- function(df, f, ...) {
  map(keep(df, is.numeric), f, ...)
}
```


#### Упражнение 21.9.3.3

<div class="question">
A possible base R equivalent of col_summary() is:

```{r}
col_sum3 <- function(df, f) {
  is_num <- sapply(df, is.numeric)
  df_num <- df[, is_num]
  sapply(df_num, f)
}
```

But it has a number of bugs as illustrated with the following inputs:

```{r}
df <- tibble(
  x = 1:3,
  y = 3:1,
  z = c("a", "b", "c")
)

# OK
col_sum3(df, mean)
# Has problems: don't always return numeric vector
col_sum3(df[1:2], mean)
col_sum3(df[1], mean)
# col_sum3(df[0], mean)
```

What causes these bugs?
</div>

Причиной этих ошибок является поведение `sapply()`. Функция `sapply()` не гарантирует тип вектора, который она возвращает, и будет возвращать разные типы векторов в зависимости от ее входных данных. Если столбцы не выбраны, вместо возврата пустого числового вектора возвращается пустой список. Это вызывает ошибку, так как мы не можем использовать список с `[`.

```{r}
sapply(df[0], is.numeric)

sapply(df[1], is.numeric)

sapply(df[1:2], is.numeric)
```

Функция `sapply()` пытается помочь, упрощая результаты, но такое поведение может быть контрпродуктивным. Можно использовать функцию `sapply()` в интерактивном режиме, но избегайте программирования с ней.

<!--chapter:end:17_iteration.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Моделирование

Знакомимся с Exploratory data analysis (EDA) --- разведочный анализ данных.

Цель моделирования --- получение простых суммарных (сводных) характеристик набора данных.

Здесь разбриаем предсказательные модели анализа данных. Есть ещё много разных, например data discovery, но их здесь не рассматриваем

Базовые принципы корректного статистического вывода:

* Каждое наблюдение можно использовать либо для разведочного анализа, либо для подтверждения гипотезы. Но не для того и другого одновременно

* В целях разведочного анализа допускается многократное использование наблюдения, но в целях подтверждения гипотез --- только однократное. Использование одного и того же наблюдения более одного раза равносильно переходу от подтверждения гипотезы к разведочному анализу.

Данные используемые для подтверждения гипотезы не должны зависеть от данных на основании которых эта гипотеза была выдвинута.

### Выдвижение гипотез и их подтверждение

Один из подходов к анализу, направленному на подтверждение гипотезы, заключается в разбиении данных на три части ещё до того, как приступить к анализу

* $60%$ --- training set. С этим набором можноделать всё что пожелается.

* $20%$ --- query set. Набор для сравнения моделей или вариантов визуализации вручную, но их не разрешается использовать в качестве части автоматизированного процесса.

* $20%$ --- test set. Эти данные можно использовать только один раз для тестирования окончательной модели.

## Базовое моделирование при помощи пакета `modelr`
### Введение

Цель моделирования --- определение суммарных характеристик набора данных. 

Моделирование включает два аспекта

1. Прежде всего необходимо определить семейство моделей. Они определяют типичную закономерность, например линейную или квадратичную зависимость. Семейство моделей описывается уравнением наподобие `y = a_1 * x + a_2` or `y = a_1 * x ^ a_2`. Где `x` и `y` --- известные переменные, а `a_1` и `a_2` варьируемые параметры.

2. Далее вы генерируете подходяющую модель, выбирая ту из семейства моделей, которая больше всего соответствует данным. В результате этого обобщенного уравнения семейства моделей конкретизируется принимая вид наподобие `y = 3 * x + 7`

Целью моделирования является не установление окончательной истины, а нахождение простого, но тем не менее полезного приближения


#### Необходимые ресурсы

```{r}
library(tidyverse)
library(splines)
library(modelr)
options(na.action = na.warn)
```

### Простая модель

Демонстрационный набор данный `sim1` содержит две непрерывные переменные `x` и `y`. Отложим их на графике, чтобы увидеть, как они связаны между собой

```{r}
ggplot(sim1, aes(x, y)) +
  geom_point()
```

между переменными наблюдается сильная взаимосвязь. Коэффициент корреляции

```{r}
cor(sim1$x, sim1$y)
```

Опишем эту взаимосвязь с помощью модели и выразим ее в явном виде.

Наша задача --- предоставить базовую форму модели. В данном случае мы используем линейное соотношение между переменными `y = a_0 + a_1 * x`.
Начнем с получения общего представления о том, как выглядят модели этого семейства. Путём случайной генерации некоторых из них и наложения их на данные.

В нашем случае можно использовать `geom_abline` --- она принимает наклон (slope), и y-пересечение (intercept).

```{r}
models <- tibble(
  a1 = runif(250, -20, 40),
  a2 = runif(250, -5, 5)
)

ggplot(sim1, aes(x, y)) + 
  geom_abline(
    aes(intercept = a1, slope = a2), 
    data = models, alpha = 1/4
  ) +
  geom_point()
```

Большинство из построенных моделей совсем неудачны. Нам нужен метод обеспечивающий количественную оценку расстояния между данными и моделью.

Это расстояние --- разность между значением предоставляемым моделью --- прогноз, и фактическим значением `y` согласно данным `data` --- результат.

![расстояния от результата до прогноза](img/model.png)

Для вычисления расстояния мы прежде всего превратим семейство моделей в функцию. 
В качестве аргументов, эта функция принимает параметры модели и данные, а в качестве выходного результата предоставляет значения, предсказанные моделью

```{r}
model1 <- function(a, data) {
  a[1] + data$x * a[2]
}

model1(c(7, 1.5), sim1)
```

Чтобы найти минимальное расстояние при помощи среднеквадратического отклонения.

```{r}
measure_distance <- function(mod, data) {
  diff <- data$y - model1(mod, data)
  sqrt(mean(diff ^ 2))
}
measure_distance(c(7, 1.5), sim1)
```

Теперь используем пакет `purrr` для того чтобы вычислить это расстояние для всех ранее определённых моделей. Нам нужна вспомогательная функция, поскольку наша функция вычисляющая расстояние лжидает модель в качестве числового вектора с длиной 2

```{r}
sim1_dist <- function(a1, a2) {
  measure_distance(c(a1, a2), sim1)
}

models <- models %>% 
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))
models
```

Выделим лучшие модели

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, color = "grey30") + 
  geom_abline(
    aes(intercept = a1, slope = a2, color = -dist), 
    data = filter(models, rank(dist) <= 10)
  )
```

Мы можем рассматривать эти модели как наблюдения и визуализировать их с помощью точечной диаграмы с осями `a1` и `a2`, опять таки расцветив их в соответстсвии со значениями `-dist`. При этом мы увидим множество моделей одновременно.
Выделим 10 лучшиъ моделей кржочками

```{r}
ggplot(models, aes(a1, a2)) +
  geom_point(data = filter(models, rank(dist) <= 10), size = 4, colour = "red") +
  geom_point(aes(colour = -dist))
```

Можно так же построить сетку поиска! Где точки расположены не хаотично, а упорядоченно

```{r}
grid <- expand.grid(
  a1 = seq(-2, 10, length = 25),
  a2 = seq(0, 2, length = 25)
  ) %>% 
  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))

grid %>% 
  ggplot(aes(a1, a2)) +
  geom_point(data = filter(grid, rank(dist) <= 10), size = 4, colour = "red") +
  geom_point(aes(colour = -dist)) 
```

Если наложить эти 10 наилучших моделей на исходные данные, то они будут выглядеть довольно прилично

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, colour = "grey30") + 
  geom_abline(
    aes(intercept = a1, slope = a2, colour = -dist), 
    data = filter(grid, rank(dist) <= 10)
  )
```

но конечно самый простой способ это воспользоваться  функцией `lm()` для построения линейных моделей

```{r}
sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
```

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, colour = "grey30") + 
  geom_abline(intercept = coef(sim1_mod)[1], slope = coef(sim1_mod)[2])
```

#### Упражнение 23.2.1.1

<div class="question">
One downside of the linear model is that it is sensitive to unusual values because the distance incorporates a squared term. Fit a linear model to the simulated data below, and visualise the results. Rerun a few times to generate different simulated datasets. What do you notice about the model?

```{r}
sim1a <- tibble(
  x = rep(1:10, each = 3),
  y = x * 1.5 + 6 + rt(length(x), df = 2)
)
```
</div>

Линейные модели неустойчивы к выбросам --- известный факт.

Попробуем это на одиночной модели

```{r}
sim1a_mod <- lm(y ~ x, sim1a)

ggplot(sim1a, aes(x, y)) + 
  geom_point(size = 2, color = "grey30") + 
  geom_abline(intercept = coef(sim1a_mod)[1], slope = coef(sim1a_mod)[2], color = "red")
```

Сделаем функцию, которая бы генерировала несколько распределений сразу

```{r}
simt <- function(i) {
  tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rt(length(x), df = 2),
    id = i
  )
}

sims <- map_df(1:15, simt)

ggplot(sims, aes(x, y)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  facet_wrap(~id, ncol = 5)
```

Что если проделать всё тоже самое с нормальным распределением

```{r}
sim_norm <- function(i) {
  tibble(
    x = rep(1:10, each = 3),
    y = x * 1.5 + 6 + rnorm(length(x)),
    .id = i
  )
}

simdf_norm <- map_df(1:12, sim_norm)

ggplot(simdf_norm, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", colour = "red") +
  facet_wrap(~.id, ncol = 4)
```

Здесь не большие выбросы, а склоны больше похожи.

Причина в том, что t-распределение Стьюдента, из которого мы выбираем с помощью `rt()`, имеет более тяжелые хвосты, чем нормальное распределение `rnorm()`. Это означает, что t-распределение Стьюдента присваивает большую вероятность значениям дальше от центра распределения.

```{r}
tibble(
  x = seq(-5, 5, length.out = 100),
  normal = dnorm(x),
  student_t = dt(x, df = 2)
) %>%
  gather(distribution, density, -x) %>%
  ggplot(aes(x = x, y = density, color = distribution)) +
  geom_line()
```

Для нормального распределения со средним `0` и стандартным отклонением `1` --- вероятность того, что оно больше 2, составляет

```{r}
pnorm(2, lower.tail = FALSE)
```

В то время как в распределении Стьюдента, с числом степеней свободы = 2,

```{r}
pt(2, df = 2, lower.tail = FALSE)
```

#### Упражнение 23.2.1.2

<div class="question">
One way to make linear models more robust is to use a different distance measure. For example, instead of root-mean-squared distance, you could use mean-absolute distance:

```{r}
measure_distance <- function(mod, data) {
  diff <- data$y - model1(mod, data)
  mean(abs(diff))
}
```

Use `optim()` to fit this model to the simulated data above and compare it to the linear model.
</div>

Чтобы вышеуказанная функция работала, нам нужно определить функцию `make_prediction()`, которая принимает числовой вектор длины два (пересечение и наклон) и возвращает предсказания,

```{r}
make_prediction <- function(mod, data) {
  mod[1] + mod[2] * data$x
}
```

Используя данные `sim1a`, лучшие параметры наименьшего абсолютного отклонения:

```{r}
best <- optim(c(0, 0), measure_distance, data = sim1a)
best$par
```

Используя данные `sim1a`, параметры целевой функции минимизации наименьших квадратов:

```{r}
measure_distance_ls <- function(mod, data) {
  diff <- data$y - (mod[1] + mod[2] * data$x)
  sqrt(mean(diff^2))
}

best <- optim(c(0, 0), measure_distance_ls, data = sim1a)
best$par
```

На практике предлагают не использовать `optim()` для соответствия этой модели, а вместо этого использовать существующую реализацию. 
Функции `rlm()` и `lqs()` в `MASS` подходят для надежных и устойчивых линейных моделей.

#### Упражнение 23.2.1.3

<div class="question">
One challenge with performing numerical optimisation is that it’s only guaranteed to find one local optimum. What’s the problem with optimising a three parameter model like this?

```{r}
model3 <- function(a, data) {
  a[1] + data$x * a[2] + a[3]
}
```
</div>

Проблема в том, что для любых значений `a[1] = a1` и `a[3] = a3`, любых других значений `a[1]` и `a[3]`, где `a[1] + a[3] == (a1 + а3)` будет иметь такую же посадку.

```{r}
measure_distance_3 <- function(a, data) {
  diff <- data$y - model3(a, data)
  sqrt(mean(diff^2))
}
```

В зависимости от наших отправных точек, мы можем найти различные оптимальные значения:

```{r}
best3a <- optim(c(0, 0, 0), measure_distance_3, data = sim1)
best3a$par

best3b <- optim(c(0, 0, 1), measure_distance_3, data = sim1)
best3b$par

best3c <- optim(c(0, 0, 5), measure_distance_3, data = sim1)
best3c$par
```

На самом деле существует бесконечное количество оптимальных значений для этой модели.

### Визуализация моделей

Если вашей целью является применение моделей для исследования статистических характеристик массивов данных, то вероятнее всего большую часть времени вы будете исследовать какие закономерности отражает модель, путём тщательного изучания семейства моделей.

Полезно бывает рассмотреть то, что моделью не охватывается, --- остатки., т.е. то что остается после вычитания прогнозных значений из фактических данных. Остатки предоставляют чрезвычайно полезную информацию, поскольку они позволяют использовать модели для устранения экстремальных пиков и тем самым дают возможность изучать слабые остаточные тренды.

#### Предсказания

Визуализацию предсказаний на основе модели мы начнём с того, что сгенерируем равномерную сетку значений охватывающих всю облать, в которой распологаются наши данные. Проще всего это можно сделать с помощью `modelr::data_grid()`.
Первый аргумент --- фрейм данных. Для последующих аргументов она находит уникальные переменные и генерирует все комбинации.

```{r}
grid <- sim1 %>%
  data_grid(x)
```

Станет ещё более понятно и интереснее, когда мы добавим переменные в нашу модель.

Следующий шаг --- добавление предсказаний. Сделаем это при помощи `modelr::add_predictions()`. Она принимает модель данных и сами данные. олученные с помощтю модели предсказания добавляет в новый столбец фрейма данных

```{r}
grid <- grid %>%
  add_predictions(sim1_mod) # sim1_mod --- это модель
```

Эту функцию можно использовать для добавления предсказаний в исходный набор данных. 

Далее мы откладываем предсказания в виде графика. 

```{r}
ggplot(sim1, aes(x)) +
  geom_point(aes(y = y)) +
  geom_line(aes(y = pred), data = grid, color = "red", size = 1)
```

Такой подход будет работать с любой моделью в R. Здесь предсказание --- это не построение дополнительных значений, а построение зависимости, по которой эти дополнительные значения должны строится.

#### Остатки

Обратная сторона предсказаний, как завещал Тьюки --- остатки. Предсказания отражают закономерность, которую модели удалось уловить, тогда как остатки предоставляют информацию о том, что не охватывается моделью.

Остатки --- это не что иное, как расстояния между наблюдениями и вычисленными нами прогнозными значениями.

Мы добавляем остатки к данным с помощью функции `modelr::add_residuals()`, которая работает во многом аналогично функции `modelr::add_predictions()`. Стоит отметить --- что мы используем исходный набор данных, а не искуственную сетку.

Это обсуловлено тем, что для вычисления остатков нам нужны фактические значения `y`

```{r}
sim1 <- sim1 %>%
  add_residuals(sim1_mod)
```

Существует несколько способов извлечения информации о модели на основе остатков. Один из них --- графические представление распределения остатков с помощю полигона частот. 

```{r}
ggplot(sim1, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)
```

Это ползволяет калибровать качество  модели: насколько прогноз отличается от наблюдаемых значений? Обратите внимание на то, что среднее остатков всегда равно 0.

Потребность в построении графиков с использование остатков вместо исходного предиктора будет возникать довольно часто.

```{r}
ggplot(sim1, aes(x, resid)) + 
  geom_ref_line(h = 0) +
  geom_point()
```

Этот график выглядит как случайный шум. Это косвенно говорит о том, что наша модель неплохо справилась со своей задачей определения закономерности в поведении данных.

#### Упражнение 23.3.3.1
<div class="question">
Instead of using `lm()` to fit a straight line, you can use `loess()` to fit a smooth curve. 
Repeat the process of model fitting, grid generation, predictions, and visualisation on `sim1` using `loess()` instead of `lm()`.
How does the result compare to `geom_smooth()`?
</div>

Сначала произведём подгонку модели

```{r}
sim1_loess <- loess(y ~ x, data = sim1)
sim1_lm <- lm(y ~ x, data = sim1)
```

Теперь сгенерируем сетку

```{r}
grid_loess <- sim1 %>%
  add_predictions(sim1_loess)
```

Теперь спрогнозируем

```{r}
sim1 <- sim1 %>%
  add_residuals(sim1_lm) %>%
  add_predictions(sim1_lm) %>%
  add_residuals(sim1_loess, var = "resid_loess") %>%
  add_predictions(sim1_loess, var = "pred_loess")
```

И после этого визуализируем. На одном графике, для сравнения, я построил три модели. Зелёная линейная, синяя --- гладкая при помощи функции `geom_smooth()`. И красная, при помощи функции `loess()`.

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, color = "grey30") + 
  geom_smooth(se = F, size = 2, color = "blue") +
  geom_line(aes(x, pred), data = grid_loess, color = "red") +
  geom_line(aes(y = pred), data = grid, color = "green")
```

И наконец, построим остатки для гладкой модели и сравним их с остатками из прямолинейной модели (черный цвет).

```{r}
ggplot(sim1, aes(x = x)) +
  geom_ref_line(h = 0) +
  geom_point(aes(y = resid)) +
  geom_point(aes(y = resid_loess), colour = "red")
```

В целом, довольно схоже.

#### Упражнение 23.3.3.2
<div class="question">
`add_predictions()` is paired with `gather_predictions()` and `spread_predictions()`. 
How do these three functions differ?
</div>

Функции `collect_predictions()` и `spread_predictions()` позволяют добавлять прогнозы из нескольких моделей одновременно.
Например

```{r}
sim1_mod <- lm(y ~ x, data = sim1)
grid <- sim1 %>%
  data_grid(x)
```

Функция `add_predictions()` добавляет только одну модель за раз. Чтобы добавить две модели:

```{r}
grid %>%
  add_predictions(sim1_mod, var = "pred_lm") %>%
  add_predictions(sim1_loess, var = "pred_loess")
```

Функция `collect_predictions()` добавляет прогнозы из нескольких моделей, складывая результаты и добавляя столбец с именем модели

```{r}
grid %>%
  gather_predictions(sim1_mod, sim1_loess)
```

Функция `spread_predictions()` добавляет прогнозы из нескольких моделей, добавляя несколько столбцов (с добавлением названия модели) с прогнозами из каждой модели.

```{r}
grid %>%
  spread_predictions(sim1_mod, sim1_loess)
```

Функция `spread_predictions()` аналогична примеру, который запускает `add_predictions()` для каждой модели, и эквивалентна запуску `spread()` после запуска `collect_predictions()`:

```{r}
grid %>%
  gather_predictions(sim1_mod, sim1_loess) %>%
  spread(model, pred)
```

#### Упражнение 23.3.3.3
<div class="question">
What does `geom_ref_line()` do? 
What package does it come from? 
Why is displaying a reference line in plots showing residuals useful and important?
</div>

`geom_ref_line()` добавляет в качестве опорной линии на участок.
В примере выше это был ноль.
В принципе, это эквивалентно запуску `geom_hline()` или `geom_vline()` с настройками по умолчанию, которые полезны для визуализации моделей. 
Поместить опорную линию в ноль для остатков важно, потому что хорошие модели (как правило) должны иметь остатки, центрированные в нуле, с примерно той же дисперсией (или распределением) по отношению к поддержке `x` и без корреляции. 
Нулевая контрольная линия облегчает визуальную оценку этих характеристик.

#### Упражнение 23.3.3.4
<div class="question">
Why might you want to look at a frequency polygon of absolute residuals? W
hat are the pros and cons compared to looking at the raw residuals?
</div>

Отображение абсолютных значений остатков облегчает просмотр распределения остатков. 
Модель предполагает, что остатки имеют средний ноль, а использование абсолютных значений остатков фактически удваивает число остатков.

```{r}
sim1_mod <- lm(y ~ x, data = sim1)

sim1 <- sim1 %>%
  add_residuals(sim1_mod)

ggplot(sim1, aes(x = abs(resid))) +
  geom_freqpoly(binwidth = 0.5)
```

Однако использование абсолютных значений невязок отбрасывает информацию о знаке, а это означает, что многоугольник частоты не может показать, насколько модель систематически переоценивает или занижает невязки.

### Формулы и семейства моделей

ДО этого мы уже сталкивались с формулами, когда использовали функции `facet_wrap()` и `facet_grid()`. В R формулы обуспечивают обзий способ получения специального поведения.

Вместо того чтобы сразу же использовать переменные в вычислениях, они захватыввают их для последующей интепретации с помощью функции.

Большинство функций моделирования в R используют стандартное преобразование от формул к функциям. Один из примеров простого преобразования:

`y ~ x` --- `y = a_1 + a_2 * x`

Если нужно увидеть что фактически делает R, можно использовать функцию `model_matrix()`.
Эта функция принимает фрейм данных и формулу и возвращает tibble-фрейм, определяющий уравнение модели: каждый столбец результата связан с одним коэффициентом модели, а функция всегда имеет вид `y = a_1 * out + a_2 * out_2`.
Для простого случая `y ~ x1` мы получаем нечто любопытное.

```{r}
df <- tribble(
  ~y, ~x1, ~x2,
  4, 2, 5,
  5, 1, 6
)
model_matrix(df, y ~ x1)
```

По умолчанию R добавляет столбец заполненный единицами. Если гнужно отказаться от него добавим в формулу `-1`

```{r}
model_matrix(df, y ~ x1 - 1)
```

При добавлении дополнительных переменных в модель размер матрицы модели, как и следовало ожидать, увеличивается

```{r}
model_matrix(df, y ~ x1 + x2)
```

Здесь <https://www.jstor.org/stable/2346786?read-now=1&seq=1#metadata_info_tab_contents> подробнее о символьных преобразованиях.

#### Категориальные переменные

Если предиктором является непрерывная переменная, то генерация функции из формулы осуществляется непосредственным образом, но если предикатор --- категориальная переменная, то всё немного усложняется.

Предположим, имеется формула наподобие `y ~ sex`, где переменная `sex` --- может принимать два значения, которые обозначают мужчину и женщину (`male` и `female`). Преобразовать эту формулу к виду `y = x_1 + x_2 * sex` не имеет смысла, поскольку переменная `sex` не является числом --- она просто не может участвовать в умножении. Вместо этого R преобразует её к виду `y = x_1 + x_2 * sex_male`, где sex_male принимает 1 для мужчин и 0 для женщин.

```{r}
df <- tribble(
  ~ sex, ~ response,
  "male", 1,
  "female", 2,
  "male", 1
)
model_matrix(df, response ~ sex)
```

Используем набор данных `sim2` для того чтобы конкретизировать общие утверждения о точной параметризации.

```{r}
ggplot(sim2) + 
  geom_point(aes(x, y))
```

Мы можем подобрать модель для этого набора данных и сгенерировать прогноз.

```{r}
mod2 <- lm(y ~ x, data = sim2)

grid <- sim2 %>% 
  data_grid(x) %>% 
  add_predictions(mod2)
grid
```

В конечном счете модель с категориальной переменной `x` будет предсказывать среднее значение для каждой категории. (Почему? потому что среднее минимизирует среднеквадратическое отклонение). Это можно легко увидеть, если наложить предсказания на исходные данные.

```{r}
ggplot(sim2, aes(x)) + 
  geom_point(aes(y = y)) +
  geom_point(data = grid, aes(y = pred), colour = "red", size = 4)
```

Вы не можете делать прогнозы относительно уровней, которые не наблюдали. Иногда это будет происходить случайно, поэтому стоит запомнить следующее сообщение об ошибке.

```{r, eval=FALSE}
tibble(x = "e") %>% 
  add_predictions(mod2)

#Ошибка в model.frame.default(Terms, newdata, na.action = na.action, xlev = #object$xlevels) :
#  длины переменных различаются (найдено в 'x2')
#Вдобавок: Предупреждение:
#'newdata' had 1 row but variables found have 100 rows 
```

#### Взаимодействия --- непрерывная и категориальная переменные

Что происходит в тех случаях, когда непрерывная переменная сочетается с категориальной?

```{r}
ggplot(sim3, aes(x1, y)) +
  geom_point(aes(color = x2))
```

Для этих данных возможны две модели

```{r}
mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)
```

КОгда добавляешь модели с помощью знака `+` они оценивают каждый эффект независимо от всех остальных. Для подгонки так называемого взаиомодействия можно использовать знак `*`. Например `y ~ x1 * x2` транслируется в `y = a_0 + a_1 * x1 + a_2 * x2 + a_12 * x1 * x2`.
Когда используешь знак `*` в модель включается как взаимодействие, так и индивидуальная компонента.

Для визуализации понадобится два новшества

* У нас два предиктора, поэтому мы должны предоставить функции `data_grid()` обе переменные. Эта функция найдёт все уникальные значения `x1` и `x2` и сгенерирует все их комбинации

* Чтобы сгенерировать прогнозы на основе сразу двух моделей, можно использовать функцию `gather_predictions()`, которая добавляет каждый прогноз в качестве строки. Комплементарной к функции `gather_predictions()` является `spread_predictions()`, которая добавляет каждый прогноз в новый столбец.

Вместе это даёт нам следующее

```{r}
grid <- sim3 %>% 
  data_grid(x1, x2) %>% 
  gather_predictions(mod1, mod2)
```

Результаты для обеих моделей можно визуализировать на одном графике

```{r}
ggplot(sim3, aes(x1, y, colour = x2)) + 
  geom_point() + 
  geom_line(data = grid, aes(y = pred)) + 
  facet_wrap(~ model)
```

ВТорая модель интуитивно кажется более корректной.
Стоит обратить внимание, что во второй модели все прямые имеют разный угол наклона, тогда как при использовании `+` в `mod1` все прямые наклонены под одним углом но с разным intercept.

Чтобы убедиться в том, какая модель лучше описывает данные можно рассмотреть остатки. 

```{r}
sim3 <- sim3 %>% 
  gather_residuals(mod1, mod2)

ggplot(sim3, aes(x1, resid, colour = x2)) + 
  geom_point() + 
  facet_grid(model ~ x2)
```

В остальном, нужна большая математическая подготовка, чтобы ответить на то, насколько вторая модель лучше чем первая.

#### Взаимодействия --- две непрерывные переменные

РАссмотрим эквивалентную модель для двух непрерывных переменных.

```{r}
mod1 <- lm(y ~ x1 + x2, data = sim4)
mod2 <- lm(y ~ x1 * x2, data = sim4)

grid <- sim4 %>% 
  data_grid(
    x1 = seq_range(x1, 5), 
    x2 = seq_range(x2, 5) 
  ) %>% 
  gather_predictions(mod1, mod2)
grid
```

удобный приём с `seq_range()`. Вместо того чтобы использовать каждое уникальное значение `х` мы собираемся задействовать регулярную сетку из *пяти* значений, равномерно расположенных между минимальным и максимальным значением.

Функция `seq_range()` имеет три других полезных аргумента

* `pretty = TRUE` --- генерирует красивую последовательность. Т.е. ту, которая хорошо воспринимается человеческим глазом.

```{r}
seq_range(c(0.0123, 0.923423), n = 5)

seq_range(c(0.0123, 0.923423), n = 5, pretty = TRUE)
```

* `trim = 0.1` --- отсекает 10% хвостовых значений. Это полезно, если распределение имеет длинные хвосты и нужно сосредоточится на генерировании значений вблизи центра

```{r}
x1 <- rcauchy(100)
seq_range(x1, n = 5)

seq_range(x1, n = 5, trim = 0.10)

seq_range(x1, n = 5, trim = 0.25)

seq_range(x1, n = 5, trim = 0.50)
```

* `expand = 0.1` --- производит эффект, в некотором смысле противоположный эффекту `trim`, приводя расширение диапазона на 10%

```{r}
x2 <- c(0, 1)
seq_range(x2, n = 5)

seq_range(x2, n = 5, expand = 0.10)

seq_range(x2, n = 5, expand = 0.25)

seq_range(x2, n = 5, expand = 0.50)
```

Попробуем визуализировать эту модель. У нас имеется два непрерывных предиктора, поэтому мы можем представить модель в виде трехмерной поверхности. Для её отображения можно воспользовать функцией `geom_tile()`

```{r}
ggplot(grid, aes(x1, x2)) + 
  geom_tile(aes(fill = pred)) + 
  facet_wrap(~ model)
```

Из результатов не следует, что модели сильно различаются.
Отчасти это оптическая иллюзия --- наши глаза и мозг недостаточно чувствительны, если речь идёт о различении цветовых оттенков.
Вместо того чтобы всматриваться на поверхность сверху, мы можем посмотреть на неё с любой другой строноы и продемонстрировать не один срез.

```{r}
ggplot(grid, aes(x1, pred, colour = x2, group = x2)) + 
  geom_line() +
  facet_wrap(~ model)
ggplot(grid, aes(x2, pred, colour = x1, group = x1)) + 
  geom_line() +
  facet_wrap(~ model)
```

Как показывают результаты --- взаимодействие двух непрерывных переменных работает в основном так же, как и взаимодействие категориальной и непрерывной переменных.
Взаимодействие указывает на отсутствие фиксированного сдвига --- для того чтобы прогнозировать значения `y`, необходимо рассматривать одновременно значения `x1` и `x2`

Модель не должна быть идеальной --- она должна лишь помогать обнаруживать пусть даже небольшую дополнительную информацию о данных.

Мы посвятили некоторое время рассмотрению остатков, чтобы посмотреть, сможем ли мы определить что `mod2` работает лучше чем `mod1`. Судя по всему, это так, но различие мужду ними довольно незначительное.

#### Преобразования

В формуле модели так же можно выполнять преобразования. Например `log(y) ~ sqrt(x1) + x2` преобразуется в `log(y) = a_1 + a_2 * sqrt(x1) + a_3 * x2`

Если преобразование включает операторы `+`, `*`, `^`,  `-` то те части формулы в которых эти операторы используются в качестве арифметических, необходимо обернуть в функцию `I()`, чтобы R не обрабатывал их как символические операторы специфицкации модели.
Например `y ~ x + I(x ^ 2)` преобразуется в `y = a_1 + a_2 * x + a_3 * x^2`

Если получается что-то не то, что хотелось увидеть можно посмотреть при помощи `model_matrix()` в соответствии с каким уравнение функция `lm()` строит модель 

```{r}
df <- tribble(
  ~y, ~x,
   1,  1,
   2,  2, 
   3,  3
)
model_matrix(df, y ~ x^2 + x)

model_matrix(df, y ~ I(x^2) + x)
```

ПРеобразования полезны тем, что их можно использовать для аппроксимации нелинейных функций.
Ряд Тейлора --- любую гладкую функцию можно разложить на бесконечную сумму многочленов. 

Их можно задавать в R при помощи встроенной функции `poly()`. Так уравнение наподобие `y = a_1 + a_2 * x + a_3 * x^2 + a_4 * x ^ 3` будет записано в 

```{r}
model_matrix(df, y ~ poly(x, 2))
```

Однако с использование функции `poly()` существует серьёзная проблема --- за пределами диапазона данных значения полинома быстро стремятся к положительной или отрицательной бесконечности. Одна из безопасных альтернатив заключается в использовании натуральных сплайнов `splines::ns()`

```{r}
model_matrix(df, y ~ ns(x, 2))
```

Посмотрим как это будет выглядеть при попытке аппроксимации нелинейной функции

```{r}
sim5 <- tibble(
  x = seq(0, 3.5 * pi, length = 50),
  y = 4 * sin(x) + rnorm(length(x))
)

ggplot(sim5, aes(x, y)) +
  geom_point()
```

Мы собираемся построить 5 моделей для этих данных

```{r}
mod1 <- lm(y ~ ns(x, 1), data = sim5)
mod2 <- lm(y ~ ns(x, 2), data = sim5)
mod3 <- lm(y ~ ns(x, 3), data = sim5)
mod4 <- lm(y ~ ns(x, 4), data = sim5)
mod5 <- lm(y ~ ns(x, 5), data = sim5)

grid <- sim5 %>% 
  data_grid(x = seq_range(x, n = 50, expand = 0.1)) %>% 
  gather_predictions(mod1, mod2, mod3, mod4, mod5, .pred = "y")

ggplot(sim5, aes(x, y)) + 
  geom_point() +
  geom_line(data = grid, colour = "red") +
  facet_wrap(~ model)
```

По графикку остатков, косвенно можно заключить, что модель 5 лучше остальных справляется с предсказанием.

```{r}
grid2 <- sim5 %>% 
  data_grid(x = seq_range(x, n = 50, expand = 0.1))

sim5 <- sim5 %>% 
  gather_residuals(mod1, mod2, mod3, mod4, mod5)

ggplot(sim5, aes(x, resid, color = model)) + 
  geom_point() + 
  facet_grid(model ~ .)
```

Обратите внимание на явно низкую точность экстраполяции за пределами набора данных. Таков недостаток аппроксимации с помощью полиномов.
ОДнако это становится реальной проблемой для всех моделей: ни одна модель не позволяет судить о том, будет ли найденное поведение истинным при экстраполяции за пределы видимых данных. В подобном случае нужно полагаться на выводы научной теории.


#### Упражнение 23.4.5.1
<div class="question">
What happens if you repeat the analysis of `sim2` using a model without an intercept. 
What happens to the model equation? 
What happens to the predictions?
</div>

Чтобы запустить модель без y-пересечения, добавьте -1 или + 0 к правой части формулы:

```{r}
mod2a <- lm(y ~ x - 1, data = sim2)

mod2 <- lm(y ~ x, data = sim2)
```

Предсказания точно такие же в моделях с и без y-пересечения:

```{r}
grid <- sim2 %>%
  data_grid(x) %>%
  spread_predictions(mod2, mod2a)
grid
```


#### Упражнение 23.4.5.2
<div class="question">
Use `model_matrix()` to explore the equations generated for the models I fit to `sim3` and `sim4`. 
Why is `*` a good shorthand for interaction?
</div>

Для `x1 * x2`, когда `x2` является *категориальной* переменной, создаются индикаторные переменные `x2b`, `x2c`, `x2d` и переменные `x1:x2b`, `x1:x2c` и `x1:x2d`, которые являются произведениями переменных `x1` и `x2`:


```{r}
x3 <- model_matrix(y ~ x1 * x2, data = sim3)
x3
```

Мы можем подтвердить, что переменные `x1:x2b` являются произведением `x1` и `x2b`

```{r}
all(x3[["x1:x2b"]] == (x3[["x1"]] * x3[["x2b"]]))
```

Для `x1 * x2`, где `x1` и `x2` являются *непрерывными* переменными, `model_matrix()` создает переменные `x1`, `x2` и `x1:x2`:

```{r}
x4 <- model_matrix(y ~ x1 * x2, data = sim4)
x4
```

Звездочка `*` является хорошим сокращением для взаимодействия, поскольку взаимодействие между `x1` и `x2` включает в себя слагаемые для `x1`, `x2` и произведение `x1` и `x2`.


#### Упражнение 23.4.5.3
<div class="question">
Using the basic principles, convert the formulas in the following two models into functions. (Hint: start by converting the categorical variable into 0-1 variables.)

```{r}
mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)
```
</div>

Задача состоит в том, чтобы преобразовать формулы в моделях в функции. Я предполагаю, что функция обрабатывает только преобразование правой части формулы в матрицу модели. Функции будут принимать один аргумент - фрейм данных со столбцами `x1` и `x2` и возвращать фрейм данных. Другими словами, функции будут частными случаями функции `model_matrix()`.

Рассмотрим правую часть первой формулы  `~ x1 + x2`. Во фрейме данных `sim3` столбец `x1` представляет собой целое число, а переменная `x2` представляет собой множитель с четырьмя уровнями.

```{r}
levels(sim3$x2)
```

Поскольку `x1` является числовым, оно не изменяется. Поскольку `x2` является фактором, он заменяется столбцами переменных индикатора для всех уровней, кроме одного. Сначала я рассмотрю особый случай, когда `x2` принимает только уровни `x2` в `sim3`. В этом случае `«a»` считается опорным уровнем и опускается, и создаются новые столбцы для `«b»`, `«c»` и `«d»`.

```{r}
model_matrix_mod1 <- function(.data) {
  mutate(.data,
    x2b = as.numeric(x2 == "b"),
    x2c = as.numeric(x2 == "c"),
    x2d = as.numeric(x2 == "d"),
    `(Intercept)` = 1
  ) %>%
    select(`(Intercept)`, x1, x2b, x2c, x2d)
}

model_matrix_mod1(sim3)
```

Более общая функция для `~ x1 + x2` не будет жестко кодировать конкретные уровни в `x2`.

```{r}
model_matrix_mod1b <- function(.data) {
  # уровни x2
  lvls <- levels(.data$x2)
  # отбросим первый уровень
  # this assumes that there are at least two levels
  lvls <- lvls[2:length(lvls)]
  # create an indicator variable for each level of x2
  for (lvl in lvls) {
    # new column name x2 + level name
    varname <- str_c("x2", lvl)
    # add indicator variable for lvl
    .data[[varname]] <- as.numeric(.data$x2 == lvl)
  }
  # generate the list of variables to keep
  x2_variables <- str_c("x2", lvls)
  # Add an intercept
  .data[["(Intercept)"]] <- 1
  # keep x1 and x2 indicator variables
  select(.data, `(Intercept)`, x1, one_of(x2_variables))
}

model_matrix_mod1b(sim3)

```

Рассмотрим правую часть первой формулы `~ x1 * x2`. Фрейм выходных данных будет состоять из `x1`, столбцов с переменными индикатора для каждого уровня (кроме контрольного уровня) `x2` и столбцов с переменными индикатора `x2`, умноженными на `x1.`

Как и в предыдущей формуле, сначала я напишу функцию, которая жестко кодирует уровни `x2`.

```{r}
model_matrix_mod2 <- function(.data) {
  mutate(.data,
    `(Intercept)` = 1,
    x2b = as.numeric(x2 == "b"),
    x2c = as.numeric(x2 == "c"),
    x2d = as.numeric(x2 == "d"),
    `x1:x2b` = x1 * x2b,
    `x1:x2c` = x1 * x2c,
    `x1:x2d` = x1 * x2d
  ) %>%
    select(`(Intercept)`, x1, x2b, x2c, x2d, `x1:x2b`, `x1:x2c`, `x1:x2d`)
}

model_matrix_mod2(sim3)
```

Для более общей функции, которая будет обрабатывать произвольные уровни в `x2`, я расширю функцию `model_matrix_mod1b()`, которую я написал ранее.

```{r}
model_matrix_mod2b <- function(.data) {
  # get dataset with x1 and x2 indicator variables
  out <- model_matrix_mod1b(.data)
  # get names of the x2 indicator columns
  x2cols <- str_subset(colnames(out), "^x2")
  # create interactions between x1 and the x2 indicator columns
  for (varname in x2cols) {
    # name of the interaction variable
    newvar <- str_c("x1:", varname)
    out[[newvar]] <- out$x1 * out[[varname]]
  }
  out
}

model_matrix_mod2b(sim3)
```

Эти функции могут быть дополнительно обобщены, чтобы `x1` и `x2` могли быть либо числовыми, либо факторами. Однако, обобщив намного больше, мы скоро начнем переопределять все функции `matrix_model()`.

#### Упражнение 23.4.5.4
<div class="question">
For `sim4`, which of `mod1` and `mod2` is better? 
I think `mod2` does a slightly better job at removing patterns, but it’s pretty subtle. Can you come up with a plot to support my claim?
</div>

Оценим модели `mod1` и `mod2` на `sim4`,

```{r}
mod1 <- lm(y ~ x1 + x2, data = sim4)
mod2 <- lm(y ~ x1 * x2, data = sim4)
```

Добавим остатки

```{r}
sim4_mods <- gather_residuals(sim4, mod1, mod2)
```

Построим график частот для остатков обеих моделей

```{r}
ggplot(sim4_mods, aes(x = resid, colour = model)) +
  geom_freqpoly(binwidth = 0.5) +
  geom_rug()
```

ПОстроим абсолютные значения остатков

```{r}
ggplot(sim4_mods, aes(x = abs(resid), colour = model)) +
  geom_freqpoly(binwidth = 0.5) +
  geom_rug()
```

не показывает большой разницы в остатках между моделями. Тем не менее, у mod2, по-видимому, меньше остатков в хвостах распределения между 2,5 и 5 (хотя самые крайние остатки относятся к mod2.

Это подтверждается проверкой стандартного отклонения от остатков этих моделей,

```{r}
sim4_mods %>%
  group_by(model) %>%
  summarise(resid = sd(resid))
```

Стандартное отклонение остатков mod2, меньше, чем отклонение mod1

### Отсутствующие значения

Моделирующие функции будут пропускать любые строки, которые содержат missing values.
По умолчанию, об этом не выводится никаких сообщений об ошибке.
Можно вывести добавочной функцией

```{r}
options(na.action = na.warn)
```


```{r}
df <- tribble(
  ~x, ~y,
  1, 2.2,
  2, NA,
  3, 3.5,
  4, 8.3,
  NA, 10
)

mod <- lm(y ~ x, data = df)
```


Для того чтобы подавить вывод сообщений нужно установить 

```{r}
options(na.action = na.exclude)
```

```{r}
mod <- lm(y ~ x, data = df, na.action = na.exclude)
```

Для того чтобы узнать сколько наблюдений было использовано

```{r}
nobs(mod)
```

### Другие семейства моделей

В главе выше мы заострили внимание на классе линейный моделей `y = a_1 * x1 + a_2 * x2 + ... + a_n * xn`.
В случае линейныз моделей дополнительно предполагается что остатки характеризуются нормальным распределением, которое мы ещё не обсуждали.

Существует большое разнообразие классов моделей.

* *Обобщённые линейные модели* --- например `stats::glm()`. В линейных моделях предполагается, что отклик является непрерывным, а ошибки подчиняются нормальному распределению. ОЛМ расширяют линейные модели, дополнительно включая возможность отклика, не являющегося непрерывным (например, двоичные данные или счётчики). Их работа базируется на определении меры расстояния, основанной на статистической идее правдоподобия

* *Обобщенные аддитивные модели* --- например `mgcv::gam()`, расширяет обобщенные линейные модели для включения произвольных гладких функций. Это означает, что вы можете написать формулу, подобную `y ~ s(x)`, которая станет уравнением, подобным `y = f (x)`, и позволить `gam()` оценить, что это за функция (с учетом некоторых ограничений гладкости, чтобы сделать задачу решаемой).

* *Линейные модели со штрафом*, например `glmnet::glmnet()`, добавляют штрафной член к расстоянию, которое штрафует сложные модели (как определено расстоянием между вектором параметра и источником). Это приводит к тому, что модели лучше обобщаются на новые наборы данных из той же совокупности.

* *Робастные линейные модели*, например `MASS:rlm()`, корректирует расстояние до точек с пониженным весом, которые находятся очень далеко. Это делает их менее чувствительными к наличию выбросов, за счет того, что они не так хороши, когда нет выбросов.

* *Деревья*, например `rpart::rpart()`, работают совершенно иначе, чем линейные модели. Они используют кусочно-постоянную модель, разбивая данные на постепенно все меньшие и меньшие части. Деревья не очень эффективны сами по себе, но они очень мощны, когда используются в совокупности с такими моделями, как случайные леса (например, `randomForest::randomForest()`) или машины градиентного бустинга (например, `xgboost::xgboost`.)


Ещё немного моделей

* <http://www-bcf.usc.edu/~gareth/ISL/>

* <http://project-mosaic-books.com>

* <http://appliedpredictivemodeling.com>

* <https://web.stanford.edu/~hastie/Papers/ESLII.pdf>

<!--chapter:end:18_modelr.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Создание модели
### Введение

В прошлой главе были искусственные данные, сейчас поработаем на реальных.

Порядок будет такой --- мы будем обнаруживать тенденции посредством визуализации, а затем конкретизировать и уточнять из с помощью модели.
Затем мы повторим процесс, но заменим старую пременную отклика остатками, опеределённой модели.

Нашей целью является переход от неявных знаний, содержащихся в данных и наших головах, к явным знаниям, содержащимся в количественной модели. Это облешчит их применение в новых областях и использование другими людьми.

Нужно уметь вовремя остановится

Давным-давно на уроке рисования мой учитель сказал мне: «Художник должен знать, когда произведение готово. Вы не можете что-то настроить в совершенстве - заверните это. Если вам это не нравится, сделайте это снова. В противном случае начните что-то новое ». Позже я услышал: «Бедная швея делает много ошибок. Хорошая швея усердно работает над исправлением этих ошибок. Великая швея не боится выбросить одежду и начать все сначала ».

<https://www.reddit.com/r/datascience/comments/4irajq>

#### Необходимые ресурсы

```{r}
library(tidyverse)
library(modelr)
options(na.action = na.warn)

library(nycflights13)
library(lubridate)
```

### Почему бриллианты низкого качества оказались более дорогими

В предыдущих главах мы наблюдали необычное соотношение между качеством бриллиантов и их ценой.
Бриллианты низкого качества, плохая огранка, неудачный цвет, и худшая чистота стоят дороже

```{r}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
ggplot(diamonds, aes(color, price)) + geom_boxplot()
ggplot(diamonds, aes(clarity, price)) + geom_boxplot()
```

Худший цвет бриллианта --- J
Худший класс чистоты --- I1


#### Цена и вес

Похоже, цена низкокачественных бриллиантов оказалась выше из-за одной важной переменной --- `carat` (вес в каратах).
Вес бриллианта --- единственно важный фактор, для определения его цены. А низкокачественные бриллианты имеют как правило большие размеры

```{r}
ggplot(diamonds, aes(carat, price)) + 
  geom_hex(bins = 50)
```

Нам будет проще увидеть, как другие атрибуты бриллианта влияют на его относительную цену, если мы построим модель, отделяющую эффект прпеменной карат. Но сначала немного подправим набор данных, чтобы с ним легче было работать

1. Сфокусируемся на бриллиантах весом меньше 2.5 карата (99,7 данных)

2. Перейдём к логарифмам переменных карат и прайс

```{r}
diamonds2 <- diamonds %>% 
  filter(carat <= 2.5) %>% 
  mutate(lprice = log2(price), lcarat = log2(carat))
```

Совместное внесение этих изменений упрощает выявление взаимосвязи переменных карат и прайс

```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_hex(bins = 50)
```

В данном случае логарифмическое преобразование особенно удобно, посколько оно линеаризует шаблон, а с линейными шаблонами легче работать.

Сделем еще один шаг и исключим эту ярко выраженную линейную тенденцию. Сначала мы явно создаём шаблон путём построения модели

```{r}
mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)
```

Затем мы смотрим что говорит о данных эта модель. Мы выполняем обратное преобразование предсказаний отменяя логарифмическое преобразование, чтобы предсказания можно было наложить на исходные данные

```{r}
grid <- diamonds2 %>% 
  data_grid(carat = seq_range(carat, 20)) %>% 
  mutate(lcarat = log2(carat)) %>% 
  add_predictions(mod_diamond, "lprice") %>% 
  mutate(price = 2 ^ lprice)

ggplot(diamonds2, aes(carat, price)) + 
  geom_hex(bins = 50) + 
  geom_line(data = grid, colour = "red", size = 1)
```

В результате получаем интересную информацию о данных. Если мы долверяем нашей модели, то большие бриллианты намного дешевле, мем можно было ожидать. Вероятно это объясняется тем, что ни один бриллиант в данном наборе не стоит более 19000 долларов.

Рассмотрение остатков подтверждает, что мы успешно исключили ярковыраженный линейный шаблон. На графике сплошное облако шума.

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) + 
  geom_hex(bins = 50)
```

Важно что теперь мы можем заново построить наши мотивирующие графики используя остатки, вместо переменной прайс

```{r}
ggplot(diamonds2, aes(cut, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(color, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(clarity, lresid)) + geom_boxplot()
```

Теперь мы видим ожидаемую взаимосвязь --- по мере улучшения качества бриллиантов растёт их относительная цена.
 Для интерпретации оси игрее необходимо подумать о том, о чем на говорят остатки и по какой шкале они измеряются.
 
 Остаток -1 указывает на то, что переменная `lprice`была на единицу ниже предсказанного значения, если основываться на его весе. $2^{-1}$ равно $\frac{1}{2}$ поэтому точка со значением -1 соответствует половине ожидаемой цены. А остатки со значением 1 соответствуют двойной предсказанной цене.
 
### Более сложная модель

При желании можно достраивть модель, усложняя её имеющимися параметрами

```{r}
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)
```

Теперь модель включает 4 предиктора и её труднее визуализировать. К счастью, к настоящему моменту все они независимы, а это означает что мы можем отобразить их по отдельности на 3 графиках.

```{r}
grid <- diamonds2 %>% 
  data_grid(cut, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
grid

ggplot(grid, aes(cut, pred)) + 
  geom_point()
```

Если модель нуждается в переменных, которые вы не продоставили ей явно, функция `data_grid()` автоматически заполнит их типичными значениям. Для непрерывных переенных она использует медиану, а для категориальных --- моду. 

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) + 
  geom_hex(bins = 50)
```

Этот график указывает на то, что имеюбтся бриллианты с довольно большими остатками --- вспомните о том, что остаток 2 означет 4-кратное превышение цены по сравнению с ожидаемой. Часто целесообразно рассматривать необчные значения по отдельности

```{r}
diamonds2 %>% 
  filter(abs(lresid2) > 1) %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(pred = round(2 ^ pred)) %>% 
  select(price, pred, carat:table, x:z) %>% 
  arrange(price)
```

В данном случае мы не находим ничего необычного, но вероятно стоило потратить какое-то время на выяснение того, не указывает ли это на возможноые проблемы с нашей моделью или на наличие ошибок в данных. В случае существования ошибок в данных это могло бы обернуться счастливыой возможностью купить бриллианты по неоправданно заниженной цене. Сила в данных

#### Упражнение 24.2.3.1
<div class="question">
In the plot of `lcarat` vs. `lprice`, there are some bright vertical strips. What do they represent?
</div>


```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_point()
```

Распределение алмазов имеет больше алмазов в круглых или дружественных для человека числах (дроби).


#### Упражнение 24.2.3.2
<div class="question">
If `log(price) = a_0 + a_1 * log(carat)`, what does that say about the relationship between price and carat?
</div>

Переведём исходное выражение в привычную математическую запись. Цену `price` я запишу как $y$, а караты `carat` как $x$

$$\log_b y = a_0 + a_1\log_b x$$

Сравним между собой отношение двух исходных выражений. Мы хотим понять, как изменяется отношение $y$ при изменении $x$. 

$$\log_b y_1 = a_0 + a_1\log_b x_1$$
$$\log_b y_2 = a_0 + a_1\log_b x_2$$
$$\log_b (y_2) - \log_b (y_1) = (a_0 + a_1\log_b x_2) - (a_0 + a_1\log_b x_1)$$
$$\log_b(\frac{y_2}{y_1}) = \log_b(\frac{x_2}{x_1})^{a_1}$$

$$\frac{y_2}{y_1} = (\frac{x_2}{x_1})^{a_1}$$

Собственно это и будет решением.

#### Упражнение 24.2.3.3
<div class="question">
Extract the diamonds that have very high and very low residuals. Is there anything unusual about these diamonds? Are the particularly bad or good, or do you think these are pricing errors?
</div>

Я буду искать подозрительные остатки, по предложенному Тьюки способу —-- буду считать выбросом, значение отклоняющиеся от квартилей на полтора размаха. 

```{r}
left <- diamonds2 %>% 
  filter(lresid2 <= quantile(lresid2,0.25) - 1.5*(quantile(lresid2,0.75) - quantile(lresid2,0.25)))

right <- diamonds2 %>% 
  filter(lresid2 >= quantile(lresid2,0.75) + 1.5*(quantile(lresid2,0.75) - quantile(lresid2,0.25)))

outliers_lresid2 <- rbind(left, right)
```

Теперь давайте визуализируем ч


```{r}
diamonds2 %>%
  ggplot(aes(cut, lresid2)) +
  geom_boxplot()
```

Вроде бы ничего подозрительного нет. 
Выбросы равномерно распределены, относительно качества огранки.
Наблюдается некая тенденция, что большая часть выбросов лижит в пределах от -1 до 1

Но давайте взглянем на остатки поближе.


```{r}
outliers_lresid2 %>%
  ggplot(aes(lresid2, color = cut)) +
  geom_freqpoly(binwidth = 0.1) + 
  facet_grid(cut~.)

outliers_lresid2 %>%
  ggplot(aes(lresid2, color = color)) +
  geom_freqpoly(binwidth = 0.1) + 
  facet_grid(color~.)

outliers_lresid2 %>%
  ggplot(aes(lresid2, color = clarity)) +
  geom_freqpoly(binwidth = 0.1) + 
  facet_grid(clarity~.)
```

Основная масса выбросов приходится на значения плюс-минус 0.5.
Практически в одинаковой мере попадаются плохие и хорошие. 
Заметно чаще эти ошибки встречаются в более дорогих алмазах.
Можно предположить, что цена искусственно завышена-занижена.

#### Упражнение 24.2.3.4
<div class="question">
Does the final model, `mod_diamond2`, do a good job of predicting diamond prices? 
Would you trust it to tell you how much to spend if you were buying a diamond?
</div>

```{r}
summary(mod_diamond2)
```

Adjusted R-squared имеет значение 0.9828.
Это очень хороший результат. Возьмём теперь предсказанные значение логарифма цены.

```{r}
diamonds2$predict <- predict(object = mod_diamond2)
```

Сравним предсказания, с реальной ценой. Я введу новую переменную, которая показывает во сколько раз предсказание отличается от реальной цены

```{r}
diamonds2 <- diamonds2 %>% 
  mutate(result = 1 - (predict / lprice))

diamonds2 %>% 
  ggplot(aes(cut, result)) +
  geom_boxplot()

mean(abs(diamonds2$result))
max(abs(diamonds2$result))
```

То есть средняя ошибка модели это 1%.
Я бы доверился такой модели перед покупкой

### Что влияет на количество ежедневных авиарейсов

Это небольшой набло данных, в нём 365 строк и 2 столбца.
Мы не будем доводить процесс до полностью реализованной модели, но каждый наш шаг будет способствовать лучшему опниманию данных.

Начнём с количества авиарейсов за день и визуализируем данные

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  group_by(date) %>% 
  summarise(n = n())
```


```{r}
ggplot(daily, aes(date, n)) +
  geom_line()
```

#### День недели

Выявления долгосрочных тенденций --- непростая задача из-за наличия сильного эффекта для недели, который доминирует над более слабыми тенденциями. Начнём с рассмортения распределения количества авиварейсов по дням недели.

```{r}
daily <- daily %>% 
  mutate(wday = wday(date, label = T))

ggplot(daily, aes(wday, n)) +
  geom_boxplot()
```

В выходные дни полётов меньше, поскольку большинство путешествуют в деловых целях. Этот эффект особенно выражен по субботам: иногда вы можете вылететь в вс, чтобы успеть на встречу, которая назначена на утро понедельника, но очень редко выбереть для вылета субботу, поскольку предпочтете провести это время с домашними.

Один из способов исключения этой сильной тенденции --- использовать модель. Сначала мы строим модель и отображаем её предсказания поверх исходных данных.

```{r}
mod <- lm(n ~ wday, data = daily)

grid <- daily %>% 
  data_grid(wday) %>% 
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, color = "red")
```

Затем вычисляем, и визуализируем остатки

```{r}
daily <- daily %>% 
  add_residuals(mod)

daily %>% 
  ggplot(aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line()
```

Обращаем внимание на изменени смысла оси `y` --- теперь вдоль неё откладываются отклонения количества полётов от ожидаемого для разных дней недели. Этот график весьма полезен, поскольку теперь, когда из него исключена значительная часть сильного эффекта дня недели, мы можем видеть некоторые слабые оставшиеся тендеции

* По видимому, начиная с июня, наша модель работает плохо --- вы по-прежнему можете наблюдать сильный регулярный шаблон, который модели не удалось захватить. Вычерчивание графика с использованием отдельных линий для каждого дня недели позволяет лучше это увидеть

```{r}
ggplot(daily, aes(date, resid, colour = wday)) + 
  geom_ref_line(h = 0) + 
  geom_line()
```

Нашей модели не удаётся точно предсказать количество авиарейсов по субботам --- летом колчиество полетов превышает ожидаемое значение, а осенью оно ниже ожидаемого значения. В следующем разделе будет показано, каким образом можно улучшить захват этого шаблона.

* Для некоторых дней количество рейсов значительно превышает ожидаемое значение

```{r}
daily %>% 
  filter(resid < -100)
```

Заметно, что часть дней выпадают на праздники

* Очевидно существование гладкого долгосрочного тренда на протяжении года. Этот тренд можно выделить с помощью функции 

```{r}
daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line(colour = "grey50") + 
  geom_smooth(se = FALSE, span = 0.20)
```

В январе (и декабре) меньше рейсов, а летом больше (май-сентябрь). Мы не можем сделать много с этой моделью количественно, потому что у нас есть только один год данных. Но мы можем использовать наши знания предметной области для мозгового штурма потенциальных объяснений.

#### Сезонный субботний эффект

Давайте сначала рассмотрим нашу неспособность точно предсказать количество рейсов в субботу. Хорошее место для начала - вернуться к необработанным числам, сосредоточившись на субботах:

```{r}
daily %>% 
  filter(wday == "Сб") %>% 
  ggplot(aes(date, n)) + 
    geom_point() + 
    geom_line() +
    scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

Я подозреваю, что эта закономерность вызвана летними каникулами: многие люди уезжают в отпуск летом, и люди не против путешествовать по субботам в отпуск. Глядя на этот график, можно догадаться, что летние каникулы идут с начала июня до конца августа. Похоже, это очень хорошо согласуется со школьными условиями штата: летний отпуск в 2013 году был 26 июня - 9 сентября.


Давайте создадим переменную «term», которая приблизительно охватывает три школьных термина, и проверим нашу работу с помощью графика:

```{r}
term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("весна", "лето", "осень") 
  )
}

daily <- daily %>% 
  mutate(term = term(date)) 

daily %>% 
  filter(wday == "Сб") %>% 
  ggplot(aes(date, n, colour = term)) +
  geom_point(alpha = 1/3) + 
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```


(Я вручную подправил даты, чтобы получить хорошие перерывы в сюжете. Использование визуализации, чтобы помочь вам понять, что делает ваша функция, является действительно мощной и общей техникой.)

Полезно посмотреть, как эта новая переменная влияет на другие дни недели:

```{r}
daily %>% 
  ggplot(aes(wday, n, colour = term)) +
    geom_boxplot()
```

Похоже, что есть существенные различия между временами года, поэтому целесообразно использовать отдельный эффект дня недели для каждого. Это улучшает нашу модель, но не настолько, как мы могли бы надеяться:

```{r}
mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>% 
  gather_residuals(without_term = mod1, with_term = mod2) %>% 
  ggplot(aes(date, resid, colour = model)) +
    geom_line(alpha = 0.75)
```

Мы можем увидеть проблему, наложив прогнозы из модели на необработанные данные:

```{r}
grid <- daily %>% 
  data_grid(wday, term) %>% 
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, colour = "red") + 
  facet_wrap(~ term)
```

Наша модель находит среднее значение, но у нас есть много больших отклонений, поэтому среднее значение, как правило, далеко от типичного значения. Мы можем решить эту проблему, используя модель, устойчивую к воздействию выбросов: `MASS::rlm()`. Это значительно уменьшает влияние выбросов на наши оценки и дает модель, которая хорошо справляется с удалением модели дня недели:

```{r}
mod3 <- MASS::rlm(n ~ wday * term, data = daily)

daily %>% 
  add_residuals(mod3, "resid") %>% 
  ggplot(aes(date, resid)) + 
  geom_hline(yintercept = 0, size = 2, colour = "white") + 
  geom_line()
```

Теперь намного легче увидеть долгосрочную тенденцию, а также положительные и отрицательные выбросы.

#### Вычисляемые переменные

Если вы экспериментируете со многими моделями и множеством визуализаций, было бы неплохо объединить создание переменных в функцию, чтобы не было возможности случайно применить другое преобразование в разных местах. Например, мы могли бы написать:

```{r}
compute_vars <- function(data) {
  data %>% 
    mutate(
      term = term(date), 
      wday = wday(date, label = TRUE)
    )
}
```

Другой вариант - поместить преобразования непосредственно в формулу модели:

```{r}
wday2 <- function(x) wday(x, label = TRUE)
mod3 <- lm(n ~ wday2(date) * term(date), data = daily)
```

Любой подход является разумным. Делаnm преобразованную переменную явной, полезно, если вы хотите проверить свою работу или использовать их в визуализации. Но вы не можете легко использовать преобразования (например, конвейеры), которые возвращают несколько столбцов. Включение преобразований в функцию модели немного облегчает жизнь, когда вы работаете со многими различными наборами данных, потому что модель самодостаточна.

#### Время года: альтернативный подход

В предыдущем разделе мы использовали наши знания предметной области (как термин «школа» в США влияет на поездки), чтобы улучшить модель. Альтернатива прямому использованию наших знаний в модели - предоставить данным больше пространства для разговора. Мы могли бы использовать более гибкую модель и позволить ей охватить интересующий нас паттерн. Простой линейный тренд не является адекватным, поэтому мы могли бы попытаться использовать естественный сплайн, чтобы соответствовать плавной кривой в течение года:

```{r}
library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily)

daily %>% 
  data_grid(wday, date = seq_range(date, n = 13)) %>% 
  add_predictions(mod) %>% 
  ggplot(aes(date, pred, colour = wday)) + 
    geom_line() +
    geom_point()
```

Мы видим сильную закономерность в количестве субботних рейсов. Это обнадеживает, потому что мы также видели этот шаблон в необработанных данных. Это хороший знак, когда вы получаете один и тот же сигнал с разных подходов.

#### Упражнение 24.3.5.1
<div class="question">
Use your Google sleuthing skills to brainstorm why there were fewer than expected flights on Jan 20, May 26, and Sep 1. (Hint: they all have the same explanation.) How would these days generalise to another year?
</div>

Это воскресенье перед выходными в понедельник, День Мартина Лютера Кинга-младшего, День памяти и День труда. Для других лет используйте даты выходных для этих лет: третий понедельник января для Мартина Лютера Кинга-младшего, последний понедельник мая для Дня памяти и первый понедельник сентября для Дня труда.

#### Упражнение 24.3.5.2
<div class="question">
What do the three days with high positive residuals represent? How would these days generalize to another year?
</div>

```{r}
daily %>% 
  top_n(3, resid)
```

Три верхних дня соответствуют субботе после Дня благодарения (30 ноября), воскресенью после Дня благодарения (1 декабря) и субботе после Рождества (28 декабря). Мы могли бы обобщить их на другие годы, используя даты этих праздников тех лет.

#### Упражнение 24.3.5.3
<div class="question">
Create a new variable that splits the `wday` variable into terms, but only for Saturdays, i.e. it should have `Thurs`, `Fri`, but `Sat-summer`, `Sat-spring`, `Sat-fall`. How does this model compare with the model with every combination of `wday` and `term`?
</div>

```{r}
daily <- daily  %>% 
  mutate(splitted_day = 
           ifelse(wday == "Сб", paste0(wday, "-", term), as.character(wday)))

mod4 <- lm(n ~ splitted_day, data = daily)

daily %>%
  gather_residuals(sat_term = mod4, all_interact = mod2) %>%
  ggplot(aes(date, resid, color = model)) +
  geom_line() +
  facet_grid(model~.)
```

Посмотрим на разницы остатков.

```{r}
daily %>%
  spread_residuals(sat_term = mod4, all_interact = mod2) %>%
  mutate(resid_diff = sat_term - all_interact) %>%
  ggplot(aes(date, resid_diff)) +
  geom_line()
```

Получаем, что модифицифрованная модель (Сб-весна) имеет более высокие остатки летом и более низкие остатки весной. При этом осенью остатки более менее одинаковы.

#### Упражнение 24.3.5.4
<div class="question">
Create a new `wday` variable that combines the day of week, term (for Saturdays), and public holidays. What do the residuals of that model look like?
</div>

Итак, погуглив, находим общенациональные американские праздники.
Создадим переменную, в которую положим все эти праздники

```{r}
holidays_2013 <-
  tribble(
    ~holiday, ~date,
    "New Year's Day", 20130101,
    "Martin Luther King Jr. Day", 20130121,
    "Washington's Birthday", 20130218,
    "Memorial Day", 20130527,
    "Independence Day", 20130704,
    "Labor Day", 20130902,
    "Columbus Day", 20131028,
    "Veteran's Day", 20131111,
    "Thanksgiving", 20131128,
    "Christmas", 20131225
  ) %>%
  mutate(date = lubridate::ymd(date))
```

Добавим, для интереса, ещё и дни до и после праздников.
Потому что по собственному опыту скажу, что чаще всего, я вылетаю на праздники в день до наступления праздника. Точнее вечером после работы, чтобы побольше побыть с родными или друзьями.

```{r}
daily <- daily %>%
  mutate(
    wday3 =
      case_when(
        date %in% (holidays_2013$date - 1L) ~ "день до праздника",
        date %in% (holidays_2013$date + 1L) ~ "день после праздника",
        date %in% holidays_2013$date ~ "праздник",
        .$wday == "сб" & .$term == "лето" ~ "сб-лето",
        .$wday == "сб" & .$term == "осень" ~ "сб-осень",
        .$wday == "сб" & .$term == "spring" ~ "сб-весн",
        TRUE ~ as.character(.$wday)
      )
  )
```

Теперь построим модель, которая будет учитывать не только сезонность суббот, но и включенные праздники.

```{r}
mod5 <- lm(n ~ wday3, data = daily)

daily %>%
  spread_residuals(resid_sat_terms = mod4, resid_holidays = mod5) %>%
  mutate(resid_diff = resid_holidays - resid_sat_terms) %>%
  ggplot(aes(date, resid_diff)) +
  geom_line(alpha = 0.75)
```

Как видно на графике, модель довольно точно определяет даты, очень похожие на введёные нами праздники и дни до и после праздников.

```{r}
daily %>%
  spread_residuals(resid_sat_terms = mod4, resid_holidays = mod5) %>%
  mutate(resid_diff = resid_holidays - resid_sat_terms) %>% 
  filter(resid_diff > 50)
```


#### Упражнение 24.3.5.5
<div class="question">
What happens if you fit a day of week effect that varies by month (i.e., n ~ wday * month)? Why is this not very helpful?
</div>

Добавим новую переменную, которая определяет месяц

```{r}
daily <- daily %>% 
  mutate(month = factor(month(date)))
```


```{r}
mod6 <- lm(n ~ wday*month, data = daily)

daily <- daily %>% 
  add_residuals(mod6)

daily %>% 
  ggplot(aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line()
```

Как видим, эта модель не эффективна, поскольку не ловит большие отклонения.
Если м ы посмотрим, на то из чего состоит модель, то увидим что в модели будет 12 * 7 = 84 параметра. Поскольку у каждого месяца есть только четыре-пять недель, каждый из этих дней недели × месяц - это в среднем только четыре или пять наблюдений. Эти оценки имеют большие стандартные ошибки и, вероятно, не обобщаются далеко за пределы выборочных данных, поскольку они оцениваются только из нескольких наблюдений.

```{r}
summary(mod6)
```

#### Упражнение 24.3.5.6
<div class="question">
What would you expect the model `n ~ wday + ns(date, 5)` to look like?
Knowing what you know about the data, why would you expect it to be not particularly effective?
</div>

Предыдущие модели вписываются в главу, и упражнения показывают, что влияние дней недели меняется в зависимости от времени года. Модель в этом упражнении не взаимодействует с эффектом дня недели и со временем года.

```{r}
mod7 <- lm(n ~ wday + ns(date, 5), data = daily)
mod8 <- lm(n ~ wday * ns(date, 5), data = daily)
```

Остатки модели, которая не взаимодействует со днём недели со временем года (mod7), больше, чем остатки модели, которая взаимодействует (mod8). Модель mod7 недооценивает выходные летом и переоценивает выходные осенью.

```{r}
daily %>%
  gather_residuals(mod7, mod8) %>%
  ggplot(aes(x = date, y = resid, color = model)) +
  geom_line(alpha = 0.75)
```

#### Упражнение 24.3.5.7
<div class="question">
We hypothesized that people leaving on Sundays are more likely to be business travelers who need to be somewhere on Monday. Explore that hypothesis by seeing how it breaks down based on distance and time: if it’s true, you’d expect to see more Sunday evening flights to places that are far away.
</div>

Сравнивая средние расстояния рейсов по дням недели, воскресные рейсы занимают второе место по длине. Субботние рейсы самые длинные в среднем. В субботу могут быть самые длинные рейсы в среднем, потому что на выходные меньше регулярных регулярных рейсов бизнес / пригородных рейсов, но это предположение.

```{r}
flights %>%
  mutate(
    date = make_date(year, month, day),
    wday = wday(date, label = TRUE)
  ) %>%
  ggplot(aes(y = distance, x = wday)) +
  geom_boxplot()
```

Построим средние дистанции и величины стандартного.
Используем функцию из упражнения ниже, чтобы поставить понедельник не первое место.

```{r}
relevel <- function(x) {
  fct_relevel(x, levels(x)[-1])
}
```


```{r}
flights %>%
  mutate(
    date = make_date(year, month, day),
    wday = wday(date, label = TRUE)
  ) %>%
  ggplot(aes(y = distance, x = relevel(wday))) +
  stat_summary()
```

В субботу в среднем летают на большие дистанции. 


Необходимо продолжить исследование.


#### Упражнение 24.3.5.8
<div class="question">
It’s a little frustrating that Sunday and Saturday are on separate ends of the plot. Write a small function to set the levels of the factor so that the week starts on Monday.
</div>

Используем релевел

```{r}
relevel <- function(x) {
  fct_relevel(x, levels(x)[-1])
}
```

Вуаля, понедельник первый

```{r}
daily <- daily %>%
  mutate(wday = wday(date, label = TRUE))


ggplot(daily, aes(relevel(wday), n)) +
  geom_boxplot() +
  labs(x = "День недели", y = "Число полётов")
```

### Больше о моделях

Тут ссылки на ещё информацию о моделях


* *Statistical Modeling: A Fresh Approach* by Danny Kaplan,
  <http://www.mosaic-web.org/go/StatisticalModeling/>. This book provides 
  a gentle introduction to modelling, where you build your intuition,
  mathematical tools, and R skills in parallel. The book replaces a traditional
  "introduction to statistics" course, providing a curriculum that is up-to-date 
  and relevant to data science.

* *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, 
  Trevor Hastie, and Robert Tibshirani, <http://www-bcf.usc.edu/~gareth/ISL/> 
  (available online for free). This book presents a family of modern modelling
  techniques collectively known as statistical learning.  For an even deeper
  understanding of the math behind the models, read the classic 
  *Elements of Statistical Learning* by Trevor Hastie, Robert Tibshirani, and
  Jerome Friedman, <https://web.stanford.edu/~hastie/Papers/ESLII.pdf> (also
  available online for free).

* *Applied Predictive Modeling* by Max Kuhn and Kjell Johnson, 
  <http://appliedpredictivemodeling.com>. This book is a companion to the 
  __caret__ package and provides practical tools for dealing with real-life
  predictive modelling challenges.


<!--chapter:end:19_make_models.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Обработка множества моделей с помощью пакетов `purrr` и `broom`
### Введение

Тут советуют не отчаиваться если сразу не получится осмыслить всё то что здесь объясняется.

#### Необходимые ресурсы

```{r, error=TRUE}
library(tidyverse)
library(modelr)
```

### Набор данных `gapminder`

В наборе соз=держится информация об изменении во времени суммарных показателей развития стран мира, рассчитанных на основк таких статистик как средняя продолжительность жизни и ВВП.

```{r, error=TRUE}
library(gapminder)
gapminder
```

В данном примере мы сосредоточим внимание всего лишь на трех переменных и попытаемся ответить на вопрос: "Как изменяется средняя продолжительность жизни `lifeExp` со временем `year` для каждой страны `country`.

```{r, error=TRUE}
gapminder %>% 
  ggplot(aes(year, lifeExp, group = country)) +
  geom_line()
```

Набор хоть и небольшой но тем не менее так сразу и не скажешь что тут происходит.
Один из способов заключается в том, чтобы использовать тот же подход, что и в предыдущей главе: существует один сильный сигнал (общий линейный тренд), который затрудняет наблюдение более слабых трендов.
Мы разведем эти факторы посредством построения модели с линейным трендом.
Эта модель захватит постоянный рост во времени, а остатки покажут, что остается.

Мы знаем как сделать это для одной страны.

```{r, error=TRUE}
nz <- filter(gapminder, country == "New Zealand")

nz %>% 
  ggplot(aes(year, lifeExp)) +
  geom_line() +
  ggtitle("Full data")

nz_mod <- lm(lifeExp ~ year, data = nz)

nz %>% 
  add_predictions(nz_mod) %>% 
  ggplot(aes(year, pred)) +
  geom_line() +
  ggtitle("Linear trend")

nz %>% 
  add_residuals(nz_mod) %>% 
  ggplot(aes(year, resid)) +
  geom_line() +
  ggtitle("Remaining pattern")
```

Теперь посмотрим как строить модель для каждой страны.

#### Вложенные данные

Сделаем вложенные данные

```{r, error=TRUE}
by_country <- gapminder %>% 
  group_by(country, continent) %>% 
  nest()

by_country

by_country <- if (require("gapminder")) {
  gapminder %>%
    group_by(country, continent) %>%
    nest()

  gapminder %>%
    nest(-country, -continent)
}
```

Последняя функция позволяет вложить в тиббл-фрейм ещё один тиббл-фрейм.

Это создает фрейм данных, который имеет одну строку на группу (на страну) и довольно необычный столбец: данные. Данные - это список фреймов данных (или, если быть точным, фрагментов данных). Это кажется сумасшедшей идеей: у нас есть фрейм данных со столбцом, который является списком других фреймов данных! Я вскоре объясню, почему я думаю, что это хорошая идея.

Столбец данных немного сложен, потому что это умеренно сложный список, и мы все еще работаем над хорошими инструментами для изучения этих объектов. К сожалению, использование str () не рекомендуется, так как это часто приводит к очень длинному выводу. Но если вы выделите один элемент из столбца данных, вы увидите, что он содержит все данные для этой страны (в данном случае, Афганистан).

```{r, error=TRUE}
by_country$data[[50]]

by_country <- by_country %>% 
  head(29)
```

Обратите внимание на разницу между стандартным сгруппированным кадром данных и вложенным фреймом данных: в сгруппированном фрейме данных каждая строка является наблюдением; во вложенном фрейме данных каждая строка является группой. Еще один способ думать о вложенном наборе данных - теперь у нас есть мета-наблюдение: строка, представляющая полный временной курс для страны, а не один момент времени.

#### Столбцы-списки

Теперь, когда у нас есть вложенный фрейм данных, мы в состоянии приспособиться к некоторым моделям. У нас есть функция подбора модели:

```{r, error=TRUE}
country_model <- function(df) {
  lm(lifeExp ~ year, data = df)
}
```

И мы хотим применить его к каждому фрейму данных. Фреймы данных находятся в списке, поэтому мы можем использовать `purrr::map()`, чтобы применить `country_model` к каждому элементу:

```{r, error=TRUE}
models <- map(by_country$data, country_model)
```

Однако вместо того, чтобы оставлять список моделей как свободно плавающий объект, я думаю, что лучше хранить его в виде столбца во фрейме данных `by_country`. 
Хранение связанных объектов в столбцах является ключевой частью значения фреймов данных, и поэтому я считаю, что списочные столбцы - это хорошая идея. 
В ходе работы с этими странами у нас будет много списков, в которых у нас будет один элемент на страну. Так почему бы не хранить их все вместе в одном фрейме данных?

Другими словами, вместо создания нового объекта в глобальной среде, мы собираемся создать новую переменную во фрейме данных `by_country`. Это работа для `dplyr::mutate()`:

```{r, error=TRUE}
by_country <- by_country %>% 
  mutate(model = map(data, country_model))
by_country
```

Это имеет большое преимущество: поскольку все связанные объекты хранятся вместе, вам не нужно вручную синхронизировать их при фильтрации или упорядочивании. Семантика фрейма данных позаботится об этом за вас:

```{r, error=TRUE}
by_country %>% 
  filter(continent == "Europe")

by_country %>% 
  arrange(continent, country)
```

Если ваш список фреймов данных и список моделей были отдельными объектами, вы должны помнить, что всякий раз, когда вы переупорядочиваете или поднастраиваете один вектор, вы должны переупорядочивать или подгруппировать все остальные, чтобы синхронизировать их. Если вы забудете, ваш код продолжит работать, но он даст неправильный ответ!

#### Отмена вложенния данных

Вычислим остатки

```{r, error=TRUE}
by_country <- by_country %>% 
  mutate(
    resid = map2(data, model, add_residuals)
  )

by_country
```

Для того чтобы нарисовать всё на одном графике разгруппируем, и приведём всё к виду обычного тиббл-фрейма

```{r, error=TRUE}
resids <- unnest(by_country, resid)
resids
```

Каждый столбец повторяется один раз для каждой строки вложенного столбца.

Теперь, когда у нас есть обычный фрейм данных, построим график остатков

```{r, error=TRUE}
resids %>% 
  ggplot(aes(year, resid)) + 
  geom_line(aes(group = country), alpha = 0.3) +
  geom_smooth(se = FALSE)
```

Добавим чуть-чуть информативности --- отобразим по континентам на разных панелях.

```{r, error=TRUE}
resids %>% 
  ggplot(aes(year, resid)) +
  geom_line(aes(group = country), alpha = 0.3) +
  facet_wrap(~continent)
```

Большие остатки указывают на то, что мы упустили какую-то тенденцию --- наша модель работает не слишком хорошо.

#### Качество модели

Вместо анализа остатков, возникающих в модели, можно рассмотреть екоторые общие меры качества модели.
До этого мы узнали, как вычислять специализированные меры.
Здесь мы будем использовать функцию `broom::glance()` для извлечения качественных метрик модели. Применяя их к модели, мы получаем фрейм данных, состоящих из одной строки.

```{r, error=TRUE}
broom::glance(nz_mod)
```

Создадим фрейм данных с одной строкой для каждой страны.

```{r, error=TRUE}
by_country %>% 
  mutate(glance = map(model, broom::glance)) %>% 
  unnest(glance)
```

Это не совсем тот вывод который нужен, поскольку тут ещё есть столбцы списки.
Таково поведение по-умолчанию. Чтобы отменить это поведение нужно:

```{r, error=TRUE}
glance <- by_country %>% 
  mutate(glance = map(model, broom::glance)) %>% 
  unnest(glance, .drop = TRUE)
```

Имея в своём распоряжении новые данные, мы можем приступить к поиску неудачных моделей.

```{r, error=TRUE}
glance %>% 
  arrange(r.squared)
```

Визуализируем, кому больше всего принадлежат неудачные модели

```{r, error=TRUE}
glance %>% 
  ggplot(aes(continent, r.squared)) +
  geom_jitter(width = 0.4)
```

В большей степени это Африка.

Мы можем отфильтровать данные соответствующие странам, с особо низким коэффициентом детерминации, и отобразить из в виде графика.

```{r, error=TRUE}
bad_fit <- filter(glance, r.squared < 0.25)

gapminder %>% 
  semi_join(bad_fit, by = "country") %>% 
  ggplot(aes(year, lifeExp, color = country)) +
  geom_line()
```

Ну в моём случае это вот так. Но вообще, там стран побольше конечно.

Здесь видно не отчётливо. Но в оригинале выделяются два основных эффекта --- эпидемия СПИД (1999-2002 годы) и геноцид в Руанде.

#### Упражнение 25.2.1
<div class="question">
A linear trend seems to be slightly too simple for the overall trend. Can you do better with a quadratic polynomial? How can you interpret the coefficients of the quadratic? Hint you might want to transform year so that it has mean zero.)
</div>

Квадратичный полином мы можем добавить при помощи функции `poly()`
Преобразуем функцию `country_model` которая дана в учебнике.

```{r, error=TRUE}

country_model <- function(df) {
  lm(lifeExp ~ poly(year - median(year), 2), data = df)
}

by_country <- gapminder %>%
  group_by(country, continent) %>%
  nest()

by_country <- by_country %>% 
  head(29)

by_country <- by_country %>%
  mutate(model = map(data, country_model))

by_country <- by_country %>%
  mutate(
    resids = map2(data, model, add_residuals)
  )


unnest(by_country, resids) %>%
  ggplot(aes(year, resid)) +
  geom_line(aes(group = country), alpha = 1 / 3) +
  geom_smooth(se = FALSE) +
  facet_wrap(~continent)

by_country %>%
  mutate(glance = map(model, broom::glance)) %>%
  unnest(glance, .drop = TRUE) %>%
  ggplot(aes(continent, r.squared)) +
  geom_jitter(width = 0.2)

glance1 <- by_country %>% 
  mutate(glance = map(model, broom::glance)) %>% 
  unnest(glance, .drop = TRUE)

glance1 %>% arrange(r.squared)
```

Как видно, в моём усечённом примере, квадратный полином улучшил модель. 
Показатель коэффициента детерминации уменьшился для стран Африки.

#### Упражнение 25.2.2
<div class="question">
Explore other methods for visualizing the distribution of $R^2$ per continent. You might want to try the ggbeeswarm package, which provides similar methods for avoiding overlaps as jitter, but uses deterministic methods.
</div>

Вот например такой метод

```{r, error=TRUE}
library("ggbeeswarm")
by_country %>%
  mutate(glance = map(model, broom::glance)) %>%
  unnest(glance, .drop = TRUE) %>%
  ggplot(aes(continent, r.squared)) +
  geom_beeswarm()
```

Выглядит несколько приятнее чем `jitter`

```{r, error=TRUE}
by_country %>%
  mutate(glance = map(model, broom::glance)) %>%
  unnest(glance, .drop = TRUE) %>%
  ggplot(aes(continent, r.squared)) +
  geom_quasirandom()
```

А этот почти такой же `jitter`


#### Упражнение 25.2.3
<div class="question">
To create the last plot (showing the data for the countries with the worst model fits), we needed two steps: we created a data frame with one row per country and then semi-joined it to the original dataset. It’s possible to avoid this join if we use `unnest()` instead of `unnest(.drop = TRUE)`. How?
</div>

Для того чтобы избежать объединения, можно дважды раскрыть вложенные столбца списки.

```{r, error=TRUE}
gapminder %>%
  group_by(country, continent) %>%
  nest() %>%
  head(29) %>% 
  mutate(model = map(data, ~ lm(lifeExp ~ year, .))) %>%
  mutate(glance = map(model, broom::glance)) %>%
  unnest(glance) %>%
  unnest(data) %>%
  filter(r.squared < 0.25) %>%
  ggplot(aes(year, lifeExp)) +
  geom_line(aes(color = country))
```

### Столбцы-списки

Авторы книги лишь недавно по достоинству оценили вложенные столбцы-списки.
Эта структура данных неявно фигурирует в определении фрейма данных --- фрейм данных это именованный список векторов равной длинны. 
Список это вектор, поэтому всегда можно было на вполне законных основаниях использовать список в качетсве столбца фрейма данных.
Однако базовые пакеты R не позволяют столе же просто создавать столбцы-списки, и функция `data.frame()` торактует список, как список столбцов.

```{r, error=TRUE}
data.frame(x = list(1:3, 3:5))
```

Такое поведение функции можно предотвратить с помощи функции `I()`, однако при этом результат выводится не в самом удобном виде

```{r, error=TRUE}
data.frame(
  x = I(list(1:3, 3:5)),
  y = c("1, 2", "3, 4, 5")
)
```

Тиббл фрейм позволяет сгладить эту проблему, за счёт того что он более *ленивый* (функция тиббл не изменяет свои входные данные), а так же за счёт того что предоставляет более наглядный метод печати.

```{r, error=TRUE}
tibble(
  x = list(1:3, 3:5),
  y = c("1, 2", "3, 4, 5")
)
```

Но с функцией `tribble()` ещё проще работать, по той причине, что она может автоматически определить, что вам нужен список.

```{r, error=TRUE}
tribble(
  ~x, ~y,
  1:3, "1, 2",
  3:5, "3, 4, 5"
)
```

Стоит понимать, что столбцы списки наиболее полезны в качестве промежуточных структур данных. С ними тяжело работать непосредственно, поскольку большинство функцй имеют дело с атомарными векторами или фреймами данных, но возможность содержать вместе все родственные эдементы в одном фрейме данных стоит дополнительных хлопот.

В общем случае эффективный канал столбцов-списков состоит из трёх частей

  1. ВЫ создаёте столбец-список с помощью одного из следующих вариантов nest()`, `summarise() + list()`,`mutate()` + функция `map` как описано в разделе создания столбцов-списков.
  2. Вы создаёте другие промежуточные столбцы-списки, преобразуя существующие столбцы-списки с помощью функций `map()`, `map2()` или `pmap()`. Так в предыдуущем типовом примере мы создавали столбец --- список моделей путем преобразования столбца --- списка фреймов данных.
  3. Вы упрощаете столбец-список путем его обратного преобразования во фрейм данных или атомарный вектор, как описано в разделе упрощения столбцов-списков.
  
### Создание столбцов-списков

Для создания используется один из трёх методов

  1. `nest()`. Для преобразования сгруппированного фрейма данных во вложненный фрейм, в котором вы имеете столбец --- список фреймов данных.
  2. с помощью `mutate()` и векторизованных функций, возвращающих список
  3. с помощью `summarise()` и `summary()`, которые возвращают несколько резельтатов.
  
Есть ещё альтернативный способ при помощи `tibble::enframe()`

Объекты в столбцах списках должны быть однородны --- каждый элемент должен содержать объекты одного и того же типа.

#### Создание столбцов списков на основе вложений

`nest()` создает вложенный фрейм данных, представляющий собой столбец-список фреймов данных. Во вложенном фрейму данных каждая строка является метанаблюдением: переменные, которые определяют наблюдение, предоставляются другими столбцами, а столбец --- список фреймов данных предоставляет индивидуальные наблюдения, которые образуют метанаблюдение.

Можно использовать двумя способами

```{r, error=TRUE}
gapminder %>% 
  group_by(country, continent) %>% 
  nest()
```

И вот так. Указываем явно, какие столбцы должны быть сгруппированы.

```{r, error=TRUE}
gapminder %>% 
  nest(year:gdpPercap)
```

#### Создание столбцов списков на основе векторизованных функций

Некоторые полезные функции принимают атомарный вектор и возваразают список. Например, функция `stringr::str_split()`, она принимает символьный вектор и возвращает список символьных векторов.

Если использовать этот подход в функции `mutate()`, то получим столбец-список

```{r, error=TRUE}
df <- tribble(
  ~x1,
  "a,b,c", 
  "d,e,f,g"
) 

df %>% 
  mutate(x2 = stringr::str_split(x1, ","))
```

Функция `unnest()` знает как обрабатывать такие списки векторов.

```{r, error=TRUE}
df %>% 
  mutate(x2 = stringr::str_split(x1, ",")) %>% 
  unnest()
```

Есть полезная функция `tidyr::separate_rows()` она является обёрткой для этого полезного шаблона.

Альтернативный вариант этого шаблона предполагает использование функций `map()`, `map2()`, `pmap()`. Например

```{r, error=TRUE}
sim <- tribble(
  ~f,      ~params,
  "runif", list(min = -1, max = 1),
  "rnorm", list(sd = 5),
  "rpois", list(lambda = 10)
)

sim %>%
  mutate(sims = invoke_map(f, params, n = 10))
```

#### Создание столбцов списков на основе многозначных итогов

Одним из ограничений `summarise()` является то, что она работает с итоговыми функциями, возвращающими одиночное значение. Таким образом, ее нельзя использовать с функциями наподобие `quantile()` которые возвращают вектор произвольной длины.

```{r, error=TRUE}
# Ошибка
mtcars %>% 
  group_by(cyl) %>% 
  summarise(q = quantile(mpg))

# > Column `q` must be length 1 (a summary value), not 5
```

Однако этот результат можно свернуть в список

```{r, error=TRUE}
mtcars %>% 
  group_by(cyl) %>% 
  summarise(q = list(quantile(mpg)))
```

Для получения полезных результатов с помощью `unnest()` вам так же понадобится получить вероятности

```{r, error=TRUE}
probs <- c(0.01, 0.25, 0.5, 0.75, 0.99)
mtcars %>% 
  group_by(cyl) %>% 
  summarise(p = list(probs), q = list(quantile(mpg, probs))) %>% 
  unnest()
```

#### Создание столбцов списков на основе именнованных списков

Фрейм данных со столбцами-списками обеспечивают решение одной часто встречающейся задачи:
как быть, если необходимо итерировать как по содержимому списка, так и по его элементам?
Вместо того чтобы пытаться втиснуть всё в один объект, часто гораздо легче создать фрейм данных: один столбец модет содержать элементы, а другой --- список. Простой способ создания такого фрейма данных из списка предлагает функция `tibble::enframe()`

```{r, error=TRUE}
x <- list(
  a = 1:5,
  b = 3:4, 
  c = 5:6
) 

df <- enframe(x)
df
```

Преимущество этой структуры --- она обобщается самым непосредственным образом: имена полезны, если вы имеете дело с символьным вектором метаданных, но в случае других типов данных или нескольких векторов они вам не помогут. 
Теперь, если вы хотите итерировать одновременно по именам и значениям, это можно сделать с помощью `map2`

```{r, error=TRUE}
df %>% 
  mutate(
    smry = map2_chr(name, value, ~ stringr::str_c(.x, ": ", .y[1]))
  )
```

#### Упражнение 25.4.1
<div class="question">
List all the functions that you can think of that take a atomic vector and return a list.
</div>

Многие функции работы со строками принимают атомарный вектор и возвращают список

```{r, error=TRUE}
str_split(sentences[1:3], " ")

str_match_all(c("abc", "aa", "aabaa", "abbbc"), "a+")
```

Функции семейства `map()` выполняют похожие вещи

```{r, error=TRUE}
map(1:3, runif)
```

#### Упражнение 25.4.2
<div class="question">
Brainstorm useful summary functions that, like `quantile()`, return multiple values.
</div>

```{r, error=TRUE}
range(mtcars$mpg)

fivenum(mtcars$mpg)

boxplot.stats(mtcars$mpg)
```

#### Упражнение 25.4.3
<div class="question">
What’s missing in the following data frame? How does quantile() return that missing piece? Why isn’t that helpful here?
</div>

```{r, error=TRUE}
mtcars %>%
  group_by(cyl) %>%
  summarise(q = list(quantile(mpg))) %>%
  unnest()
```

Не хватает конкретные значения квантилей от 0 до 1.
Функция `quantile()` возвращает их в названиях столбцов.

```{r, error=TRUE}
quantile(mtcars$mpg)
```

Поскольку функция `unnest()` отбрасывает имена векторов, они здесь бесполезны.

#### Упражнение 25.4.3
<div class="question">
What does this code do? Why might might it be useful?
</div>

```{r, error=TRUE}
mtcars %>%
  group_by(cyl) %>%
  summarise_each(funs(list))
```

Этот код создает фрейм данных, в котором каждая строка соответствует значению цилиндров `group_by(cyl)`, а каждое наблюдение для каждого столбца (кроме `cyl`) является вектором всех значений этого столбца для этого значения цилиндров.


### Упрощение столбцов-списков

Чтобы применить методы манипулирования данными и визуализации, которые вы изучили в этой книге, вам нужно упростить список-столбец обратно до обычного столбца (атомарного вектора) или набора столбцов. Техника, которую вы будете использовать, чтобы вернуться к более простой структуре, зависит от того, хотите ли вы одно значение для элемента или несколько значений:

* Если вам нужно одиночное значение, используйте `mutate()` с функциями `map_lgl()`, `map_int()`, `map_dbl()` и `map_chr()` для создания атомарного вектора.

* Если вам нужно несколько значений, используйте `unnest()`, чтобы преобразовать столбцы списка обратно в обычные столбцы, повторяя строки столько раз, сколько необходимо.

Разберём их подробнее

#### Преобразование списка в вектор

Преобразовав свой столбец-список в атомарный выектор, вы получите обычный столбец. Например, вы всегда можете суммировать объект по типу и длине, поэтому следующий код будет работать для любого списка столбца

```{r, error=TRUE}
df <- tribble(
  ~x,
  letters[1:5],
  1:3,
  runif(5)
)
  
df %>% mutate(
  type = map_chr(x, typeof),
  length = map_int(x, length)
)
```

Это та же основная информация, которую вы получаете из функции `print()` по умолчанию, но теперь вы можете использовать ее для фильтрации. Это полезный метод, если у вас есть неоднородный список, и вы хотите отфильтровать части, которые не нужны.

Не забывайте о сокращенных вызовах функций `map_*()` - вы можете использовать `map_chr(x, "apple")`, чтобы извлечь строку, хранящуюся в `apple`, для каждого элемента `x`. Это полезно для разделения вложенных списков в обычные столбцы. Используйте аргумент `.null`, чтобы указать значение, которое будет использоваться, если элемент отсутствует (вместо возврата `NULL`):

```{r, error=TRUE}
df <- tribble(
  ~x,
  list(a = 1, b = 2),
  list(a = 2, c = 4)
)
df %>% mutate(
  a = map_dbl(x, "a"),
  b = map_dbl(x, "b", .null = NA_real_)
)
```

#### Отмена вложения

Функция `unnest()` работает, повторяя обычные столбцы один раз для каждого элемента списка-столбца. Например, в следующем очень простом примере мы повторяем первую строку 4 раза (потому что там первый элемент y имеет длину четыре), а вторую строку один раз:

```{r, error=TRUE}
tibble(x = 1:2, y = list(1:4, 1)) %>% unnest(y)
```

Это означает, что вы не можете одновременно удалить два столбца, которые содержат разное количество элементов:

```{r, error=TRUE}
# работает, поскольку y и z содержат одинаковое кол-во элементов
# в каждой строке
df1 <- tribble(
  ~x, ~y,           ~z,
   1, c("a", "b"), 1:2,
   2, "c",           3
)
df1

df1 %>% unnest(y, z)


# Не работает, поскольку y и z имеют разное кол-во элементов
df2 <- tribble(
  ~x, ~y,           ~z,
   1, "a",         1:2,  
   2, c("b", "c"),   3
)
df2

# df2 %>% unnest(y, z) 
```

Тот же принцип применяется при развертывании списка-столбцов фреймов данных. Вы можете отложить несколько списочных столбцов, если все фреймы данных в каждой строке имеют одинаковое количество строк.

#### Упражнение 25.5.1
<div class="question">
Why might the `lengths()` function be useful for creating atomic vector columns from list-columns?
</div>

Функция `lengths()` возвращает длину каждого элемента в списке. Это может быть полезно для проверки, имеют ли все элементы в столбце списка одинаковую длину. Вы можете получить максимальную длину, чтобы определить, сколько атомных векторных столбцов создать. Это также замена для чего-то вроде `map_int(x, length)` или `sapply(x, length)`.

#### Упражнение 25.5.2
<div class="question">
ist the most common types of vector found in a data frame. What makes lists different?
</div>

Частовстречающиеся вектора это 

* `logical`

* `numeric`

* `integer`

* `character`

* `factor`

Все распространенные типы векторов во фремйах данных являются атомарными. Списки не являются атомарными, поскольку они могут содержать другие списки и другие векторы.

### Приведение данных к аккуратной форме при помоще пакета `broom`

Пакет `broom` предоставляет три основных инструмента для превращения моделей в аккуратные фреймы данных:

* `broom::glance(model)` возвращает строку для каждой модели. В каждом столбце дается сводка модели: либо показатель качества модели, либо сложность, либо их комбинация.

* `broom::tidy(model)` возвращает строку для каждого коэффициента в модели. Каждый столбец содержит информацию об оценке или ее изменчивости.

* `broom::augment(модель, данные)` возвращает строку для каждой строки в данных, добавляя дополнительные значения, такие как невязки, и влияет на статистику.

<!--chapter:end:20_purrr_and_broom.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Коммуникация
## Язык разметки R Markdown
### Введение

Не буду копипастить эту главу книги, в оригинале всё довольно подробно и понятно описано.

<!--chapter:end:21_communication.Rmd-->

