---
output: html_document
editor_options: 
  chunk_output_type: console
---

## Создание модели
### Введение

В прошлой главе были искусственные данные, сейчас поработаем на реальных.

Порядок будет такой --- мы будем обнаруживать тенденции посредством визуализации, а затем конкретизировать и уточнять из с помощью модели.
Затем мы повторим процесс, но заменим старую пременную отклика остатками, опеределённой модели.

Нашей целью является переход от неявных знаний, содержащихся в данных и наших головах, к явным знаниям, содержащимся в количественной модели. Это облешчит их применение в новых областях и использование другими людьми.

Нужно уметь вовремя остановится

Давным-давно на уроке рисования мой учитель сказал мне: «Художник должен знать, когда произведение готово. Вы не можете что-то настроить в совершенстве - заверните это. Если вам это не нравится, сделайте это снова. В противном случае начните что-то новое ». Позже я услышал: «Бедная швея делает много ошибок. Хорошая швея усердно работает над исправлением этих ошибок. Великая швея не боится выбросить одежду и начать все сначала ».

<https://www.reddit.com/r/datascience/comments/4irajq>

#### Необходимые ресурсы

```{r}
library(tidyverse)
library(modelr)
options(na.action = na.warn)

library(nycflights13)
library(lubridate)
```

### Почему бриллианты низкого качества оказались более дорогими

В предыдущих главах мы наблюдали необычное соотношение между качеством бриллиантов и их ценой.
Бриллианты низкого качества, плохая огранка, неудачный цвет, и худшая чистота стоят дороже

```{r}
ggplot(diamonds, aes(cut, price)) + geom_boxplot()
ggplot(diamonds, aes(color, price)) + geom_boxplot()
ggplot(diamonds, aes(clarity, price)) + geom_boxplot()
```

Худший цвет бриллианта --- J
Худший класс чистоты --- I1


#### Цена и вес

Похоже, цена низкокачественных бриллиантов оказалась выше из-за одной важной переменной --- `carat` (вес в каратах).
Вес бриллианта --- единственно важный фактор, для определения его цены. А низкокачественные бриллианты имеют как правило большие размеры

```{r}
ggplot(diamonds, aes(carat, price)) + 
  geom_hex(bins = 50)
```

Нам будет проще увидеть, как другие атрибуты бриллианта влияют на его относительную цену, если мы построим модель, отделяющую эффект прпеменной карат. Но сначала немного подправим набор данных, чтобы с ним легче было работать

1. Сфокусируемся на бриллиантах весом меньше 2.5 карата (99,7 данных)

2. Перейдём к логарифмам переменных карат и прайс

```{r}
diamonds2 <- diamonds %>% 
  filter(carat <= 2.5) %>% 
  mutate(lprice = log2(price), lcarat = log2(carat))
```

Совместное внесение этих изменений упрощает выявление взаимосвязи переменных карат и прайс

```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_hex(bins = 50)
```

В данном случае логарифмическое преобразование особенно удобно, посколько оно линеаризует шаблон, а с линейными шаблонами легче работать.

Сделем еще один шаг и исключим эту ярко выраженную линейную тенденцию. Сначала мы явно создаём шаблон путём построения модели

```{r}
mod_diamond <- lm(lprice ~ lcarat, data = diamonds2)
```

Затем мы смотрим что говорит о данных эта модель. Мы выполняем обратное преобразование предсказаний отменяя логарифмическое преобразование, чтобы предсказания можно было наложить на исходные данные

```{r}
grid <- diamonds2 %>% 
  data_grid(carat = seq_range(carat, 20)) %>% 
  mutate(lcarat = log2(carat)) %>% 
  add_predictions(mod_diamond, "lprice") %>% 
  mutate(price = 2 ^ lprice)

ggplot(diamonds2, aes(carat, price)) + 
  geom_hex(bins = 50) + 
  geom_line(data = grid, colour = "red", size = 1)
```

В результате получаем интересную информацию о данных. Если мы долверяем нашей модели, то большие бриллианты намного дешевле, мем можно было ожидать. Вероятно это объясняется тем, что ни один бриллиант в данном наборе не стоит более 19000 долларов.

Рассмотрение остатков подтверждает, что мы успешно исключили ярковыраженный линейный шаблон. На графике сплошное облако шума.

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond, "lresid")

ggplot(diamonds2, aes(lcarat, lresid)) + 
  geom_hex(bins = 50)
```

Важно что теперь мы можем заново построить наши мотивирующие графики используя остатки, вместо переменной прайс

```{r}
ggplot(diamonds2, aes(cut, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(color, lresid)) + geom_boxplot()
ggplot(diamonds2, aes(clarity, lresid)) + geom_boxplot()
```

Теперь мы видим ожидаемую взаимосвязь --- по мере улучшения качества бриллиантов растёт их относительная цена.
 Для интерпретации оси игрее необходимо подумать о том, о чем на говорят остатки и по какой шкале они измеряются.
 
 Остаток -1 указывает на то, что переменная `lprice`была на единицу ниже предсказанного значения, если основываться на его весе. $2^{-1}$ равно $\frac{1}{2}$ поэтому точка со значением -1 соответствует половине ожидаемой цены. А остатки со значением 1 соответствуют двойной предсказанной цене.
 
### Более сложная модель

При желании можно достраивть модель, усложняя её имеющимися параметрами

```{r}
mod_diamond2 <- lm(lprice ~ lcarat + color + cut + clarity, data = diamonds2)
```

Теперь модель включает 4 предиктора и её труднее визуализировать. К счастью, к настоящему моменту все они независимы, а это означает что мы можем отобразить их по отдельности на 3 графиках.

```{r}
grid <- diamonds2 %>% 
  data_grid(cut, .model = mod_diamond2) %>% 
  add_predictions(mod_diamond2)
grid

ggplot(grid, aes(cut, pred)) + 
  geom_point()
```

Если модель нуждается в переменных, которые вы не продоставили ей явно, функция `data_grid()` автоматически заполнит их типичными значениям. Для непрерывных переенных она использует медиану, а для категориальных --- моду. 

```{r}
diamonds2 <- diamonds2 %>% 
  add_residuals(mod_diamond2, "lresid2")

ggplot(diamonds2, aes(lcarat, lresid2)) + 
  geom_hex(bins = 50)
```

Этот график указывает на то, что имеюбтся бриллианты с довольно большими остатками --- вспомните о том, что остаток 2 означет 4-кратное превышение цены по сравнению с ожидаемой. Часто целесообразно рассматривать необчные значения по отдельности

```{r}
diamonds2 %>% 
  filter(abs(lresid2) > 1) %>% 
  add_predictions(mod_diamond2) %>% 
  mutate(pred = round(2 ^ pred)) %>% 
  select(price, pred, carat:table, x:z) %>% 
  arrange(price)
```

В данном случае мы не находим ничего необычного, но вероятно стоило потратить какое-то время на выяснение того, не указывает ли это на возможноые проблемы с нашей моделью или на наличие ошибок в данных. В случае существования ошибок в данных это могло бы обернуться счастливыой возможностью купить бриллианты по неоправданно заниженной цене. Сила в данных

#### Упражнение 24.2.3.1
<div class="question">
In the plot of `lcarat` vs. `lprice`, there are some bright vertical strips. What do they represent?
</div>


```{r}
ggplot(diamonds2, aes(lcarat, lprice)) + 
  geom_point()
```

Распределение алмазов имеет больше алмазов в круглых или дружественных для человека числах (дроби).


#### Упражнение 24.2.3.2
<div class="question">
If `log(price) = a_0 + a_1 * log(carat)`, what does that say about the relationship between price and carat?
</div>

Переведём исходное выражение в привычную математическую запись. Цену `price` я запишу как $y$, а караты `carat` как $x$

$$\log_b y = a_0 + a_1\log_b x$$

Сравним между собой отношение двух исходных выражений. Мы хотим понять, как изменяется отношение $y$ при изменении $x$. 

$$\log_b y_1 = a_0 + a_1\log_b x_1$$
$$\log_b y_2 = a_0 + a_1\log_b x_2$$
$$\log_b (y_2) - \log_b (y_1) = (a_0 + a_1\log_b x_2) - (a_0 + a_1\log_b x_1)$$
$$\log_b(\frac{y_2}{y_1}) = \log_b(\frac{x_2}{x_1})^{a_1}$$

$$\frac{y_2}{y_1} = (\frac{x_2}{x_1})^{a_1}$$

Собственно это и будет решением.

#### Упражнение 24.2.3.3
<div class="question">
Extract the diamonds that have very high and very low residuals. Is there anything unusual about these diamonds? Are the particularly bad or good, or do you think these are pricing errors?
</div>

Я буду искать подозрительные остатки, по предложенному Тьюки способу —-- буду считать выбросом, значение отклоняющиеся от квартилей на полтора размаха. 

```{r}
left <- diamonds2 %>% 
  filter(lresid2 <= quantile(lresid2,0.25) - 1.5*(quantile(lresid2,0.75) - quantile(lresid2,0.25)))

right <- diamonds2 %>% 
  filter(lresid2 >= quantile(lresid2,0.75) + 1.5*(quantile(lresid2,0.75) - quantile(lresid2,0.25)))

outliers_lresid2 <- rbind(left, right)
```

Теперь давайте визуализируем ч


```{r}
diamonds2 %>%
  ggplot(aes(cut, lresid2)) +
  geom_boxplot()
```

Вроде бы ничего подозрительного нет. 
Выбросы равномерно распределены, относительно качества огранки.
Наблюдается некая тенденция, что большая часть выбросов лижит в пределах от -1 до 1

Но давайте взглянем на остатки поближе.


```{r}
outliers_lresid2 %>%
  ggplot(aes(lresid2, color = cut)) +
  geom_freqpoly(binwidth = 0.1) + 
  facet_grid(cut~.)

outliers_lresid2 %>%
  ggplot(aes(lresid2, color = color)) +
  geom_freqpoly(binwidth = 0.1) + 
  facet_grid(color~.)

outliers_lresid2 %>%
  ggplot(aes(lresid2, color = clarity)) +
  geom_freqpoly(binwidth = 0.1) + 
  facet_grid(clarity~.)
```

Основная масса выбросов приходится на значения плюс-минус 0.5.
Практически в одинаковой мере попадаются плохие и хорошие. 
Заметно чаще эти ошибки встречаются в более дорогих алмазах.
Можно предположить, что цена искусственно завышена-занижена.

#### Упражнение 24.2.3.4
<div class="question">
Does the final model, `mod_diamond2`, do a good job of predicting diamond prices? 
Would you trust it to tell you how much to spend if you were buying a diamond?
</div>

```{r}
summary(mod_diamond2)
```

Adjusted R-squared имеет значение 0.9828.
Это очень хороший результат. Возьмём теперь предсказанные значение логарифма цены.

```{r}
diamonds2$predict <- predict(object = mod_diamond2)
```

Сравним предсказания, с реальной ценой. Я введу новую переменную, которая показывает во сколько раз предсказание отличается от реальной цены

```{r}
diamonds2 <- diamonds2 %>% 
  mutate(result = 1 - (predict / lprice))

diamonds2 %>% 
  ggplot(aes(cut, result)) +
  geom_boxplot()

mean(abs(diamonds2$result))
max(abs(diamonds2$result))
```

То есть средняя ошибка модели это 1%.
Я бы доверился такой модели перед покупкой

### Что влияет на количество ежедневных авиарейсов

Это небольшой набло данных, в нём 365 строк и 2 столбца.
Мы не будем доводить процесс до полностью реализованной модели, но каждый наш шаг будет способствовать лучшему опниманию данных.

Начнём с количества авиарейсов за день и визуализируем данные

```{r}
daily <- flights %>% 
  mutate(date = make_date(year, month, day)) %>% 
  group_by(date) %>% 
  summarise(n = n())
```


```{r}
ggplot(daily, aes(date, n)) +
  geom_line()
```

#### День недели

Выявления долгосрочных тенденций --- непростая задача из-за наличия сильного эффекта для недели, который доминирует над более слабыми тенденциями. Начнём с рассмортения распределения количества авиварейсов по дням недели.

```{r}
daily <- daily %>% 
  mutate(wday = wday(date, label = T))

ggplot(daily, aes(wday, n)) +
  geom_boxplot()
```

В выходные дни полётов меньше, поскольку большинство путешествуют в деловых целях. Этот эффект особенно выражен по субботам: иногда вы можете вылететь в вс, чтобы успеть на встречу, которая назначена на утро понедельника, но очень редко выбереть для вылета субботу, поскольку предпочтете провести это время с домашними.

Один из способов исключения этой сильной тенденции --- использовать модель. Сначала мы строим модель и отображаем её предсказания поверх исходных данных.

```{r}
mod <- lm(n ~ wday, data = daily)

grid <- daily %>% 
  data_grid(wday) %>% 
  add_predictions(mod, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, color = "red")
```

Затем вычисляем, и визуализируем остатки

```{r}
daily <- daily %>% 
  add_residuals(mod)

daily %>% 
  ggplot(aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line()
```

Обращаем внимание на изменени смысла оси `y` --- теперь вдоль неё откладываются отклонения количества полётов от ожидаемого для разных дней недели. Этот график весьма полезен, поскольку теперь, когда из него исключена значительная часть сильного эффекта дня недели, мы можем видеть некоторые слабые оставшиеся тендеции

* По видимому, начиная с июня, наша модель работает плохо --- вы по-прежнему можете наблюдать сильный регулярный шаблон, который модели не удалось захватить. Вычерчивание графика с использованием отдельных линий для каждого дня недели позволяет лучше это увидеть

```{r}
ggplot(daily, aes(date, resid, colour = wday)) + 
  geom_ref_line(h = 0) + 
  geom_line()
```

Нашей модели не удаётся точно предсказать количество авиарейсов по субботам --- летом колчиество полетов превышает ожидаемое значение, а осенью оно ниже ожидаемого значения. В следующем разделе будет показано, каким образом можно улучшить захват этого шаблона.

* Для некоторых дней количество рейсов значительно превышает ожидаемое значение

```{r}
daily %>% 
  filter(resid < -100)
```

Заметно, что часть дней выпадают на праздники

* Очевидно существование гладкого долгосрочного тренда на протяжении года. Этот тренд можно выделить с помощью функции 

```{r}
daily %>% 
  ggplot(aes(date, resid)) + 
  geom_ref_line(h = 0) + 
  geom_line(colour = "grey50") + 
  geom_smooth(se = FALSE, span = 0.20)
```

В январе (и декабре) меньше рейсов, а летом больше (май-сентябрь). Мы не можем сделать много с этой моделью количественно, потому что у нас есть только один год данных. Но мы можем использовать наши знания предметной области для мозгового штурма потенциальных объяснений.

#### Сезонный субботний эффект

Давайте сначала рассмотрим нашу неспособность точно предсказать количество рейсов в субботу. Хорошее место для начала - вернуться к необработанным числам, сосредоточившись на субботах:

```{r}
daily %>% 
  filter(wday == "Сб") %>% 
  ggplot(aes(date, n)) + 
    geom_point() + 
    geom_line() +
    scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```

Я подозреваю, что эта закономерность вызвана летними каникулами: многие люди уезжают в отпуск летом, и люди не против путешествовать по субботам в отпуск. Глядя на этот график, можно догадаться, что летние каникулы идут с начала июня до конца августа. Похоже, это очень хорошо согласуется со школьными условиями штата: летний отпуск в 2013 году был 26 июня - 9 сентября.


Давайте создадим переменную «term», которая приблизительно охватывает три школьных термина, и проверим нашу работу с помощью графика:

```{r}
term <- function(date) {
  cut(date, 
    breaks = ymd(20130101, 20130605, 20130825, 20140101),
    labels = c("весна", "лето", "осень") 
  )
}

daily <- daily %>% 
  mutate(term = term(date)) 

daily %>% 
  filter(wday == "Сб") %>% 
  ggplot(aes(date, n, colour = term)) +
  geom_point(alpha = 1/3) + 
  geom_line() +
  scale_x_date(NULL, date_breaks = "1 month", date_labels = "%b")
```


(Я вручную подправил даты, чтобы получить хорошие перерывы в сюжете. Использование визуализации, чтобы помочь вам понять, что делает ваша функция, является действительно мощной и общей техникой.)

Полезно посмотреть, как эта новая переменная влияет на другие дни недели:

```{r}
daily %>% 
  ggplot(aes(wday, n, colour = term)) +
    geom_boxplot()
```

Похоже, что есть существенные различия между временами года, поэтому целесообразно использовать отдельный эффект дня недели для каждого. Это улучшает нашу модель, но не настолько, как мы могли бы надеяться:

```{r}
mod1 <- lm(n ~ wday, data = daily)
mod2 <- lm(n ~ wday * term, data = daily)

daily %>% 
  gather_residuals(without_term = mod1, with_term = mod2) %>% 
  ggplot(aes(date, resid, colour = model)) +
    geom_line(alpha = 0.75)
```

Мы можем увидеть проблему, наложив прогнозы из модели на необработанные данные:

```{r}
grid <- daily %>% 
  data_grid(wday, term) %>% 
  add_predictions(mod2, "n")

ggplot(daily, aes(wday, n)) +
  geom_boxplot() + 
  geom_point(data = grid, colour = "red") + 
  facet_wrap(~ term)
```

Наша модель находит среднее значение, но у нас есть много больших отклонений, поэтому среднее значение, как правило, далеко от типичного значения. Мы можем решить эту проблему, используя модель, устойчивую к воздействию выбросов: `MASS::rlm()`. Это значительно уменьшает влияние выбросов на наши оценки и дает модель, которая хорошо справляется с удалением модели дня недели:

```{r}
mod3 <- MASS::rlm(n ~ wday * term, data = daily)

daily %>% 
  add_residuals(mod3, "resid") %>% 
  ggplot(aes(date, resid)) + 
  geom_hline(yintercept = 0, size = 2, colour = "white") + 
  geom_line()
```

Теперь намного легче увидеть долгосрочную тенденцию, а также положительные и отрицательные выбросы.

#### Вычисляемые переменные

Если вы экспериментируете со многими моделями и множеством визуализаций, было бы неплохо объединить создание переменных в функцию, чтобы не было возможности случайно применить другое преобразование в разных местах. Например, мы могли бы написать:

```{r}
compute_vars <- function(data) {
  data %>% 
    mutate(
      term = term(date), 
      wday = wday(date, label = TRUE)
    )
}
```

Другой вариант - поместить преобразования непосредственно в формулу модели:

```{r}
wday2 <- function(x) wday(x, label = TRUE)
mod3 <- lm(n ~ wday2(date) * term(date), data = daily)
```

Любой подход является разумным. Делаnm преобразованную переменную явной, полезно, если вы хотите проверить свою работу или использовать их в визуализации. Но вы не можете легко использовать преобразования (например, конвейеры), которые возвращают несколько столбцов. Включение преобразований в функцию модели немного облегчает жизнь, когда вы работаете со многими различными наборами данных, потому что модель самодостаточна.

#### Время года: альтернативный подход

В предыдущем разделе мы использовали наши знания предметной области (как термин «школа» в США влияет на поездки), чтобы улучшить модель. Альтернатива прямому использованию наших знаний в модели - предоставить данным больше пространства для разговора. Мы могли бы использовать более гибкую модель и позволить ей охватить интересующий нас паттерн. Простой линейный тренд не является адекватным, поэтому мы могли бы попытаться использовать естественный сплайн, чтобы соответствовать плавной кривой в течение года:

```{r}
library(splines)
mod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily)

daily %>% 
  data_grid(wday, date = seq_range(date, n = 13)) %>% 
  add_predictions(mod) %>% 
  ggplot(aes(date, pred, colour = wday)) + 
    geom_line() +
    geom_point()
```

Мы видим сильную закономерность в количестве субботних рейсов. Это обнадеживает, потому что мы также видели этот шаблон в необработанных данных. Это хороший знак, когда вы получаете один и тот же сигнал с разных подходов.

#### Упражнение 24.3.5.1
<div class="question">
Use your Google sleuthing skills to brainstorm why there were fewer than expected flights on Jan 20, May 26, and Sep 1. (Hint: they all have the same explanation.) How would these days generalise to another year?
</div>

Это воскресенье перед выходными в понедельник, День Мартина Лютера Кинга-младшего, День памяти и День труда. Для других лет используйте даты выходных для этих лет: третий понедельник января для Мартина Лютера Кинга-младшего, последний понедельник мая для Дня памяти и первый понедельник сентября для Дня труда.

#### Упражнение 24.3.5.2
<div class="question">
What do the three days with high positive residuals represent? How would these days generalize to another year?
</div>

```{r}
daily %>% 
  top_n(3, resid)
```

Три верхних дня соответствуют субботе после Дня благодарения (30 ноября), воскресенью после Дня благодарения (1 декабря) и субботе после Рождества (28 декабря). Мы могли бы обобщить их на другие годы, используя даты этих праздников тех лет.

#### Упражнение 24.3.5.3
<div class="question">
Create a new variable that splits the `wday` variable into terms, but only for Saturdays, i.e. it should have `Thurs`, `Fri`, but `Sat-summer`, `Sat-spring`, `Sat-fall`. How does this model compare with the model with every combination of `wday` and `term`?
</div>

```{r}
daily <- daily  %>% 
  mutate(splitted_day = 
           ifelse(wday == "Сб", paste0(wday, "-", term), as.character(wday)))

mod4 <- lm(n ~ splitted_day, data = daily)

daily %>%
  gather_residuals(sat_term = mod4, all_interact = mod2) %>%
  ggplot(aes(date, resid, color = model)) +
  geom_line() +
  facet_grid(model~.)
```

Посмотрим на разницы остатков.

```{r}
daily %>%
  spread_residuals(sat_term = mod4, all_interact = mod2) %>%
  mutate(resid_diff = sat_term - all_interact) %>%
  ggplot(aes(date, resid_diff)) +
  geom_line()
```

Получаем, что модифицифрованная модель (Сб-весна) имеет более высокие остатки летом и более низкие остатки весной. При этом осенью остатки более менее одинаковы.

#### Упражнение 24.3.5.4
<div class="question">
Create a new `wday` variable that combines the day of week, term (for Saturdays), and public holidays. What do the residuals of that model look like?
</div>

Итак, погуглив, находим общенациональные американские праздники.
Создадим переменную, в которую положим все эти праздники

```{r}
holidays_2013 <-
  tribble(
    ~holiday, ~date,
    "New Year's Day", 20130101,
    "Martin Luther King Jr. Day", 20130121,
    "Washington's Birthday", 20130218,
    "Memorial Day", 20130527,
    "Independence Day", 20130704,
    "Labor Day", 20130902,
    "Columbus Day", 20131028,
    "Veteran's Day", 20131111,
    "Thanksgiving", 20131128,
    "Christmas", 20131225
  ) %>%
  mutate(date = lubridate::ymd(date))
```

Добавим, для интереса, ещё и дни до и после праздников.
Потому что по собственному опыту скажу, что чаще всего, я вылетаю на праздники в день до наступления праздника. Точнее вечером после работы, чтобы побольше побыть с родными или друзьями.

```{r}
daily <- daily %>%
  mutate(
    wday3 =
      case_when(
        date %in% (holidays_2013$date - 1L) ~ "день до праздника",
        date %in% (holidays_2013$date + 1L) ~ "день после праздника",
        date %in% holidays_2013$date ~ "праздник",
        .$wday == "сб" & .$term == "лето" ~ "сб-лето",
        .$wday == "сб" & .$term == "осень" ~ "сб-осень",
        .$wday == "сб" & .$term == "spring" ~ "сб-весн",
        TRUE ~ as.character(.$wday)
      )
  )
```

Теперь построим модель, которая будет учитывать не только сезонность суббот, но и включенные праздники.

```{r}
mod5 <- lm(n ~ wday3, data = daily)

daily %>%
  spread_residuals(resid_sat_terms = mod4, resid_holidays = mod5) %>%
  mutate(resid_diff = resid_holidays - resid_sat_terms) %>%
  ggplot(aes(date, resid_diff)) +
  geom_line(alpha = 0.75)
```

Как видно на графике, модель довольно точно определяет даты, очень похожие на введёные нами праздники и дни до и после праздников.

```{r}
daily %>%
  spread_residuals(resid_sat_terms = mod4, resid_holidays = mod5) %>%
  mutate(resid_diff = resid_holidays - resid_sat_terms) %>% 
  filter(resid_diff > 50)
```


#### Упражнение 24.3.5.5
<div class="question">
What happens if you fit a day of week effect that varies by month (i.e., n ~ wday * month)? Why is this not very helpful?
</div>

Добавим новую переменную, которая определяет месяц

```{r}
daily <- daily %>% 
  mutate(month = factor(month(date)))
```


```{r}
mod6 <- lm(n ~ wday*month, data = daily)

daily <- daily %>% 
  add_residuals(mod6)

daily %>% 
  ggplot(aes(date, resid)) +
  geom_ref_line(h = 0) +
  geom_line()
```

Как видим, эта модель не эффективна, поскольку не ловит большие отклонения.
Если м ы посмотрим, на то из чего состоит модель, то увидим что в модели будет 12 * 7 = 84 параметра. Поскольку у каждого месяца есть только четыре-пять недель, каждый из этих дней недели × месяц - это в среднем только четыре или пять наблюдений. Эти оценки имеют большие стандартные ошибки и, вероятно, не обобщаются далеко за пределы выборочных данных, поскольку они оцениваются только из нескольких наблюдений.

```{r}
summary(mod6)
```

#### Упражнение 24.3.5.6
<div class="question">
What would you expect the model `n ~ wday + ns(date, 5)` to look like?
Knowing what you know about the data, why would you expect it to be not particularly effective?
</div>

Предыдущие модели вписываются в главу, и упражнения показывают, что влияние дней недели меняется в зависимости от времени года. Модель в этом упражнении не взаимодействует с эффектом дня недели и со временем года.

```{r}
mod7 <- lm(n ~ wday + ns(date, 5), data = daily)
mod8 <- lm(n ~ wday * ns(date, 5), data = daily)
```

Остатки модели, которая не взаимодействует со днём недели со временем года (mod7), больше, чем остатки модели, которая взаимодействует (mod8). Модель mod7 недооценивает выходные летом и переоценивает выходные осенью.

```{r}
daily %>%
  gather_residuals(mod7, mod8) %>%
  ggplot(aes(x = date, y = resid, color = model)) +
  geom_line(alpha = 0.75)
```

#### Упражнение 24.3.5.7
<div class="question">
We hypothesized that people leaving on Sundays are more likely to be business travelers who need to be somewhere on Monday. Explore that hypothesis by seeing how it breaks down based on distance and time: if it’s true, you’d expect to see more Sunday evening flights to places that are far away.
</div>

Сравнивая средние расстояния рейсов по дням недели, воскресные рейсы занимают второе место по длине. Субботние рейсы самые длинные в среднем. В субботу могут быть самые длинные рейсы в среднем, потому что на выходные меньше регулярных регулярных рейсов бизнес / пригородных рейсов, но это предположение.

```{r}
flights %>%
  mutate(
    date = make_date(year, month, day),
    wday = wday(date, label = TRUE)
  ) %>%
  ggplot(aes(y = distance, x = wday)) +
  geom_boxplot()
```

Построим средние дистанции и величины стандартного.
Используем функцию из упражнения ниже, чтобы поставить понедельник не первое место.

```{r}
flights %>%
  mutate(
    date = make_date(year, month, day),
    wday = wday(date, label = TRUE)
  ) %>%
  ggplot(aes(y = distance, x = relevel(wday))) +
  stat_summary()
```

В субботу в среднем летают на большие дистанции. 


Необходимо продолжить исследование.


#### Упражнение 24.3.5.8
<div class="question">
It’s a little frustrating that Sunday and Saturday are on separate ends of the plot. Write a small function to set the levels of the factor so that the week starts on Monday.
</div>

Используем релевел

```{r}
relevel <- function(x) {
  fct_relevel(x, levels(x)[-1])
}
```

Вуаля, понедельник первый

```{r}
daily <- daily %>%
  mutate(wday = wday(date, label = TRUE))


ggplot(daily, aes(relevel(wday), n)) +
  geom_boxplot() +
  labs(x = "День недели", y = "Число полётов")
```

### Больше о моделях

Тут ссылки на ещё информацию о моделях


* *Statistical Modeling: A Fresh Approach* by Danny Kaplan,
  <http://www.mosaic-web.org/go/StatisticalModeling/>. This book provides 
  a gentle introduction to modelling, where you build your intuition,
  mathematical tools, and R skills in parallel. The book replaces a traditional
  "introduction to statistics" course, providing a curriculum that is up-to-date 
  and relevant to data science.

* *An Introduction to Statistical Learning* by Gareth James, Daniela Witten, 
  Trevor Hastie, and Robert Tibshirani, <http://www-bcf.usc.edu/~gareth/ISL/> 
  (available online for free). This book presents a family of modern modelling
  techniques collectively known as statistical learning.  For an even deeper
  understanding of the math behind the models, read the classic 
  *Elements of Statistical Learning* by Trevor Hastie, Robert Tibshirani, and
  Jerome Friedman, <https://web.stanford.edu/~hastie/Papers/ESLII.pdf> (also
  available online for free).

* *Applied Predictive Modeling* by Max Kuhn and Kjell Johnson, 
  <http://appliedpredictivemodeling.com>. This book is a companion to the 
  __caret__ package and provides practical tools for dealing with real-life
  predictive modelling challenges.

